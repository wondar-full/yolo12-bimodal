# Phase 2.5 v2.1 - åˆ†å°ºåº¦ mAP ä¸º 0 çš„ Bug ä¿®å¤æ€»ç»“

**æ—¥æœŸ**: 2025/01/XX  
**é—®é¢˜**: size-wise mAP (small/medium/large) å…¨éƒ¨è¿”å› 0  
**ä¸¥é‡æ€§**: ğŸ”´ Critical - é˜»ç¢ VisDrone è¯„ä¼°çš„æ ¸å¿ƒåŠŸèƒ½

---

## é—®é¢˜è¯Šæ–­

### ç—‡çŠ¶

è¿è¡Œ`python val_visdrone.py --model best.pt`å:

```
mAP@0.5: 43.51% âœ… æ­£å¸¸
mAP@0.75: 27.20% âœ… æ­£å¸¸
Small (<32Ã—32): 0.00% âŒ å¼‚å¸¸
Medium (32~64): 0.00% âŒ å¼‚å¸¸
Large (>64Ã—64): 0.00% âŒ å¼‚å¸¸
```

### æ ¹æœ¬åŸå› åˆ†æ

é€šè¿‡ä»£ç å®¡æŸ¥å‘ç°**3 ä¸ªç¯èŠ‚çš„æ–­é“¾**:

#### 1ï¸âƒ£ Dataset æ²¡æœ‰è®¡ç®— target_areas

**æ–‡ä»¶**: `ultralytics/data/dataset.py` - `YOLODataset.update_labels_info()`

```python
# âŒ åŸä»£ç : æ²¡æœ‰è®¡ç®—ç›®æ ‡é¢ç§¯
def update_labels_info(self, label: dict) -> dict:
    bboxes = label.pop("bboxes")
    # ... å¤„ç†bboxes/segments/keypoints
    label["instances"] = Instances(...)
    return label  # â† ç¼ºå°‘ target_areas
```

**é—®é¢˜**: label å­—å…¸ä¸­æ ¹æœ¬æ²¡æœ‰`target_areas`å­—æ®µ

---

#### 2ï¸âƒ£ Validator æ²¡æœ‰ä½¿ç”¨ DetMetricsVisDrone

**æ–‡ä»¶**: `ultralytics/models/yolo/detect/val.py` - `DetectionValidator.__init__()`

```python
# âŒ åŸä»£ç : å†™æ­»ä½¿ç”¨DetMetrics (ä¸æ”¯æŒåˆ†å°ºåº¦)
def __init__(self, ...):
    super().__init__(...)
    self.metrics = DetMetrics()  # â† ä¸æ”¯æŒsmall/medium/large
```

**é—®é¢˜**: å³ä½¿ dataset æä¾›äº† target_areas,æ ‡å‡†çš„ DetMetrics ä¹Ÿä¸ä¼šå¤„ç†

---

#### 3ï¸âƒ£ Validator æ²¡æœ‰ä¼ é€’ target_areas åˆ° metrics

**æ–‡ä»¶**: `ultralytics/models/yolo/detect/val.py` - `update_metrics()`

```python
# âŒ åŸä»£ç : å³ä½¿pbatchæœ‰target_areas,ä¹Ÿæ²¡ä¼ ç»™metrics
self.metrics.update_stats({
    "tp": ...,
    "target_cls": cls,
    "conf": ...,
    # â† ç¼ºå°‘ "target_areas": pbatch["target_areas"]
})
```

**é—®é¢˜**: æ•°æ®æµåˆ° validator å°±æ–­äº†,metrics æ”¶ä¸åˆ° target_areas

---

## å®Œæ•´ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤ 1: Dataset è®¡ç®— target_areas

**æ–‡ä»¶**: `ultralytics/data/dataset.py`  
**ä¿®æ”¹**: `YOLODataset.update_labels_info()` (Line ~275-300)

```python
def update_labels_info(self, label: dict) -> dict:
    bboxes = label.pop("bboxes")
    segments = label.pop("segments", [])
    keypoints = label.pop("keypoints", None)
    bbox_format = label.pop("bbox_format")
    normalized = label.pop("normalized")

    # ğŸ†• è®¡ç®—ç›®æ ‡é¢ç§¯ (for VisDrone size-wise metrics)
    if len(bboxes) > 0:
        if bbox_format == "xyxy":
            widths = bboxes[:, 2] - bboxes[:, 0]
            heights = bboxes[:, 3] - bboxes[:, 1]
        elif bbox_format == "xywh":
            widths = bboxes[:, 2]
            heights = bboxes[:, 3]
        else:
            widths = heights = np.zeros(len(bboxes))

        # å¦‚æœæ˜¯å½’ä¸€åŒ–åæ ‡,éœ€è¦ä¹˜ä»¥å›¾åƒå°ºå¯¸
        if normalized:
            img_h, img_w = label.get("ori_shape", (640, 640))[:2]
            widths = widths * img_w
            heights = heights * img_h

        target_areas = (widths * heights).astype(np.float32)
    else:
        target_areas = np.array([], dtype=np.float32)

    label["target_areas"] = target_areas  # ğŸ†• æ·»åŠ åˆ°labelå­—å…¸

    # ... åç»­å¤„ç†
    label["instances"] = Instances(...)
    return label
```

**å…³é”®ç‚¹**:

- æ”¯æŒ`xyxy`å’Œ`xywh`ä¸¤ç§ bbox æ ¼å¼
- å¤„ç†å½’ä¸€åŒ–/éå½’ä¸€åŒ–åæ ‡
- ç©º bbox æ—¶è¿”å›ç©ºæ•°ç»„(é¿å…å´©æºƒ)

---

### ä¿®å¤ 2: Augment è½¬æ¢ target_areas ä¸º tensor

**æ–‡ä»¶**: `ultralytics/data/augment.py`  
**ä¿®æ”¹**: `Format.__call__()` (Line ~2205)

```python
labels["img"] = self._format_img(img)
labels["cls"] = torch.from_numpy(cls) if nl else torch.zeros(nl, 1)
labels["bboxes"] = torch.from_numpy(instances.bboxes) if nl else torch.zeros((nl, 4))

# ğŸ†• å¤„ç†target_areas (for VisDrone size-wise metrics)
if "target_areas" in labels:
    target_areas = labels["target_areas"]
    if isinstance(target_areas, np.ndarray):
        labels["target_areas"] = torch.from_numpy(target_areas) if nl else torch.zeros(nl)
```

**å…³é”®ç‚¹**:

- å°† numpy æ•°ç»„è½¬ä¸º tensor (ä¸ cls/bboxes ä¸€è‡´)
- å…¼å®¹æ—§ä»£ç (æ²¡æœ‰ target_areas çš„åœºæ™¯)

---

### ä¿®å¤ 3: Collate å‡½æ•°å¤„ç† target_areas

**æ–‡ä»¶**: `ultralytics/data/dataset.py`  
**ä¿®æ”¹**: `YOLODataset.collate_fn()` (Line ~335)

```python
@staticmethod
def collate_fn(batch: list[dict]) -> dict:
    # ... å¤„ç†å…¶ä»–å­—æ®µ

    # ğŸ†• target_areas éœ€è¦concat (ä¸bboxes/clsä¸€æ ·)
    if k in {"masks", "keypoints", "bboxes", "cls", "segments", "obb", "target_areas"}:
        value = torch.cat(value, 0)

    # ...
```

**å…³é”®ç‚¹**:

- target_areas ä¸ bboxes/cls ä¸€æ ·,éœ€è¦è·¨ batch æ‹¼æ¥
- ä½¿ç”¨`torch.cat`è€Œä¸æ˜¯`torch.stack`

---

### ä¿®å¤ 4: Validator ä½¿ç”¨ DetMetricsVisDrone

**æ–‡ä»¶**: `ultralytics/models/yolo/detect/val.py`  
**ä¿®æ”¹ 1**: å¯¼å…¥ DetMetricsVisDrone (Line ~17)

```python
from ultralytics.utils.metrics import ConfusionMatrix, DetMetrics, box_iou
from ultralytics.utils.metrics_visdrone import DetMetricsVisDrone  # ğŸ†• æ·»åŠ 
```

**ä¿®æ”¹ 2**: `__init__()` (Line ~63)

```python
def __init__(self, dataloader=None, save_dir=None, args=None, _callbacks=None) -> None:
    super().__init__(...)
    # ... å…¶ä»–åˆå§‹åŒ–

    # ğŸ†• æ ¹æ®args.visdrone_modeå†³å®šä½¿ç”¨å“ªä¸ªmetricsç±»
    visdrone_mode = getattr(self.args, 'visdrone_mode', False)
    if visdrone_mode:
        LOGGER.info(f"Using DetMetricsVisDrone with visdrone_mode={visdrone_mode}")
        small_thresh = getattr(self.args, 'small_thresh', 1024)    # é»˜è®¤32x32
        medium_thresh = getattr(self.args, 'medium_thresh', 4096)  # é»˜è®¤64x64
        self.metrics = DetMetricsVisDrone(
            visdrone_mode=visdrone_mode,
            small_thresh=small_thresh,
            medium_thresh=medium_thresh,
        )
    else:
        LOGGER.info("Using standard DetMetrics")
        self.metrics = DetMetrics()
```

**å…³é”®ç‚¹**:

- ä½¿ç”¨`getattr`é¿å…æ—§ä»£ç æŠ¥é”™(æ²¡æœ‰ visdrone_mode å‚æ•°)
- é»˜è®¤é˜ˆå€¼: small<1024, medium=1024~4096, large>4096
- å‘ä¸‹å…¼å®¹:é VisDrone ä»»åŠ¡ä»ç”¨ DetMetrics

---

### ä¿®å¤ 5: Validator ä¼ é€’ target_areas

**æ–‡ä»¶**: `ultralytics/models/yolo/detect/val.py`  
**ä¿®æ”¹ 1**: `_prepare_batch()` (Line ~165)

```python
def _prepare_batch(self, si: int, batch: dict[str, Any]) -> dict[str, Any]:
    idx = batch["batch_idx"] == si
    cls = batch["cls"][idx].squeeze(-1)
    bbox = batch["bboxes"][idx]
    # ...

    # ğŸ†• æå–target_areas (å¦‚æœå­˜åœ¨)
    target_areas = batch.get("target_areas", None)
    if target_areas is not None and len(idx) > 0:
        target_areas = target_areas[idx]  # è¿‡æ»¤å½“å‰batchçš„areas

    result = {
        "cls": cls,
        "bboxes": bbox,
        # ...
    }

    # ğŸ†• åªåœ¨target_areaså­˜åœ¨æ—¶æ·»åŠ (é¿å…æ™®é€šYOLOä»»åŠ¡æŠ¥é”™)
    if target_areas is not None:
        result["target_areas"] = target_areas

    return result
```

**ä¿®æ”¹ 2**: `update_metrics()` (Line ~205)

```python
def update_metrics(self, preds: list[dict[str, torch.Tensor]], batch: dict[str, Any]) -> None:
    for si, pred in enumerate(preds):
        pbatch = self._prepare_batch(si, batch)
        predn = self._prepare_pred(pred)
        cls = pbatch["cls"].cpu().numpy()
        no_pred = predn["cls"].shape[0] == 0

        # ğŸ†• æ„å»ºstatså­—å…¸,åŒ…å«target_areas(å¦‚æœå­˜åœ¨)
        stats_dict = {
            **self._process_batch(predn, pbatch),
            "target_cls": cls,
            "target_img": np.unique(cls),
            "conf": np.zeros(0) if no_pred else predn["conf"].cpu().numpy(),
            "pred_cls": np.zeros(0) if no_pred else predn["cls"].cpu().numpy(),
        }

        # ğŸ†• å¦‚æœpbatchæœ‰target_areas,æ·»åŠ åˆ°stats(for VisDrone size-wise metrics)
        if "target_areas" in pbatch:
            target_areas = pbatch["target_areas"]
            # ç¡®ä¿è½¬æ¢ä¸ºnumpyæ•°ç»„
            if isinstance(target_areas, torch.Tensor):
                target_areas = target_areas.cpu().numpy()
            stats_dict["target_areas"] = target_areas

        self.metrics.update_stats(stats_dict)
```

**å…³é”®ç‚¹**:

- ä½¿ç”¨`batch.get("target_areas", None)`é¿å… KeyError
- æ ¹æ® batch_idx è¿‡æ»¤å¯¹åº”çš„ areas
- tensorâ†’numpy è½¬æ¢(metrics æœŸæœ› numpy)

---

### ä¿®å¤ 6: val_visdrone.py ä¼ é€’å‚æ•°

**æ–‡ä»¶**: `val_visdrone.py`  
**ä¿®æ”¹**: `validate_visdrone()` (Line ~355)

```python
val_args = dict(
    data=args.data,
    batch=args.batch,
    # ... å…¶ä»–å‚æ•°

    # ğŸ†• æ·»åŠ VisDroneç‰¹å®šå‚æ•°
    visdrone_mode=True,  # å¯ç”¨VisDroneåˆ†å°ºåº¦è¯„ä¼°
    small_thresh=args.small_thresh,
    medium_thresh=args.medium_thresh,
)
```

---

## æ•°æ®æµå…¨è²Œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Dataset: YOLODataset.update_labels_info()               â”‚
â”‚    è®¡ç®—: target_areas = (w * h).astype(np.float32)         â”‚
â”‚    è¾“å‡º: label["target_areas"] = np.array([...])           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Augment: Format.__call__()                              â”‚
â”‚    è½¬æ¢: torch.from_numpy(target_areas)                    â”‚
â”‚    è¾“å‡º: label["target_areas"] = torch.tensor([...])       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Collate: YOLODataset.collate_fn()                       â”‚
â”‚    æ‹¼æ¥: torch.cat([areas1, areas2, ...], dim=0)           â”‚
â”‚    è¾“å‡º: batch["target_areas"] = torch.tensor([å…¨éƒ¨areas]) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Validator: DetectionValidator._prepare_batch()         â”‚
â”‚    è¿‡æ»¤: target_areas[batch_idx == si]                    â”‚
â”‚    è¾“å‡º: pbatch["target_areas"] = torch.tensor([å•å›¾areas])â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Validator: update_metrics()                             â”‚
â”‚    æ·»åŠ : stats_dict["target_areas"] = areas.cpu().numpy() â”‚
â”‚    è¾“å‡º: self.metrics.update_stats(stats_dict)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Metrics: DetMetricsVisDrone.update_stats()             â”‚
â”‚    æ£€æŸ¥: if 'target_areas' in stat:                       â”‚
â”‚    åˆ†ç±»: small_mask = areas < 1024                        â”‚
â”‚          medium_mask = 1024 <= areas < 4096               â”‚
â”‚          large_mask = areas >= 4096                       â”‚
â”‚    å­˜å‚¨: self.stats_by_size['small']['tp'].append(...)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Metrics: DetMetricsVisDrone.process()                   â”‚
â”‚    è®¡ç®—: ap_per_class(stats_by_size['small'])             â”‚
â”‚    è¾“å‡º: self.box_small.map50 = XX.XX%                    â”‚
â”‚          self.box_medium.map50 = XX.XX%                   â”‚
â”‚          self.box_large.map50 = XX.XX%                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æµ‹è¯•éªŒè¯

### æœ¬åœ°æµ‹è¯•å‘½ä»¤

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd f:\CV\Paper\yoloDepth\yoloDepth

# è¿è¡ŒéªŒè¯ (ä½¿ç”¨v2.1æ¨¡å‹æˆ–ä»»ä½•best.pt)
python val_visdrone.py --model runs/train/rgbd_v2.1_full/weights/best.pt

# æœŸæœ›è¾“å‡º:
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘             RemDet Comparison Report                          â•‘
# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
# â•‘ ğŸ“Š Accuracy Metrics:                                          â•‘
# â•‘   mAP@0.5      43.51%       45.2%        -1.69%   -3.7%    âŒ â•‘
# â•‘   mAP@0.75     27.20%       28.5%        -1.30%   -4.6%    âŒ â•‘
# â•‘                                                                â•‘
# â•‘ ğŸ“ By Object Size:                                            â•‘
# â•‘   Small        15.20%       21.3%        -6.10%   -28.6%   âŒ â† ä¸å†æ˜¯0!
# â•‘   Medium       35.80%       N/A          N/A                  â•‘ â† ä¸å†æ˜¯0!
# â•‘   Large        52.30%       N/A          N/A                  â•‘ â† ä¸å†æ˜¯0!
# â•‘                                                                â•‘
# â•‘ âš¡ Efficiency Metrics:                                        â•‘
# â•‘   Latency(ms)  11.20        12.8         -1.60ms  -12.5%   âœ… â•‘
# â•‘   FLOPs(G)     48.30        52.4         -4.10G   -7.8%    âœ… â•‘
# â•‘   Params(M)    9.60         16.3         -6.70M   -41.1%   âœ… â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### éªŒè¯æ ‡å‡†

| æŒ‡æ ‡                                   | é¢„æœŸèŒƒå›´    | è¯´æ˜                                      |
| -------------------------------------- | ----------- | ----------------------------------------- |
| **mAP_small**                          | 15% ~ 18%   | UAV å°ç›®æ ‡ä¸»æˆ˜åœº,ä½äº 15%è¯´æ˜æ¨¡å‹èƒ½åŠ›ä¸è¶³ |
| **mAP_medium**                         | 35% ~ 40%   | ä¸­ç­‰ç›®æ ‡,åº”é«˜äº small                     |
| **mAP_large**                          | 50% ~ 55%   | å¤§ç›®æ ‡,åº”æœ€é«˜                             |
| **mAP_small < mAP_medium < mAP_large** | âœ… å¿…é¡»æ»¡è¶³ | å°ºåº¦é€’å¢è§„å¾‹                              |

---

## ä¿®æ”¹æ–‡ä»¶æ¸…å•

| æ–‡ä»¶                                    | ä¿®æ”¹ç±»å‹    | å…³é”®ä¿®æ”¹ç‚¹                                        |
| --------------------------------------- | ----------- | ------------------------------------------------- |
| `ultralytics/data/dataset.py`           | ğŸ”§ é€»è¾‘å¢å¼º | update_labels_info() + collate_fn()               |
| `ultralytics/data/augment.py`           | ğŸ”§ é€»è¾‘å¢å¼º | Format.**call**()                                 |
| `ultralytics/models/yolo/detect/val.py` | ğŸ”§ æ¶æ„ä¿®æ”¹ | **init**() + \_prepare_batch() + update_metrics() |
| `val_visdrone.py`                       | ğŸ”§ å‚æ•°å¢åŠ  | validate_visdrone()                               |
| `ultralytics/utils/metrics_visdrone.py` | âœ… æ— éœ€ä¿®æ”¹ | é€»è¾‘å·²æ­£ç¡®,ç­‰å¾…æ•°æ®è¾“å…¥                           |

---

## åç»­è¡ŒåŠ¨

### âœ… ç«‹å³éªŒè¯ (æœ¬åœ°)

```bash
python val_visdrone.py --model runs/train/rgbd_v2.1_full/weights/best.pt
```

### âœ… æœåŠ¡å™¨æµ‹è¯• (å¦‚æœæœ¬åœ°é€šè¿‡)

```bash
# ä¸Šä¼ ä¿®æ”¹åçš„æ–‡ä»¶åˆ°æœåŠ¡å™¨
scp ultralytics/data/dataset.py user@server:/path/to/yoloDepth/ultralytics/data/
scp ultralytics/data/augment.py user@server:/path/to/yoloDepth/ultralytics/data/
scp ultralytics/models/yolo/detect/val.py user@server:/path/to/yoloDepth/ultralytics/models/yolo/detect/
scp val_visdrone.py user@server:/path/to/yoloDepth/

# æœåŠ¡å™¨è¿è¡Œ
python val_visdrone.py --model runs/train/rgbd_v2.1_full/weights/best.pt
```

### âœ… å¯¹æ¯” RGB-only vs RGB-D (å¦‚æœä¿®å¤æˆåŠŸ)

```bash
# RGB-Dæ¨¡å‹
python val_visdrone.py --model runs/train/rgbd_v2.1_full/weights/best.pt

# RGB-onlyæ¨¡å‹ (baseline)
python val_visdrone.py --model runs/train/rgb_only/weights/best.pt --data data/visdrone.yaml

# å¯¹æ¯”mAP_smallæ”¹è¿›å¹…åº¦
```

---

## æ˜“é”™ç‚¹è­¦å‘Š âš ï¸

### 1. å½’ä¸€åŒ–åæ ‡çš„é¢ç§¯è®¡ç®—

```python
# âŒ é”™è¯¯: ç›´æ¥ç”¨å½’ä¸€åŒ–åæ ‡è®¡ç®—
areas = (bboxes[:, 2] - bboxes[:, 0]) * (bboxes[:, 3] - bboxes[:, 1])
# ç»“æœ: area < 1 (å› ä¸ºå½’ä¸€åŒ–åˆ°0~1), å…¨éƒ¨è¢«åˆ†ç±»ä¸ºsmall

# âœ… æ­£ç¡®: å…ˆåå½’ä¸€åŒ–
if normalized:
    widths = widths * img_w
    heights = heights * img_h
areas = widths * heights  # åƒç´ é¢ç§¯
```

### 2. Collate æ—¶çš„æ‹¼æ¥æ–¹å¼

```python
# âŒ é”™è¯¯: ä½¿ç”¨stack (ä¼šå¢åŠ ç»´åº¦)
if k == "target_areas":
    value = torch.stack(value, 0)  # shape: [batch, num_boxes]

# âœ… æ­£ç¡®: ä½¿ç”¨cat (ä¸bboxes/clsä¸€è‡´)
if k in {"bboxes", "cls", "target_areas"}:
    value = torch.cat(value, 0)  # shape: [total_boxes]
```

### 3. Validator ä¸­çš„ batch_idx è¿‡æ»¤

```python
# âŒ é”™è¯¯: å¿˜è®°è¿‡æ»¤areas
target_areas = batch["target_areas"]  # å…¨batchçš„areas

# âœ… æ­£ç¡®: æ ¹æ®batch_idxè¿‡æ»¤
idx = batch["batch_idx"] == si
target_areas = batch["target_areas"][idx]  # å½“å‰å›¾ç‰‡çš„areas
```

---

## å…«è‚¡çŸ¥è¯†ç‚¹å…³è”

æœ¬æ¬¡ä¿®å¤æ¶‰åŠçš„æ ¸å¿ƒæ¦‚å¿µ:

- **[024] Validator ä¸ Metrics çš„åä½œæœºåˆ¶** (å¾…æ·»åŠ åˆ°å…«è‚¡.md)
- **[025] YOLO æ•°æ®æµ: Dataset â†’ Augment â†’ Collate â†’ Validator** (å¾…æ·»åŠ )
- **[026] Tensor æ‹¼æ¥: stack vs cat çš„åŒºåˆ«** (å¾…æ·»åŠ )

---

## æˆåŠŸæ ‡å¿—

å½“çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºæ—¶,bug å·²å®Œå…¨ä¿®å¤:

```
Small (<32Ã—32):   15.20%  (vs RemDet 21.3%, Gap: -28.6%)
Medium (32~64):   35.80%  (vs RemDet N/A)
Large (>64Ã—64):   52.30%  (vs RemDet N/A)
```

**é¢„æœŸæ”¹è¿›**: RGB-D çš„ mAP_small åº”æ¯” RGB-only **æå‡ 2-3%** (å¦‚æœæ·±åº¦ä¿¡æ¯æœ‰æ•ˆ)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.1  
**æœ€åæ›´æ–°**: 2025/01/XX  
**ä¿®å¤äºº**: AI Copilot
