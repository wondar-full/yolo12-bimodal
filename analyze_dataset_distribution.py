#!/usr/bin/env python3
"""
VisDroneæ•°æ®é›†ç›®æ ‡å°ºå¯¸åˆ†å¸ƒç»Ÿè®¡è„šæœ¬
æŒ‰ç…§COCOæ ‡å‡†å’Œè‡ªå®šä¹‰é˜ˆå€¼åˆ†æè®­ç»ƒé›†/éªŒè¯é›†çš„Small/Medium/Largeç›®æ ‡åˆ†å¸ƒ
"""

import os
import yaml
import numpy as np
from pathlib import Path
from collections import defaultdict
import matplotlib.pyplot as plt
from tqdm import tqdm


class DatasetAnalyzer:
    """æ•°æ®é›†ç›®æ ‡å°ºå¯¸åˆ†å¸ƒåˆ†æå™¨"""
    
    def __init__(self, data_yaml_path, img_size=640):
        """
        Args:
            data_yaml_path: æ•°æ®é›†YAMLé…ç½®æ–‡ä»¶è·¯å¾„
            img_size: è®­ç»ƒ/éªŒè¯æ—¶çš„å›¾åƒå°ºå¯¸
        """
        self.img_size = img_size
        self.data_yaml_path = Path(data_yaml_path)
        
        # åŠ è½½æ•°æ®é›†é…ç½®
        with open(data_yaml_path, 'r', encoding='utf-8') as f:
            self.data_config = yaml.safe_load(f)
        
        # è·å–æ•°æ®é›†æ ¹ç›®å½• (å¤„ç†å¯èƒ½çš„åˆ—è¡¨æ ¼å¼)
        path_value = self.data_config.get('path', '.')
        if isinstance(path_value, list):
            # YAMLä¸­pathå¯èƒ½æ˜¯å¤šè¡Œå†™æ³•,å–ç¬¬ä¸€ä¸ªéç©ºå€¼
            self.data_root = Path([p for p in path_value if p][0])
        else:
            self.data_root = Path(path_value)
        
        # COCOæ ‡å‡†é˜ˆå€¼
        self.coco_small_thresh = 32 * 32  # 1024
        self.coco_medium_thresh = 96 * 96  # 9216
        
        # è‡ªå®šä¹‰é˜ˆå€¼ (ç”¨äºå¯¹æ¯”)
        self.custom_small_thresh = 32 * 32  # 1024
        self.custom_medium_thresh = 64 * 64  # 4096
        
        print(f"ğŸ“ æ•°æ®é›†æ ¹ç›®å½•: {self.data_root}")
        print(f"ğŸ“ è®­ç»ƒå›¾åƒå°ºå¯¸: {img_size}Ã—{img_size}")
        print(f"\nğŸ“ COCOæ ‡å‡†é˜ˆå€¼:")
        print(f"  Small:  area < {self.coco_small_thresh} (<{int(np.sqrt(self.coco_small_thresh))}Ã—{int(np.sqrt(self.coco_small_thresh))})")
        print(f"  Medium: {self.coco_small_thresh} â‰¤ area < {self.coco_medium_thresh} ({int(np.sqrt(self.coco_small_thresh))}Ã—{int(np.sqrt(self.coco_small_thresh))} ~ {int(np.sqrt(self.coco_medium_thresh))}Ã—{int(np.sqrt(self.coco_medium_thresh))})")
        print(f"  Large:  area â‰¥ {self.coco_medium_thresh} (â‰¥{int(np.sqrt(self.coco_medium_thresh))}Ã—{int(np.sqrt(self.coco_medium_thresh))})")
        print(f"\nğŸ“ è‡ªå®šä¹‰é˜ˆå€¼ (VisDroneä¼˜åŒ–):")
        print(f"  Small:  area < {self.custom_small_thresh} (<{int(np.sqrt(self.custom_small_thresh))}Ã—{int(np.sqrt(self.custom_small_thresh))})")
        print(f"  Medium: {self.custom_small_thresh} â‰¤ area < {self.custom_medium_thresh} ({int(np.sqrt(self.custom_small_thresh))}Ã—{int(np.sqrt(self.custom_small_thresh))} ~ {int(np.sqrt(self.custom_medium_thresh))}Ã—{int(np.sqrt(self.custom_medium_thresh))})")
        print(f"  Large:  area â‰¥ {self.custom_medium_thresh} (â‰¥{int(np.sqrt(self.custom_medium_thresh))}Ã—{int(np.sqrt(self.custom_medium_thresh))})")
    
    def analyze_split(self, split='train'):
        """
        åˆ†ææŒ‡å®šæ•°æ®é›†åˆ’åˆ† (train/val/test)
        
        Args:
            split: 'train' or 'val' or 'test'
            
        Returns:
            dict: ç»Ÿè®¡ç»“æœ
        """
        print(f"\n{'='*80}")
        print(f"ğŸ” åˆ†æ {split.upper()} æ•°æ®é›†")
        print(f"{'='*80}")
        
        # æ ¹æ®YAMLé…ç½®è·å–è·¯å¾„
        if split == 'train':
            img_rel_path = self.data_config.get('train', 'images/train')
        elif split == 'val':
            img_rel_path = self.data_config.get('val', 'images/val')
        elif split == 'test':
            img_rel_path = self.data_config.get('test', 'images/test')
        else:
            raise ValueError(f"Unknown split: {split}")
        
        # æ¨æ–­æ ‡ç­¾è·¯å¾„
        # ä¾‹å¦‚: VisDrone2019-DET-train/images/rgb -> VisDrone2019-DET-train/labels
        # é€šç”¨è§„åˆ™: æ›¿æ¢ /images/xxx ä¸º /labels
        label_rel_path = img_rel_path
        if '/images/' in label_rel_path:
            # æ‰¾åˆ°/images/çš„ä½ç½®,æ›¿æ¢åé¢çš„éƒ¨åˆ†
            parts = label_rel_path.split('/images/')
            label_rel_path = parts[0] + '/labels'
        elif '\\images\\' in label_rel_path:
            parts = label_rel_path.split('\\images\\')
            label_rel_path = parts[0] + '\\labels'
        else:
            # å¦‚æœè·¯å¾„ä¸­æ²¡æœ‰images,å°è¯•ç›´æ¥æ›¿æ¢
            label_rel_path = label_rel_path.replace('images', 'labels')
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        img_dir = self.data_root / img_rel_path
        label_dir = self.data_root / label_rel_path
        
        print(f"ğŸ“‚ å›¾åƒç›®å½•: {img_dir}")
        print(f"ğŸ“‚ æ ‡ç­¾ç›®å½•: {label_dir}")
        
        if not label_dir.exists():
            print(f"âŒ æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {label_dir}")
            return None
        
        if not img_dir.exists():
            print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {img_dir}")
            return None
        
        # æ”¶é›†æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
        label_files = list(label_dir.glob('*.txt'))
        print(f"ğŸ“„ æ‰¾åˆ° {len(label_files)} ä¸ªæ ‡ç­¾æ–‡ä»¶")
        
        if len(label_files) == 0:
            print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶!")
            return None
        
        # ç»Ÿè®¡æ•°æ®
        stats_coco = {
            'small': [],
            'medium': [],
            'large': [],
            'areas': [],
            'widths': [],
            'heights': []
        }
        
        stats_custom = {
            'small': [],
            'medium': [],
            'large': [],
        }
        
        total_objects = 0
        total_images = 0
        images_with_objects = 0
        
        # éå†æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
        for label_file in tqdm(label_files, desc=f"å¤„ç†{split}æ ‡ç­¾"):
            total_images += 1
            
            # è·å–å¯¹åº”çš„å›¾åƒæ–‡ä»¶
            img_file = img_dir / label_file.with_suffix('.jpg').name
            if not img_file.exists():
                img_file = img_dir / label_file.with_suffix('.png').name
            
            if not img_file.exists():
                continue
            
            # è¯»å–å›¾åƒå°ºå¯¸
            from PIL import Image
            try:
                with Image.open(img_file) as img:
                    img_w, img_h = img.size
            except:
                # å¦‚æœè¯»å–å¤±è´¥,å‡è®¾æ˜¯640Ã—640
                img_w, img_h = self.img_size, self.img_size
            
            # è¯»å–æ ‡ç­¾
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            if len(lines) == 0:
                continue
            
            images_with_objects += 1
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) < 5:
                    continue
                
                # YOLOæ ¼å¼: class x_center y_center width height (å½’ä¸€åŒ–)
                cls_id = int(parts[0])
                x_center, y_center, w_norm, h_norm = map(float, parts[1:5])
                
                # è½¬æ¢ä¸ºåƒç´ å°ºå¯¸ (resizeåˆ°è®­ç»ƒå°ºå¯¸)
                # å‡è®¾è®­ç»ƒæ—¶ä¼šresizeåˆ°img_sizeÃ—img_size
                w_pixel = w_norm * self.img_size
                h_pixel = h_norm * self.img_size
                area = w_pixel * h_pixel
                
                total_objects += 1
                
                # è®°å½•åŸå§‹æ•°æ®
                stats_coco['areas'].append(area)
                stats_coco['widths'].append(w_pixel)
                stats_coco['heights'].append(h_pixel)
                
                # COCOæ ‡å‡†åˆ†ç±»
                if area < self.coco_small_thresh:
                    stats_coco['small'].append(area)
                elif area < self.coco_medium_thresh:
                    stats_coco['medium'].append(area)
                else:
                    stats_coco['large'].append(area)
                
                # è‡ªå®šä¹‰é˜ˆå€¼åˆ†ç±»
                if area < self.custom_small_thresh:
                    stats_custom['small'].append(area)
                elif area < self.custom_medium_thresh:
                    stats_custom['medium'].append(area)
                else:
                    stats_custom['large'].append(area)
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        self._print_statistics(split, stats_coco, stats_custom, total_objects, 
                              total_images, images_with_objects)
        
        return {
            'stats_coco': stats_coco,
            'stats_custom': stats_custom,
            'total_objects': total_objects,
            'total_images': total_images,
            'images_with_objects': images_with_objects
        }
    
    def _print_statistics(self, split, stats_coco, stats_custom, total_objects, 
                         total_images, images_with_objects):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š {split.upper()} æ•°æ®é›†ç»Ÿè®¡ç»“æœ")
        print(f"{'='*80}")
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»å›¾åƒæ•°: {total_images}")
        print(f"  æœ‰ç›®æ ‡çš„å›¾åƒ: {images_with_objects} ({100*images_with_objects/total_images:.1f}%)")
        print(f"  æ€»ç›®æ ‡æ•°: {total_objects}")
        print(f"  å¹³å‡æ¯å¼ å›¾åƒç›®æ ‡æ•°: {total_objects/images_with_objects:.1f}")
        
        # é¢ç§¯ç»Ÿè®¡
        areas = np.array(stats_coco['areas'])
        print(f"\nğŸ“ ç›®æ ‡é¢ç§¯ç»Ÿè®¡ (pixelsÂ²):")
        print(f"  æœ€å°: {areas.min():.1f}")
        print(f"  æœ€å¤§: {areas.max():.1f}")
        print(f"  å¹³å‡: {areas.mean():.1f}")
        print(f"  ä¸­ä½æ•°: {np.median(areas):.1f}")
        print(f"  25%åˆ†ä½: {np.percentile(areas, 25):.1f}")
        print(f"  75%åˆ†ä½: {np.percentile(areas, 75):.1f}")
        
        # å®½é«˜ç»Ÿè®¡
        widths = np.array(stats_coco['widths'])
        heights = np.array(stats_coco['heights'])
        print(f"\nğŸ“ ç›®æ ‡å°ºå¯¸ç»Ÿè®¡ (pixels):")
        print(f"  å®½åº¦: min={widths.min():.1f}, max={widths.max():.1f}, mean={widths.mean():.1f}")
        print(f"  é«˜åº¦: min={heights.min():.1f}, max={heights.max():.1f}, mean={heights.mean():.1f}")
        print(f"  é•¿å®½æ¯”: min={(widths/heights).min():.2f}, max={(widths/heights).max():.2f}, mean={(widths/heights).mean():.2f}")
        
        # COCOæ ‡å‡†ç»Ÿè®¡
        n_small_coco = len(stats_coco['small'])
        n_medium_coco = len(stats_coco['medium'])
        n_large_coco = len(stats_coco['large'])
        
        print(f"\nğŸ“Š COCOæ ‡å‡† (32Â²/96Â²) å°ºå¯¸åˆ†å¸ƒ:")
        print(f"  Small  (<32Ã—32):   {n_small_coco:>6} ({100*n_small_coco/total_objects:>5.1f}%)")
        print(f"  Medium (32~96):    {n_medium_coco:>6} ({100*n_medium_coco/total_objects:>5.1f}%)")
        print(f"  Large  (â‰¥96Ã—96):   {n_large_coco:>6} ({100*n_large_coco/total_objects:>5.1f}%)")
        print(f"  æ€»è®¡:              {total_objects:>6} (100.0%)")
        
        # è‡ªå®šä¹‰é˜ˆå€¼ç»Ÿè®¡
        n_small_custom = len(stats_custom['small'])
        n_medium_custom = len(stats_custom['medium'])
        n_large_custom = len(stats_custom['large'])
        
        print(f"\nğŸ“Š VisDroneä¼˜åŒ– (32Â²/64Â²) å°ºå¯¸åˆ†å¸ƒ:")
        print(f"  Small  (<32Ã—32):   {n_small_custom:>6} ({100*n_small_custom/total_objects:>5.1f}%)")
        print(f"  Medium (32~64):    {n_medium_custom:>6} ({100*n_medium_custom/total_objects:>5.1f}%)")
        print(f"  Large  (â‰¥64Ã—64):   {n_large_custom:>6} ({100*n_large_custom/total_objects:>5.1f}%)")
        print(f"  æ€»è®¡:              {total_objects:>6} (100.0%)")
        
        # å¯¹æ¯”åˆ†æ
        print(f"\nğŸ“ˆ é˜ˆå€¼å¯¹æ¯”åˆ†æ:")
        print(f"  Largeç›®æ ‡æ•°é‡:")
        print(f"    COCOæ ‡å‡† (96Â²): {n_large_coco:>6} ({100*n_large_coco/total_objects:>5.1f}%)")
        print(f"    VisDrone (64Â²): {n_large_custom:>6} ({100*n_large_custom/total_objects:>5.1f}%)")
        print(f"    å¢åŠ å€æ•°: {n_large_custom/n_large_coco if n_large_coco > 0 else 'N/A'}Ã—")
        
        # è­¦å‘Šä¿¡æ¯
        if n_large_coco < 100:
            print(f"\nâš ï¸  è­¦å‘Š: COCOæ ‡å‡†ä¸‹Largeç›®æ ‡ä»…{n_large_coco}ä¸ª(<100), ç»Ÿè®¡ä¸å¯é !")
        if n_large_coco / total_objects < 0.01:
            print(f"âš ï¸  è­¦å‘Š: Largeç›®æ ‡å æ¯”{100*n_large_coco/total_objects:.1f}%(<1%), å»ºè®®è°ƒæ•´é˜ˆå€¼!")
    
    def plot_distribution(self, train_result, val_result, save_path='distribution_analysis.png'):
        """
        ç»˜åˆ¶æ•°æ®åˆ†å¸ƒå¯¹æ¯”å›¾
        
        Args:
            train_result: è®­ç»ƒé›†ç»Ÿè®¡ç»“æœ
            val_result: éªŒè¯é›†ç»Ÿè®¡ç»“æœ
            save_path: ä¿å­˜è·¯å¾„
        """
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('VisDrone Dataset Size Distribution Analysis', fontsize=16, fontweight='bold')
        
        # æå–æ•°æ®
        train_coco = train_result['stats_coco']
        train_custom = train_result['stats_custom']
        val_coco = val_result['stats_coco']
        val_custom = val_result['stats_custom']
        
        # 1. COCOæ ‡å‡† - è®­ç»ƒé›†
        ax = axes[0, 0]
        sizes_coco_train = [len(train_coco['small']), len(train_coco['medium']), len(train_coco['large'])]
        labels = ['Small\n(<32Ã—32)', 'Medium\n(32~96)', 'Large\n(â‰¥96Ã—96)']
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        ax.pie(sizes_coco_train, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        ax.set_title('Train Set - COCO Standard', fontsize=12, fontweight='bold')
        
        # 2. COCOæ ‡å‡† - éªŒè¯é›†
        ax = axes[0, 1]
        sizes_coco_val = [len(val_coco['small']), len(val_coco['medium']), len(val_coco['large'])]
        ax.pie(sizes_coco_val, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        ax.set_title('Val Set - COCO Standard', fontsize=12, fontweight='bold')
        
        # 3. COCO vs VisDroneå¯¹æ¯”
        ax = axes[0, 2]
        x = np.arange(3)
        width = 0.35
        train_coco_nums = [len(train_coco['small']), len(train_coco['medium']), len(train_coco['large'])]
        train_custom_nums = [len(train_custom['small']), len(train_custom['medium']), len(train_custom['large'])]
        ax.bar(x - width/2, train_coco_nums, width, label='COCO (96Â²)', color='#FF6B6B', alpha=0.8)
        ax.bar(x + width/2, train_custom_nums, width, label='VisDrone (64Â²)', color='#45B7D1', alpha=0.8)
        ax.set_xlabel('Object Size')
        ax.set_ylabel('Number of Objects')
        ax.set_title('Train Set - Threshold Comparison', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(['Small', 'Medium', 'Large'])
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        
        # 4. VisDroneä¼˜åŒ– - è®­ç»ƒé›†
        ax = axes[1, 0]
        sizes_custom_train = [len(train_custom['small']), len(train_custom['medium']), len(train_custom['large'])]
        labels_custom = ['Small\n(<32Ã—32)', 'Medium\n(32~64)', 'Large\n(â‰¥64Ã—64)']
        ax.pie(sizes_custom_train, labels=labels_custom, colors=colors, autopct='%1.1f%%', startangle=90)
        ax.set_title('Train Set - VisDrone Optimized', fontsize=12, fontweight='bold')
        
        # 5. VisDroneä¼˜åŒ– - éªŒè¯é›†
        ax = axes[1, 1]
        sizes_custom_val = [len(val_custom['small']), len(val_custom['medium']), len(val_custom['large'])]
        ax.pie(sizes_custom_val, labels=labels_custom, colors=colors, autopct='%1.1f%%', startangle=90)
        ax.set_title('Val Set - VisDrone Optimized', fontsize=12, fontweight='bold')
        
        # 6. é¢ç§¯åˆ†å¸ƒç›´æ–¹å›¾
        ax = axes[1, 2]
        all_areas_train = np.array(train_coco['areas'])
        all_areas_val = np.array(val_coco['areas'])
        bins = np.logspace(0, 5, 50)  # å¯¹æ•°åˆ»åº¦
        ax.hist(all_areas_train, bins=bins, alpha=0.5, label='Train', color='#FF6B6B', edgecolor='black')
        ax.hist(all_areas_val, bins=bins, alpha=0.5, label='Val', color='#45B7D1', edgecolor='black')
        ax.axvline(x=1024, color='red', linestyle='--', label='Small/Medium (32Â²)', linewidth=2)
        ax.axvline(x=4096, color='orange', linestyle='--', label='VisDrone (64Â²)', linewidth=2)
        ax.axvline(x=9216, color='green', linestyle='--', label='COCO (96Â²)', linewidth=2)
        ax.set_xscale('log')
        ax.set_xlabel('Object Area (pixelsÂ², log scale)')
        ax.set_ylabel('Frequency')
        ax.set_title('Area Distribution Histogram', fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"\nğŸ“Š åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")
        plt.close()
    
    def generate_report(self, train_result, val_result, save_path='dataset_report.txt'):
        """
        ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š
        
        Args:
            train_result: è®­ç»ƒé›†ç»Ÿè®¡ç»“æœ
            val_result: éªŒè¯é›†ç»Ÿè®¡ç»“æœ
            save_path: ä¿å­˜è·¯å¾„
        """
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("VisDrone Dataset Size Distribution Report\n")
            f.write("="*80 + "\n\n")
            
            # è®­ç»ƒé›†ç»Ÿè®¡
            f.write("TRAINING SET\n")
            f.write("-"*80 + "\n")
            self._write_split_stats(f, train_result, 'train')
            
            f.write("\n" + "="*80 + "\n\n")
            
            # éªŒè¯é›†ç»Ÿè®¡
            f.write("VALIDATION SET\n")
            f.write("-"*80 + "\n")
            self._write_split_stats(f, val_result, 'val')
            
            f.write("\n" + "="*80 + "\n")
            f.write("RECOMMENDATIONS\n")
            f.write("="*80 + "\n\n")
            
            # åˆ†æLargeç›®æ ‡å æ¯”
            train_large_coco = len(train_result['stats_coco']['large'])
            val_large_coco = len(val_result['stats_coco']['large'])
            train_total = train_result['total_objects']
            val_total = val_result['total_objects']
            
            train_large_pct = 100 * train_large_coco / train_total
            val_large_pct = 100 * val_large_coco / val_total
            
            if val_large_pct < 1.0:
                f.write(f"âš ï¸  CRITICAL: Val set has only {val_large_coco} large objects ({val_large_pct:.1f}%)\n")
                f.write(f"   This is statistically unreliable for evaluation!\n\n")
                f.write(f"ğŸ’¡ RECOMMENDATION: Use VisDrone optimized threshold (64Â²) instead\n")
                f.write(f"   - This will increase large objects to ~{len(val_result['stats_custom']['large'])} ")
                f.write(f"({100*len(val_result['stats_custom']['large'])/val_total:.1f}%)\n")
                f.write(f"   - More reliable for statistical evaluation\n")
                f.write(f"   - Better reflects UAV detection scenarios\n\n")
            
            if train_large_pct < 5.0:
                f.write(f"âš ï¸  WARNING: Train set has only {train_large_pct:.1f}% large objects\n")
                f.write(f"   Model may not learn large object detection well\n\n")
                f.write(f"ğŸ’¡ RECOMMENDATION: Consider data augmentation for large objects\n")
                f.write(f"   - Random crop & zoom\n")
                f.write(f"   - Copy-paste augmentation\n\n")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")
    
    def _write_split_stats(self, f, result, split):
        """å†™å…¥å•ä¸ªæ•°æ®é›†åˆ’åˆ†çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats_coco = result['stats_coco']
        stats_custom = result['stats_custom']
        total = result['total_objects']
        
        f.write(f"Total images: {result['total_images']}\n")
        f.write(f"Images with objects: {result['images_with_objects']}\n")
        f.write(f"Total objects: {total}\n\n")
        
        f.write("COCO Standard (32Â²/96Â²):\n")
        f.write(f"  Small  (<32Ã—32):  {len(stats_coco['small']):>6} ({100*len(stats_coco['small'])/total:>5.1f}%)\n")
        f.write(f"  Medium (32~96):   {len(stats_coco['medium']):>6} ({100*len(stats_coco['medium'])/total:>5.1f}%)\n")
        f.write(f"  Large  (â‰¥96Ã—96):  {len(stats_coco['large']):>6} ({100*len(stats_coco['large'])/total:>5.1f}%)\n\n")
        
        f.write("VisDrone Optimized (32Â²/64Â²):\n")
        f.write(f"  Small  (<32Ã—32):  {len(stats_custom['small']):>6} ({100*len(stats_custom['small'])/total:>5.1f}%)\n")
        f.write(f"  Medium (32~64):   {len(stats_custom['medium']):>6} ({100*len(stats_custom['medium'])/total:>5.1f}%)\n")
        f.write(f"  Large  (â‰¥64Ã—64):  {len(stats_custom['large']):>6} ({100*len(stats_custom['large'])/total:>5.1f}%)\n\n")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åˆ†æVisDroneæ•°æ®é›†çš„ç›®æ ‡å°ºå¯¸åˆ†å¸ƒ')
    parser.add_argument('--data', type=str, default='data/visdrone-rgbd.yaml',
                       help='æ•°æ®é›†YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--img-size', type=int, default=640,
                       help='è®­ç»ƒ/éªŒè¯å›¾åƒå°ºå¯¸')
    parser.add_argument('--save-dir', type=str, default='.',
                       help='ç»“æœä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DatasetAnalyzer(args.data, args.img_size)
    
    # åˆ†æè®­ç»ƒé›†
    print("\n" + "="*80)
    print("å¼€å§‹åˆ†ææ•°æ®é›†...")
    print("="*80)
    
    train_result = analyzer.analyze_split('train')
    val_result = analyzer.analyze_split('val')
    
    if train_result and val_result:
        # ç»˜åˆ¶åˆ†å¸ƒå›¾
        save_dir = Path(args.save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        plot_path = save_dir / 'distribution_analysis.png'
        analyzer.plot_distribution(train_result, val_result, plot_path)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = save_dir / 'dataset_report.txt'
        analyzer.generate_report(train_result, val_result, report_path)
        
        print("\n" + "="*80)
        print("âœ… åˆ†æå®Œæˆ!")
        print("="*80)
        print(f"ğŸ“Š å¯è§†åŒ–ç»“æœ: {plot_path}")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        print("\nğŸ’¡ å»ºè®®:")
        
        val_large_coco = len(val_result['stats_coco']['large'])
        val_total = val_result['total_objects']
        val_large_pct = 100 * val_large_coco / val_total
        
        if val_large_pct < 1.0:
            print(f"âš ï¸  éªŒè¯é›†Largeç›®æ ‡ä»…{val_large_coco}ä¸ª({val_large_pct:.1f}%), ç»Ÿè®¡ä¸å¯é !")
            print(f"ğŸ’¡ å»ºè®®ä½¿ç”¨VisDroneä¼˜åŒ–é˜ˆå€¼(64Â²), Largeç›®æ ‡å°†å¢åŠ åˆ°{len(val_result['stats_custom']['large'])}ä¸ª")
            print(f"   ({100*len(val_result['stats_custom']['large'])/val_total:.1f}%)")
    else:
        print("\nâŒ æ•°æ®é›†åˆ†æå¤±è´¥, è¯·æ£€æŸ¥è·¯å¾„é…ç½®!")


if __name__ == '__main__':
    main()
