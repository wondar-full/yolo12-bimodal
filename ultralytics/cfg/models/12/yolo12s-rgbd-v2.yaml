# Ultralytics YOLO üöÄ, AGPL-3.0 license
# YOLO12-S RGB-D v2.0 - Enhanced Multi-Scale Fusion
# Created: 2025-10-26 for yoloDepth project
# Target: Surpass RemDet (AAAI2025) with aggressive RGB-D fusion

# ================================================================================================
# Key Improvements over v1.0
# ================================================================================================
# 1. Multi-scale RGB-D fusion at P3/P4/P5 (not just Layer 0)
# 2. Depth feature reuse through skip connections
# 3. RemDet-inspired lightweight design (fewer params, higher mAP)
# 4. Optimized for small objects (VisDrone's 68.2% small target challenge)

# ================================================================================================
# Model Configuration
# ================================================================================================
nc: 10 # Number of classes (VisDrone: 10 classes)

# Model compound scaling constants
scales:
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # nano
  s: [0.50, 0.50, 1024] # small - **RGB-D v2 baseline**
  m: [0.50, 1.00, 512] # medium
  l: [1.00, 1.00, 512] # large
  x: [1.00, 1.50, 512] # extra-large

# ================================================================================================
# Backbone (Feature Extractor) - Multi-Scale RGB-D Fusion
# ================================================================================================
# Strategy:
# 1. Layer 0: RGBDStem (early fusion)
# 2. Save depth features at each scale (P2/P3/P4/P5)
# 3. Fuse depth in backbone P3/P4/P5 for multi-scale enhancement

backbone:
  # [from, repeats, module, args]

  # ============ P1/2 Stage (640‚Üí320) ============
  # Layer 0: RGB-D Dual-Branch Stem
  # Output: [fused 64ch, depth 64ch] = 128ch total
  - [-1, 1, RGBDStem, [4, 128, 3, 2, 1, 64, "gated_add", 16, True]] # 0-P1/2

  # ============ P2/4 Stage (320‚Üí160) ============
  # Layer 1-2: Standard processing
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4 (downsample)
  - [-1, 2, C3k2, [256, False, 0.25]] # 2 (feature extraction)

  # ============ P3/8 Stage (160‚Üí80) ============
  # Layer 3: Downsample to P3
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8

  # Layer 4: Extract depth features for P3 fusion
  # Split Layer 0's output: use depth branch (channels 64-128)
  # TODO: Need custom splitter module or modify C3k2 to accept RGB-D
  - [-1, 2, C3k2, [512, False, 0.25]] # 4-P3 features

  # ============ P4/16 Stage (80‚Üí40) ============
  # Layer 5: Downsample to P4
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16

  # Layer 6: A2C2f with potential depth fusion
  - [-1, 4, A2C2f, [512, True, 4]] # 6-P4 features

  # ============ P5/32 Stage (40‚Üí20) ============
  # Layer 7: Downsample to P5
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32

  # Layer 8: A2C2f for P5
  - [-1, 4, A2C2f, [1024, True, 1]] # 8-P5 features

# ================================================================================================
# Head (Detection Neck + Prediction) - Enhanced FPN
# ================================================================================================
# RemDet insight: Lightweight neck is crucial for speed
# Keep standard structure but consider depth-aware attention in future

head:
  # ============ Upsample Path (Top-Down) ============
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 9
  - [[-1, 6], 1, Concat, [1]] # 10 - cat backbone P4
  - [-1, 2, A2C2f, [512, False, -1]] # 11

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 12
  - [[-1, 4], 1, Concat, [1]] # 13 - cat backbone P3
  - [-1, 2, A2C2f, [256, False, -1]] # 14 (P3/8-small)

  # ============ Downsample Path (Bottom-Up) ============
  - [-1, 1, Conv, [256, 3, 2]] # 15
  - [[-1, 11], 1, Concat, [1]] # 16 - cat head P4
  - [-1, 2, A2C2f, [512, False, -1]] # 17 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]] # 18
  - [[-1, 8], 1, Concat, [1]] # 19 - cat head P5
  - [-1, 2, C3k2, [1024, True]] # 20 (P5/32-large)

  # ============ Detection Heads ============
  - [[14, 17, 20], 1, Detect, [nc]] # 21 - Detect(P3, P4, P5)

# ================================================================================================
# v2.0 Limitations (To be addressed in v2.1+)
# ================================================================================================
# Current v2.0 still has issues:
# 1. Depth features from Layer 0 are not explicitly propagated to P3/P4/P5
# 2. No custom fusion module at multi-scales (just standard Concat)
# 3. Lacks RemDet's ChannelC2f and GatedFFN innovations
#
# Why v2.0 is still conservative:
# - First test if multi-scale concatenation helps
# - Avoid too many custom modules at once (debugging nightmare)
# - Establish baseline before adding advanced techniques
#
# Expected v2.0 performance:
# - mAP@0.5: 39-40% (similar to v1.0, maybe +1-2%)
# - Reason: Depth info still "diluted" after Layer 0
#
# Recommended next steps:
# 1. Create RGBDMidFusion module for P3/P4/P5
# 2. Add depth skip connections (preserve depth features)
# 3. Integrate RemDet's ChannelC2f (9x expansion)
# 4. Add SOLR loss for small objects

# ================================================================================================
# Training Hyperparameters (Same as v1.0)
# ================================================================================================
# optimizer: SGD (momentum=0.937, weight_decay=0.0005)
# lr_scheduler: CosineAnnealing
# initial_lr: 0.01
# warmup_epochs: 3
# total_epochs: 300
# batch_size: 16
# mosaic: 1.0
# mixup: 0.15

# ================================================================================================
# Version History
# ================================================================================================
# v1.0 (2025-10-26 14:00): Initial RGB-D baseline
#   - RGBDStem at Layer 0 only
#   - Result: 30.86% mAP@0.5 @ 10 epochs (projected 41% @ 300 epochs)
#   - Limitation: Depth features not utilized in later layers
#
# v2.0 (2025-10-26 20:30): Conceptual multi-scale fusion
#   - Same structure as v1.0 (no code changes yet)
#   - Documented plan for depth skip connections
#   - Expected: Minimal improvement without RGBDMidFusion module
#   - Status: **Placeholder for next development phase**

# ================================================================================================
# IMPORTANT NOTE
# ================================================================================================
# ‚ö†Ô∏è This v2.0 YAML is currently IDENTICAL to v1.0 in functionality
#
# Why? Because implementing true multi-scale RGB-D fusion requires:
# 1. New module: RGBDMidFusion (for P3/P4/P5 depth injection)
# 2. Depth skip connection mechanism (preserve depth from Layer 0)
# 3. Modified Concat to handle RGB+Depth streams separately
#
# These will be implemented in the next work session.
# Current v2.0 serves as a DESIGN DOCUMENT for the roadmap.
#
# To actually improve performance, we need:
# - Phase 2: Implement RGBDMidFusion module (like RGBDStem but for intermediate layers)
# - Phase 3: Add RemDet's ChannelC2f (proven +1.8% mAP)
# - Phase 4: Integrate SOLR loss (small object localization refinement)
