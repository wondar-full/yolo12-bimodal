# 多尺寸模型训练指南 (n/s/m/l/x)

**创建日期**: 2025-11-16  
**更新**: 增加多尺寸模型训练支持  
**目标**: 训练 YOLO12 n/s/m/l/x 全系列,对标 RemDet Tiny/S/M/L/X

---

## 📌 重要更正: RemDet-X 基线

⚠️ **之前的目标有误!** 查看 RemDet 论文 Table 1 发现:

| 指标               | 之前说的 | 实际值 (Table 1) |
| ------------------ | -------- | ---------------- |
| RemDet-X AP@val_50 | 45.2%    | **48.3%** ✅     |
| RemDet-X AP@val    | 27%      | **29.9%** ✅     |
| RemDet-X AP@val_s  | 19.5%    | **19.5%** ✅     |

**结论**:

- ✅ `val_uav_joint.py`已更正为 48.3%
- ✅ 目标更具挑战性,但 RGB-D 优势应能弥补
- ✅ 预期我们的 YOLO12-X-RGBD: **49-51% AP@val_50**

---

## 🎯 全尺寸对标策略

| 我们的模型    | 对标 RemDet | AP@val_50 目标        | Params | FLOPs | Batch | 训练时间 |
| ------------- | ----------- | --------------------- | ------ | ----- | ----- | -------- |
| YOLO12-N-RGBD | RemDet-Tiny | **36-38%** (vs 33.5%) | ~3M    | ~8G   | 32    | 1-2 天   |
| YOLO12-S-RGBD | RemDet-S    | **45-47%** (vs 42.3%) | ~11M   | ~46G  | 16    | 2-3 天   |
| YOLO12-M-RGBD | RemDet-M    | **48-50%** (vs 45.0%) | ~22M   | ~92G  | 8     | 3-4 天   |
| YOLO12-L-RGBD | RemDet-L    | **50-52%** (vs 47.4%) | ~44M   | ~184G | 4     | 4-5 天   |
| YOLO12-X-RGBD | RemDet-X    | **49-51%** (vs 48.3%) | ~66M   | ~276G | 2     | 5-6 天   |

**预期优势来源**:

- RGB-D 融合: +3-4% (已在 v2.1 验证)
- 数据扩充: +1.5-2% (VisDrone → VisDrone+UAVDT)
- 总增益: +4.5-6%

---

## 🔧 训练方式

### 方式 1: 单独训练每个模型

```bash
# YOLOv12-S (推荐优先训练)
python train_uav_joint.py \
    --model ultralytics/cfg/models/12/yolo12-rgbd-v2.1-universal.yaml \
    --cfg s \
    --data data/uav-joint-rgbd.yaml \
    --epochs 300 \
    --batch 16 \
    --device 0 \
    --name rgbd_v2.1_s_joint_300ep

# YOLOv12-M
python train_uav_joint.py \
    --model ultralytics/cfg/models/12/yolo12-rgbd-v2.1-universal.yaml \
    --cfg m \
    --data data/uav-joint-rgbd.yaml \
    --epochs 300 \
    --batch 8 \
    --device 0 \
    --name rgbd_v2.1_m_joint_300ep

# YOLOv12-X (终极目标)
python train_uav_joint.py \
    --model ultralytics/cfg/models/12/yolo12-rgbd-v2.1-universal.yaml \
    --cfg x \
    --data data/uav-joint-rgbd.yaml \
    --epochs 300 \
    --batch 2 \
    --device 0 \
    --name rgbd_v2.1_x_joint_300ep

# YOLOv12-N (轻量级)
python train_uav_joint.py \
    --model ultralytics/cfg/models/12/yolo12-rgbd-v2.1-universal.yaml \
    --cfg n \
    --data data/uav-joint-rgbd.yaml \
    --epochs 300 \
    --batch 32 \
    --device 0 \
    --name rgbd_v2.1_n_joint_300ep

# YOLOv12-L (可选)
python train_uav_joint.py \
    --model ultralytics/cfg/models/12/yolo12-rgbd-v2.1-universal.yaml \
    --cfg l \
    --data data/uav-joint-rgbd.yaml \
    --epochs 300 \
    --batch 4 \
    --device 0 \
    --name rgbd_v2.1_l_joint_300ep
```

### 方式 2: 批量训练 (自动化)

**Linux/Mac**:

```bash
chmod +x batch_train_all_sizes.sh
nohup ./batch_train_all_sizes.sh > batch_train.log 2>&1 &

# 查看进度
tail -f batch_train.log
```

**Windows PowerShell**:

```powershell
.\batch_train_all_sizes.ps1
```

---

## 📊 验证与对比

### 单个模型验证

```bash
python val_uav_joint.py \
    --weights runs/train/rgbd_v2.1_s_joint_300ep/weights/best.pt \
    --data data/uav-joint-rgbd.yaml \
    --device 0 \
    --batch 16
```

### 生成对比表格

```bash
# 训练完所有模型后运行
python generate_comparison_table.py
```

**输出**:

- Markdown 表格 (用于 GitHub README)
- LaTeX 表格 (用于论文)
- 改进总结 (胜率统计)
- `performance_comparison.md` 文件

---

## 🎯 训练优先级建议

### 方案 A: 快速验证 (1 周)

只训练**s 模型**验证 RGB-D 优势:

```bash
python train_uav_joint.py --cfg s --batch 16 --epochs 300
```

- 预期: 45-47% vs RemDet-S 42.3% (+3-5%)
- 如果成功 → 继续训练其他尺寸
- 如果失败 → 调整策略(SOLR/更长训练)

### 方案 B: 论文发表 (2 周)

训练**s + m + x**三个模型:

```bash
# 顺序: s → m → x
./batch_train_all_sizes.sh  # 选择只训练s/m/x
```

- 覆盖轻量/中型/大型三个档次
- 对比 RemDet-S/M/X 三个基线
- 足够支撑论文的性能对比表

### 方案 C: 完整实验 (3 周)

训练**n + s + m + l + x**全系列:

```bash
./batch_train_all_sizes.sh  # 全部训练
```

- 最全面的对比
- 适合高水平会议/期刊
- 可分析 RGB-D 优势在不同尺寸的表现

---

## ⚠️ 注意事项

### 1. 显存限制

| 模型 | 推荐 batch | 最小显存 | RTX 4090 可用 batch |
| ---- | ---------- | -------- | ------------------- |
| n    | 32         | 8GB      | 64 (可以更大)       |
| s    | 16         | 12GB     | 24                  |
| m    | 8          | 16GB     | 12                  |
| l    | 4          | 20GB     | 6                   |
| x    | 2          | 22GB     | 4                   |

如果 OOM,降低 batch 并确保`nbs=128`保持梯度累积。

### 2. 训练时间预估

基于 RTX 4090 单卡:

- **总耗时**: 15-20 天 (5 个模型 × 3-4 天平均)
- **并行加速**: 如果有多张卡,可同时训练多个尺寸
- **中断恢复**: 使用`--resume`参数恢复训练

### 3. 性能分析

训练完成后,重点关注:

1. **哪个尺寸 RGB-D 优势最明显?**

   - 预期: 小模型(n/s)优势更大 (深度信息补偿参数不足)
   - 大模型(l/x)优势可能较小 (RGB 特征已足够强)

2. **AP_small 的提升**

   - UAV 场景关键指标
   - 深度信息对小目标帮助最大

3. **效率对比**
   - Latency 是否在可接受范围
   - RGB-D 是否显著拖慢推理

---

## 📚 八股知识点补充

### Q: 为什么 RemDet-X 用 48.3%而不是 45.2%?

**A**: 论文 Table 1 有两个测试集:

- **o (original)**: VisDrone 官方测试集,RemDet-X = 48.3%
- **o+ca (original + COCO-all)**: 加上 COCO 泛化测试,RemDet-X = 45.2%

我们对标的是**VisDrone val set**,应该用**48.3%**!

### Q: 为什么不同尺寸用同一个 YAML?

**A**: YOLOv12 的`scales`机制:

```yaml
scales:
  n: [0.5, 0.25, 1024] # [depth_multiple, width_multiple, max_channels]
  s: [0.5, 0.50, 1024]
  m: [0.5, 1.00, 512]
  l: [1.0, 1.00, 512]
  x: [1.0, 1.50, 512]
```

模型构建时会根据`--cfg`参数自动调整:

- `repeats = base_repeats * depth_multiple`
- `channels = base_channels * width_multiple`
- `channels = min(channels, max_channels)`

这样只需一个 YAML 就能生成 5 个尺寸!

### Q: batch size 和学习率要不要一起调整?

**A**: 理论上需要,但实践中:

- **RemDet**: 所有尺寸统一 lr=0.01
- **我们**: 也用 lr=0.01,但通过 nbs=128 保持梯度累积

原因: effective_lr = lr \* sqrt(batch_size)

- n: batch=32, effective_lr = 0.01 \* sqrt(32/16) = 0.014
- x: batch=2, effective_lr = 0.01 \* sqrt(2/16) = 0.0035

但 nbs=128 让 weight_decay 等保持一致,所以不用手动调整。

---

## 📝 检查清单

训练前:

- [ ] 数据集完整性检查 (`check_dataset_ready.py`)
- [ ] 深度图质量检查 (`check_depth_quality.py`)
- [ ] 确认显存足够 (参考上表)
- [ ] 选择训练方案 (A/B/C)

训练中:

- [ ] 每日检查 loss 曲线
- [ ] 监控 gate_mean (应在 0.3-0.5)
- [ ] 验证无 OOM/NaN 错误
- [ ] 记录异常情况

训练后:

- [ ] 验证所有 best.pt
- [ ] 生成对比表格 (`generate_comparison_table.py`)
- [ ] 分析哪个尺寸优势最明显
- [ ] 撰写改进记录

---

**祝训练顺利!如果有任何问题,随时查阅文档或咨询导师。** 🚀
