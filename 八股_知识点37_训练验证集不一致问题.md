# å…«è‚¡çŸ¥è¯†ç‚¹ #37: è®­ç»ƒé›†ä¸éªŒè¯é›†æ•°æ®ä¸ä¸€è‡´å¯¼è‡´çš„æ€§èƒ½é—®é¢˜

## ğŸ“š æ ‡å‡†æ¡ˆä¾‹

**é—®é¢˜åœºæ™¯**: ä¿®å¤è®­ç»ƒæ•°æ®åé‡æ–°è®­ç»ƒ,ä½†æ€§èƒ½æå‡è¿œä½äºé¢„æœŸ

**å…¸å‹è¡¨ç°**:

- è®­ç»ƒ loss æ­£å¸¸ä¸‹é™
- è®­ç»ƒé›† mAP æå‡æ˜æ˜¾
- **ä½†éªŒè¯é›† mAP å‡ ä¹ä¸å˜æˆ–æå‡æå°**
- æœ€ç»ˆæ¨¡å‹æ€§èƒ½è¿œä½äºç†è®ºå€¼

**æ ¹æœ¬åŸå› **:

> åªä¿®å¤äº†è®­ç»ƒé›†æ•°æ®,è€ŒéªŒè¯é›†/æµ‹è¯•é›†ä»ä½¿ç”¨é”™è¯¯æ•°æ®

## ğŸ” æœ¬é¡¹ç›®åº”ç”¨ - exp_joint_v16 é—®é¢˜è¯Šæ–­

### é—®é¢˜è¡¨ç°

```
ä¿®å¤UAVDTç±»åˆ«ID: 4â†’3, 6â†’5, 9â†’8

é¢„æœŸç»“æœ:
  - mAPä» 19.51% â†’ 40-45% (æå‡ 20-25ä¸ªç™¾åˆ†ç‚¹)

å®é™…ç»“æœ:
  - exp_joint_v15: 19.51% mAP (ä¿®å¤å‰)
  - exp_joint_v16: 20.82% mAP (ä¿®å¤å)
  - å®é™…æå‡: +1.31ä¸ªç™¾åˆ†ç‚¹ âŒ
```

### é—®é¢˜åˆ†æ

**3 å¤§å¯èƒ½åŸå› ** (æŒ‰ä¼˜å…ˆçº§):

#### ğŸ¥‡ åŸå›  1: éªŒè¯é›†æ ‡ç­¾æœªä¿®å¤ â­**æœ€å¯èƒ½**

```bash
# å‡è®¾åœºæ™¯:
è®­ç»ƒé›†: /Datasets/UAVDT_YOLO/train/labels/rgb/
  - å·²ä¿®å¤: ç±»åˆ«IDä¸º 3, 5, 8 âœ…

éªŒè¯é›†: /Datasets/UAVDT_YOLO/val/labels/rgb/
  - æœªä¿®å¤: ç±»åˆ«IDä»ä¸º 4, 6, 9 âŒ

ç»“æœ:
  - æ¨¡å‹å­¦ä¹ : carâ†’3, truckâ†’5, busâ†’8 (æ­£ç¡®)
  - éªŒè¯æ—¶: æ ‡ç­¾æ˜¯ 4, 6, 9 (é”™è¯¯)
  - æ¨¡å‹é¢„æµ‹3è¢«æ ‡ç­¾4åˆ¤ä¸ºé”™è¯¯
  - mAPä¸¥é‡ä½ä¼°!
```

**éªŒè¯æ–¹æ³•**:

```bash
# åœ¨æœåŠ¡å™¨è¿è¡Œ
cd /data2/user/2024/lzy/Datasets/UAVDT_YOLO/val/labels/rgb
find . -name '*.txt' -exec cat {} \; | awk '{print $1}' | sort | uniq -c

# é¢„æœŸ: çœ‹åˆ° 3, 5, 8
# å¼‚å¸¸: å¦‚æœçœ‹åˆ° 4, 6, 9 â†’ éªŒè¯é›†æœªä¿®å¤!
```

#### ğŸ¥ˆ åŸå›  2: æ•°æ®ç¼“å­˜é—®é¢˜

```python
# YOLOæ•°æ®åŠ è½½æœºåˆ¶:
class YOLODataset:
    def __init__(self, img_path, cache=True):
        cache_file = Path(img_path).with_suffix('.cache')

        if cache and cache_file.exists():
            # âš ï¸ ç›´æ¥è¯»å–ç¼“å­˜,ä¸é‡æ–°æ‰«ææ ‡ç­¾!
            self.labels = torch.load(cache_file)
        else:
            # æ­£å¸¸æ‰«æ
            self.labels = self.scan_labels()
            torch.save(self.labels, cache_file)
```

**é—®é¢˜**:

- ä¿®å¤æ ‡ç­¾å‰å·²ç”Ÿæˆ`.cache`æ–‡ä»¶
- ä¿®å¤æ ‡ç­¾å,è®­ç»ƒä»è¯»å–æ—§ç¼“å­˜
- ç›¸å½“äºä¿®å¤æ²¡ç”Ÿæ•ˆ

**è§£å†³æ–¹æ¡ˆ**:

```bash
# åˆ é™¤æ‰€æœ‰ç¼“å­˜
find /data2/user/2024/lzy/Datasets/UAVDT_YOLO -name "*.cache" -delete

# æˆ–è€…è®­ç»ƒæ—¶ç¦ç”¨ç¼“å­˜
python train_depth.py --cache False
```

#### ğŸ¥‰ åŸå›  3: è®­ç»ƒé›†æœªçœŸæ­£ä¿®å¤

**å¯èƒ½æƒ…å†µ**:

- `fix_uavdt_category_ids.py` æœªæ‰§è¡Œ
- è„šæœ¬æ‰§è¡Œå¤±è´¥ä½†æœªæŠ¥é”™
- ä¿®å¤äº†å‰¯æœ¬,è®­ç»ƒè¯»å–çš„æ˜¯åŸå§‹æ•°æ®

**éªŒè¯æ–¹æ³•**:

```bash
cd /data2/user/2024/lzy/Datasets/UAVDT_YOLO/train/labels/rgb
find . -name '*.txt' -exec cat {} \; | awk '{print $1}' | sort | uniq -c

# é¢„æœŸ: 394633 3, 17491 5, 10787 8
# å¼‚å¸¸: 394633 4, 17491 6, 10787 9 â†’ æœªä¿®å¤
```

## ğŸ“ æ·±å…¥è®²è§£

### 1. è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†çš„ä½œç”¨

| æ•°æ®é›†     | ä½œç”¨                            | é¢‘ç‡       | å½±å“             |
| ---------- | ------------------------------- | ---------- | ---------------- |
| **è®­ç»ƒé›†** | ç”¨äºæ¨¡å‹å‚æ•°ä¼˜åŒ–(æ¢¯åº¦ä¸‹é™)      | æ¯ä¸ª batch | ç›´æ¥å½±å“å­¦ä¹ è¿‡ç¨‹ |
| **éªŒè¯é›†** | ç”¨äºè¶…å‚æ•°è°ƒä¼˜å’Œ early stopping | æ¯ä¸ª epoch | é—´æ¥æŒ‡å¯¼è®­ç»ƒ     |
| **æµ‹è¯•é›†** | ç”¨äºæœ€ç»ˆæ€§èƒ½è¯„ä¼°                | è®­ç»ƒç»“æŸ   | å†³å®šæœ€ç»ˆç»“è®º     |

### 2. æ•°æ®ä¸ä¸€è‡´çš„å½±å“

**åœºæ™¯ 1: è®­ç»ƒé›†æ­£ç¡®,éªŒè¯é›†é”™è¯¯**

```
è®­ç»ƒè¿‡ç¨‹:
  Epoch 1: train_loss=2.5, val_loss=3.0, val_mAP=10%
  Epoch 50: train_loss=1.2, val_loss=2.8, val_mAP=15%
  Epoch 100: train_loss=0.9, val_loss=2.7, val_mAP=18%

è¡¨ç°:
  - train_lossæŒç»­ä¸‹é™ âœ…
  - val_lossç¼“æ…¢ä¸‹é™
  - val_mAPå¢é•¿ææ…¢ âŒ

è¯¯åˆ¤:
  - ç ”ç©¶è€…ä»¥ä¸ºæ¨¡å‹ä¸¥é‡è¿‡æ‹Ÿåˆ
  - å®é™…æ˜¯éªŒè¯é›†æ ‡ç­¾é”™è¯¯!
```

**åœºæ™¯ 2: è®­ç»ƒé›†é”™è¯¯,éªŒè¯é›†æ­£ç¡®**

```
è®­ç»ƒè¿‡ç¨‹:
  Epoch 1-100: æ¨¡å‹å­¦ä¹ é”™è¯¯çš„æ˜ å°„å…³ç³»

éªŒè¯è¡¨ç°:
  - val_mAPå§‹ç»ˆå¾ˆä½ (å› ä¸ºå­¦åˆ°äº†é”™è¯¯çŸ¥è¯†)

é—®é¢˜:
  - æ›´éš¾å‘ç°,å› ä¸ºéªŒè¯é›†æ˜¯"æ­£ç¡®"çš„
  - åªæœ‰æ£€æŸ¥è®­ç»ƒæ•°æ®æ‰èƒ½å‘ç°
```

### 3. YOLO ç¼“å­˜æœºåˆ¶è¯¦è§£

**ç¼“å­˜å†…å®¹**:

```python
# .cache æ–‡ä»¶å­˜å‚¨å†…å®¹:
{
    'version': '1.0',
    'hash': '...',  # å›¾åƒç›®å½•çš„hash
    'results': {
        'image1.jpg': {
            'shape': (640, 640),
            'labels': array([[3, 0.5, 0.5, 0.2, 0.3], ...]),  # âš ï¸ åŒ…å«ç±»åˆ«ID
            'segments': [...],
        },
        ...
    }
}
```

**ç¼“å­˜å¤±æ•ˆæ¡ä»¶**:

```python
def get_cache_file(img_path):
    # åªåŸºäºå›¾åƒè·¯å¾„ç”Ÿæˆhash
    cache_path = Path(img_path).with_suffix('.cache')

    # âŒ ä¸æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶ä¿®æ”¹æ—¶é—´!
    # âŒ ä¸æ£€æŸ¥æ ‡ç­¾å†…å®¹hash!
    # âŒ åªè¦.cacheå­˜åœ¨å°±ç›´æ¥ç”¨

    return cache_path
```

**ä¸ºä»€ä¹ˆä¼šå‡ºé—®é¢˜**:

1. é¦–æ¬¡è®­ç»ƒæ—¶ç”Ÿæˆ cache (æ ‡ç­¾ ID=4,6,9)
2. ä¿®æ”¹æ ‡ç­¾æ–‡ä»¶ (ID æ”¹ä¸º 3,5,8)
3. å†æ¬¡è®­ç»ƒæ—¶:
   - YOLO æ£€æµ‹åˆ° cache å­˜åœ¨
   - ç›´æ¥åŠ è½½æ—§ cache (ID ä»æ˜¯ 4,6,9)
   - **ä¿®æ”¹ä¸ç”Ÿæ•ˆ!**

## ğŸ”¥ å¸¸è§è¿½é—®ä¸æ ‡å‡†ç­”æ¡ˆ

### Q1: ä¸ºä»€ä¹ˆä¸åœ¨ä¿®æ”¹æ ‡ç­¾åè‡ªåŠ¨åˆ é™¤ç¼“å­˜?

**A**: YOLO è®¾è®¡æ—¶å‡è®¾æ ‡ç­¾æ˜¯é™æ€çš„

```python
# YOLOå‡è®¾:
# 1. æ•°æ®é›†å‡†å¤‡å¥½åå°±ä¸å†å˜åŒ–
# 2. ç¼“å­˜åŠ é€Ÿé‡å¤è®­ç»ƒ
# 3. ç”¨æˆ·è´Ÿè´£æ•°æ®ä¸€è‡´æ€§

# ä½†å®é™…é¡¹ç›®ä¸­:
# - ç»å¸¸éœ€è¦ä¿®å¤æ ‡ç­¾é”™è¯¯
# - å¯èƒ½å¢é‡æ·»åŠ æ•°æ®
# - éœ€è¦æ‰‹åŠ¨ç®¡ç†ç¼“å­˜
```

### Q2: å¦‚ä½•é¿å…è®­ç»ƒ/éªŒè¯é›†ä¸ä¸€è‡´?

**A**: æ‰¹é‡ä¿®å¤è„šæœ¬ + éªŒè¯æµç¨‹

```python
def fix_dataset_labels(dataset_root, old_ids, new_ids):
    """
    åŒæ—¶ä¿®å¤train/val/testæ‰€æœ‰åˆ†å‰²
    """
    splits = ['train', 'val', 'test']

    for split in splits:
        label_dir = Path(dataset_root) / split / 'labels'
        if not label_dir.exists():
            print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„åˆ†å‰²: {split}")
            continue

        # ä¿®å¤æ ‡ç­¾
        fix_labels(label_dir, old_ids, new_ids)

        # åˆ é™¤ç¼“å­˜
        cache_files = label_dir.parent.glob('*.cache')
        for cache in cache_files:
            cache.unlink()
            print(f"âœ… åˆ é™¤ç¼“å­˜: {cache}")

    # éªŒè¯ä¿®å¤ç»“æœ
    verify_all_splits(dataset_root, new_ids)
```

### Q3: è®­ç»ƒæ—¶å¦‚ä½•æ£€æµ‹æ•°æ®é›†é—®é¢˜?

**A**: ç›‘æ§è®­ç»ƒæ—¥å¿—ä¸­çš„å…³é”®ä¿¡æ¯

```bash
# æ£€æŸ¥å®ä¾‹æ•°
grep -i "instance" train.log | head -5
# âœ… åº”è¯¥çœ‹åˆ°: Scanning /path/to/labels... 422911 images, 422911 instances

# æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
grep -i "class" train.log | head -10
# âœ… åº”è¯¥çœ‹åˆ°æ­£ç¡®çš„ç±»åˆ«ç»Ÿè®¡

# æ£€æŸ¥éªŒè¯é›†è·¯å¾„
grep -i "val" train.log | head -3
# âœ… ç¡®è®¤è¯»å–äº†æ­£ç¡®çš„éªŒè¯é›†è·¯å¾„
```

### Q4: å¦‚æœè®­ç»ƒå·²ç»è¿›è¡Œäº†å¾ˆä¹…æ‰å‘ç°é—®é¢˜æ€ä¹ˆåŠ?

**A**: åˆ†ææƒé‡,åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ

```python
# ç­–ç•¥1: å¦‚æœåªæ˜¯éªŒè¯é›†é”™è¯¯
# â†’ æ¨¡å‹æƒé‡æ˜¯æ­£ç¡®çš„!
# â†’ åªéœ€ä¿®å¤éªŒè¯é›†,é‡æ–°evaluate

python val_depth.py \
    --weights runs/train/exp_joint_v16/weights/best.pt \
    --data data/visdrone_uavdt_joint_fixed.yaml  # ä¿®å¤åçš„é…ç½®

# ç­–ç•¥2: å¦‚æœè®­ç»ƒé›†é”™è¯¯
# â†’ æ¨¡å‹æƒé‡æ˜¯é”™è¯¯çš„
# â†’ å¿…é¡»é‡æ–°è®­ç»ƒ (æ— æ³•æŒ½æ•‘)

CUDA_VISIBLE_DEVICES=7 python train_depth.py \
    --weights yolo12n.pt  # ä»å¤´å¼€å§‹
    --data data/fixed.yaml
```

## ğŸ’¡ æ˜“é”™ç‚¹æç¤º

### æ˜“é”™ç‚¹ 1: åªæ£€æŸ¥è®­ç»ƒé›†,å¿˜è®°éªŒè¯é›†

```bash
# âŒ é”™è¯¯åšæ³•
cd Datasets/UAVDT_YOLO/train/labels
python fix_labels.py  # åªä¿®å¤è®­ç»ƒé›†

# âœ… æ­£ç¡®åšæ³•
for split in train val test; do
    cd Datasets/UAVDT_YOLO/$split/labels
    python fix_labels.py
done
```

### æ˜“é”™ç‚¹ 2: ä¿®å¤åä¸åˆ ç¼“å­˜

```bash
# âŒ é”™è¯¯åšæ³•
python fix_labels.py  # ä¿®å¤æ ‡ç­¾
python train.py       # ç›´æ¥è®­ç»ƒ (è¯»å–æ—§ç¼“å­˜!)

# âœ… æ­£ç¡®åšæ³•
python fix_labels.py
find . -name "*.cache" -delete  # åˆ é™¤ç¼“å­˜
python train.py --cache False   # ç¦ç”¨ç¼“å­˜æˆ–å¼ºåˆ¶é‡å»º
```

### æ˜“é”™ç‚¹ 3: ç›¸ä¿¡è®­ç»ƒæ›²çº¿è€Œä¸éªŒè¯æ•°æ®

```bash
# âŒ é”™è¯¯æ€è·¯
# "è®­ç»ƒlossä¸‹é™äº†,è¯´æ˜æ•°æ®æ²¡é—®é¢˜"

# âœ… æ­£ç¡®æ€è·¯
# 1. å…ˆéªŒè¯æ•°æ®æ­£ç¡®æ€§
cat labels/*.txt | head -100  # äººå·¥æŠ½æŸ¥
grep class_id train.log       # æ£€æŸ¥ç»Ÿè®¡

# 2. å†ç›¸ä¿¡è®­ç»ƒæ›²çº¿
```

## ğŸ“– æ‹“å±•é˜…è¯»

### 1. æ•°æ®ç‰ˆæœ¬ç®¡ç†

**å·¥å…·æ¨è**: DVC (Data Version Control)

```bash
# åƒGitä¸€æ ·ç®¡ç†æ•°æ®é›†
dvc add Datasets/UAVDT_YOLO
dvc push

# ä¿®å¤æ ‡ç­¾å
dvc add Datasets/UAVDT_YOLO  # è‡ªåŠ¨æ£€æµ‹å˜åŒ–
dvc push
git commit -m "Fix UAVDT label category IDs"
```

### 2. è‡ªåŠ¨åŒ–éªŒè¯ç®¡é“

```python
# æ•°æ®é›†CI/CD
class DatasetValidator:
    def validate_split(self, split):
        """éªŒè¯å•ä¸ªåˆ†å‰²çš„æ•°æ®è´¨é‡"""
        checks = [
            self.check_label_range(),      # ç±»åˆ«IDåœ¨æœ‰æ•ˆèŒƒå›´
            self.check_bbox_validity(),     # è¾¹ç•Œæ¡†åˆæ³•
            self.check_image_label_match(), # å›¾åƒæ ‡ç­¾å¯¹åº”
            self.check_class_distribution(),# ç±»åˆ«åˆ†å¸ƒåˆç†
        ]
        return all(checks)

    def validate_consistency(self):
        """éªŒè¯train/val/testä¸€è‡´æ€§"""
        train_classes = self.get_classes('train')
        val_classes = self.get_classes('val')

        # ç±»åˆ«IDé›†åˆå¿…é¡»ä¸€è‡´
        assert train_classes == val_classes, \
            f"ç±»åˆ«ä¸ä¸€è‡´: train={train_classes}, val={val_classes}"
```

### 3. ç›¸å…³è®ºæ–‡

- **Data Debugging**: "Data Debugging: Detecting and Diagnosing Errors in Datasets" (CVPR 2021)
- **Label Noise**: "Learning with Noisy Labels" (TPAMI 2020)
- **Data Validation**: "Data Validation for Machine Learning" (SysML 2019)

## ğŸ§ª æ€è€ƒé¢˜

### é¢˜ç›® 1: å¿«é€Ÿè¯Šæ–­

ç»™å®šä»¥ä¸‹è®­ç»ƒæ—¥å¿—,åˆ¤æ–­å¯èƒ½çš„é—®é¢˜:

```
Epoch 1: train_loss=2.1, val_loss=2.5, val_mAP=12%
Epoch 50: train_loss=1.0, val_loss=2.4, val_mAP=14%
Epoch 100: train_loss=0.6, val_loss=2.3, val_mAP=15%
Epoch 150: train_loss=0.4, val_loss=2.2, val_mAP=16%
```

**ç­”æ¡ˆ**:

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹</summary>

æ˜æ˜¾çš„ train/val ä¸ä¸€è‡´é—®é¢˜:

1. train_loss æ­£å¸¸ä¸‹é™ (0.4 æ˜¯å¾ˆå¥½çš„å€¼)
2. val_loss ä¸‹é™ç¼“æ…¢ (ä» 2.5â†’2.2,å‡ ä¹ä¸åŠ¨)
3. val_mAP å¢é•¿ææ…¢ (12%â†’16%,åªæ¶¨ 4 ä¸ªç‚¹)

è¯Šæ–­æ­¥éª¤:

1. æ£€æŸ¥éªŒè¯é›†æ ‡ç­¾æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ—§ç¼“å­˜
3. æ£€æŸ¥ train/val æ•°æ®åˆ†å¸ƒæ˜¯å¦ä¸€è‡´
</details>

### é¢˜ç›® 2: è®¾è®¡ä¿®å¤æ–¹æ¡ˆ

æœ‰ä¸¤ä¸ªæ•°æ®é›†åˆå¹¶è®­ç»ƒ:

- VisDrone: ç±»åˆ« 0-9 (10 ç±»)
- UAVDT: ç±»åˆ« 3,5,8 (3 ç±»,å¤ç”¨ VisDrone çš„ car/truck/bus)

å‘ç° UAVDT æ ‡ç­¾é”™è¯¯å†™æˆäº† 4,6,9,è¯·è®¾è®¡å®Œæ•´ä¿®å¤æµç¨‹ã€‚

**ç­”æ¡ˆ**:

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹</summary>

```python
# æ­¥éª¤1: å¤‡ä»½åŸå§‹æ•°æ®
cp -r Datasets/UAVDT_YOLO Datasets/UAVDT_YOLO_backup

# æ­¥éª¤2: æ‰¹é‡ä¿®å¤æ‰€æœ‰åˆ†å‰²
for split in train val test; do
    python fix_uavdt_category_ids.py \
        --label_dir Datasets/UAVDT_YOLO/$split/labels/rgb \
        --mapping "4:3,6:5,9:8"
done

# æ­¥éª¤3: åˆ é™¤æ‰€æœ‰ç¼“å­˜
find Datasets/UAVDT_YOLO -name "*.cache" -delete
find Datasets/VisDrone -name "*.cache" -delete

# æ­¥éª¤4: éªŒè¯ä¿®å¤ç»“æœ
for split in train val test; do
    echo "=== $split ==="
    cd Datasets/UAVDT_YOLO/$split/labels/rgb
    find . -name "*.txt" -exec cat {} \; | \
        awk '{print $1}' | sort | uniq -c
done

# æ­¥éª¤5: é‡æ–°è®­ç»ƒ (ç¦ç”¨ç¼“å­˜)
python train_depth.py \
    --data data/visdrone_uavdt_joint.yaml \
    --cache False \
    --name exp_joint_v17_fixed

# æ­¥éª¤6: ç›‘æ§è®­ç»ƒæ—¥å¿—
tail -f runs/train/exp_joint_v17_fixed/train.log | \
    grep -i "instance\|class"
```

</details>

## ğŸ“Š æœ¬æ¬¡é—®é¢˜æ€»ç»“

### exp_joint_v16 é—®é¢˜è¯Šæ–­

| æ£€æŸ¥é¡¹     | é¢„æœŸ     | å®é™…       | çŠ¶æ€ |
| ---------- | -------- | ---------- | ---- |
| è®­ç»ƒé›†æ ‡ç­¾ | 3,5,8    | **å¾…éªŒè¯** | â“   |
| éªŒè¯é›†æ ‡ç­¾ | 3,5,8    | **å¾…éªŒè¯** | â“   |
| ç¼“å­˜æ–‡ä»¶   | å·²åˆ é™¤   | **å¾…éªŒè¯** | â“   |
| æ€§èƒ½æå‡   | +20-25pp | +1.3pp     | âŒ   |

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³**: è¿è¡Œ `verify_uavdt_dataset.sh` ç¡®å®šæ ¹æœ¬åŸå› 
2. **ä¿®å¤**: æ ¹æ®è¯Šæ–­ç»“æœä¿®å¤æ•°æ®
3. **é‡è®­**: å¯åŠ¨ exp_joint_v17 (ç¡®ä¿æ•°æ®æ­£ç¡®)
4. **éªŒè¯**: ç›‘æ§ mAP æ˜¯å¦è¾¾åˆ° 40%+

---

**è®°å¿†å£è¯€**:

> æ”¹æ•°æ®å¿…åˆ ç¼“å­˜,æ”¹è®­ç»ƒå¿…æ”¹éªŒè¯,
> ä¸‰é›†ç»Ÿä¸€æ˜¯å…³é”®,ä¸ç„¶ç™½å¿™ä¸€åœºç©º!

**å…³é”®æ•™è®­**:
æ°¸è¿œä¸è¦ç›¸ä¿¡"æˆ‘å·²ç»ä¿®å¤äº†æ•°æ®",ä¸€å®šè¦**éªŒè¯**:

1. âœ… æŸ¥çœ‹æ ‡ç­¾æ–‡ä»¶å†…å®¹
2. âœ… æ£€æŸ¥è®­ç»ƒæ—¥å¿—ç»Ÿè®¡
3. âœ… å¯¹æ¯”è®­ç»ƒ/éªŒè¯ä¸€è‡´æ€§
4. âœ… åˆ é™¤æ‰€æœ‰ç›¸å…³ç¼“å­˜
