"""
å¿«é€ŸéªŒè¯Lossæƒé‡è®¡ç®—çš„å¼ é‡ç»´åº¦
ç”¨äºç¡®ä¿ä¿®å¤åçš„ä»£ç èƒ½æ­£ç¡®å¤„ç†å¹¿æ’­
"""
import torch

# æ¨¡æ‹Ÿå®é™…è®­ç»ƒä¸­çš„å¼ é‡ç»´åº¦
batch_size = 16
num_anchors = 8400  # 80x80 + 40x40 + 20x20 = 6400+1600+400

# æ¨¡æ‹Ÿå…³é”®å¼ é‡
stride_tensor = torch.randn(num_anchors, 1)  # (8400, 1)
target_bboxes = torch.randn(batch_size, num_anchors, 4)  # (16, 8400, 4)
fg_mask = torch.randint(0, 2, (batch_size, num_anchors)).bool()  # (16, 8400)
target_scores = torch.randn(batch_size, num_anchors, 10)  # (16, 8400, 10)

print("=" * 60)
print("ğŸ“Š å¼ é‡ç»´åº¦éªŒè¯")
print("=" * 60)
print(f"stride_tensor:   {stride_tensor.shape}")
print(f"target_bboxes:   {target_bboxes.shape}")
print(f"fg_mask:         {fg_mask.shape}")
print(f"target_scores:   {target_scores.shape}")
print()

# æµ‹è¯•ä¿®å¤åçš„ä»£ç é€»è¾‘
print("=" * 60)
print("ğŸ”§ æµ‹è¯•Size-Adaptiveæƒé‡è®¡ç®—")
print("=" * 60)

num_classes = 10
area_weights = torch.ones(batch_size, num_anchors)
print(f"åˆå§‹ area_weights: {area_weights.shape}")

if fg_mask.sum() > 0:
    # ä¿®å¤åçš„å¹¿æ’­é€»è¾‘
    stride_broadcast = stride_tensor.unsqueeze(0)  # (1, 8400, 1)
    print(f"stride_broadcast: {stride_broadcast.shape}")
    
    # è®¡ç®—å®½åº¦å’Œé«˜åº¦
    gt_widths = (target_bboxes[:, :, 2] - target_bboxes[:, :, 0]) * stride_broadcast.squeeze(-1)
    gt_heights = (target_bboxes[:, :, 3] - target_bboxes[:, :, 1]) * stride_broadcast.squeeze(-1)
    
    print(f"gt_widths:  {gt_widths.shape}")
    print(f"gt_heights: {gt_heights.shape}")
    
    gt_areas = gt_widths * gt_heights
    print(f"gt_areas:   {gt_areas.shape}")
    
    # åˆ†é…æƒé‡ (æ³¨æ„: area_weightsç°åœ¨æ˜¯ (bs, num_anchors))
    area_weights = torch.where(
        gt_areas < 1024,
        torch.tensor(2.0),
        torch.where(
            gt_areas < 9216,
            torch.tensor(1.5),
            torch.tensor(1.0)
        )
    )
    print(f"æ¡ä»¶æƒé‡ area_weights: {area_weights.shape}")
    
    # åº”ç”¨fg_mask
    area_weights = area_weights * fg_mask.float()
    print(f"fg_maskå area_weights: {area_weights.shape}")
    
    # æ‰©å±•åˆ°åŒ¹é…target_scoreså½¢çŠ¶
    size_weights = area_weights.unsqueeze(-1).expand(batch_size, num_anchors, num_classes)
    print(f"æ‰©å±•å size_weights: {size_weights.shape}")
    print(f"target_scoreså½¢çŠ¶: {target_scores.shape}")
    print(f"âœ… å½¢çŠ¶åŒ¹é…æˆåŠŸ!" if size_weights.shape == target_scores.shape else "âŒ å½¢çŠ¶ä¸åŒ¹é…!")
    
    # éªŒè¯æƒé‡åˆ†å¸ƒ
    print()
    print("=" * 60)
    print("ğŸ“ˆ æƒé‡ç»Ÿè®¡")
    print("=" * 60)
    valid_area_weights = area_weights[fg_mask]
    print(f"æ­£æ ·æœ¬æ•°é‡: {fg_mask.sum().item()}")
    print(f"æƒé‡Ã—2.0æ•°é‡: {(valid_area_weights == 2.0).sum().item()}")
    print(f"æƒé‡Ã—1.5æ•°é‡: {(valid_area_weights == 1.5).sum().item()}")
    print(f"æƒé‡Ã—1.0æ•°é‡: {(valid_area_weights == 1.0).sum().item()}")
    print(f"æƒé‡èŒƒå›´: [{valid_area_weights.min().item():.1f}, {valid_area_weights.max().item():.1f}]")
    
    # éªŒè¯cls_lossè®¡ç®—
    print()
    print("=" * 60)
    print("ğŸ§® éªŒè¯Lossè®¡ç®—")
    print("=" * 60)
    cls_loss_per_sample = torch.randn_like(target_scores)
    print(f"cls_loss_per_sample: {cls_loss_per_sample.shape}")
    weighted_cls_loss = cls_loss_per_sample * size_weights
    print(f"weighted_cls_loss:   {weighted_cls_loss.shape}")
    print(f"âœ… å¯ä»¥æ­£å¸¸ç›¸ä¹˜!" if weighted_cls_loss.shape == cls_loss_per_sample.shape else "âŒ ç›¸ä¹˜å¤±è´¥!")
    
    # éªŒè¯box_lossæƒé‡
    avg_area_weight = area_weights[fg_mask].mean()
    print(f"avg_area_weight:     {avg_area_weight.item():.3f} (æ ‡é‡)")
    print(f"âœ… å¯ä»¥ç”¨äºbox_lossç¼©æ”¾!")

print()
print("=" * 60)
print("âœ… æ‰€æœ‰ç»´åº¦æ£€æŸ¥é€šè¿‡!")
print("=" * 60)
