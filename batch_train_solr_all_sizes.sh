#!/bin/bash
# æ‰¹é‡è®­ç»ƒæ‰€æœ‰å°ºå¯¸çš„YOLO12-RGBDæ¨¡å‹ (with SOLR loss)
# ç”¨é€”: å¯¹æ¯”ä¸åŒæ¨¡å‹å°ºå¯¸ (n/s/m/l/x) ä¸RemDetçš„æ€§èƒ½å·®å¼‚
# 
# ä½¿ç”¨æ–¹æ³•:
#   bash batch_train_solr_all_sizes.sh
#
# æˆ–åˆ†åˆ«è¿è¡Œ:
#   bash batch_train_solr_all_sizes.sh n  # åªè®­ç»ƒnano
#   bash batch_train_solr_all_sizes.sh s  # åªè®­ç»ƒsmall
#   bash batch_train_solr_all_sizes.sh m  # åªè®­ç»ƒmedium

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# ================================================================================================
# é…ç½®å‚æ•°
# ================================================================================================
DATA_YAML="data/visdrone-rgbd.yaml"  # æ•°æ®é›†é…ç½®æ–‡ä»¶
EPOCHS=300                           # è®­ç»ƒè½®æ•°
DEVICE="0"                           # GPUè®¾å¤‡å· (å¤šå¡ç”¨ "0,1,2,3")
PROJECT="runs/train_solr"            # è¾“å‡ºç›®å½•
BASE_BATCH=16                        # åŸºå‡†batch size (ä¼šæ ¹æ®æ¨¡å‹å¤§å°è‡ªåŠ¨è°ƒæ•´)

# SOLRæƒé‡é…ç½®
SMALL_WEIGHT=2.5    # å°ç›®æ ‡æƒé‡
MEDIUM_WEIGHT=2.0   # ä¸­ç­‰ç›®æ ‡æƒé‡ (å…³é”®å‚æ•°,é’ˆå¯¹RemDetå·®è·)
LARGE_WEIGHT=1.0    # å¤§ç›®æ ‡æƒé‡

# ================================================================================================
# æ¨¡å‹é…ç½® (size: batch_size)
# ================================================================================================
declare -A MODEL_CONFIGS=(
    ["n"]="32"   # nano:   ~3M params,  ~8G FLOPs  â†’ batch=32
    ["s"]="16"   # small:  ~11M params, ~46G FLOPs â†’ batch=16
    ["m"]="8"    # medium: ~22M params, ~92G FLOPs â†’ batch=8
    ["l"]="4"    # large:  ~44M params, ~184G FLOPs â†’ batch=4
    ["x"]="2"    # xlarge: ~66M params, ~276G FLOPs â†’ batch=2
)

# RemDetå¯¹æ ‡è¡¨ (ç”¨äºå¯¹æ¯”)
declare -A REMDET_TARGETS=(
    ["n"]="RemDet-Tiny (AP@0.5: 37.1%, AP_m: 33.0%)"
    ["s"]="RemDet-S (AP@0.5: 42.3%, AP_m: 38.5%)"
    ["m"]="RemDet-M (AP@0.5: 45.0%, AP_m: 41.2%)"
    ["l"]="RemDet-L (AP@0.5: 47.4%, AP_m: 43.6%)"
    ["x"]="RemDet-X (AP@0.5: 48.3%, AP_m: 44.8%)"
)

# ================================================================================================
# è¾…åŠ©å‡½æ•°
# ================================================================================================
print_header() {
    echo ""
    echo "================================================================================================"
    echo "$1"
    echo "================================================================================================"
    echo ""
}

print_info() {
    echo "â„¹ï¸  $1"
}

print_success() {
    echo "âœ… $1"
}

print_error() {
    echo "âŒ $1"
}

# ================================================================================================
# è®­ç»ƒå‡½æ•°
# ================================================================================================
train_model() {
    local size=$1
    local batch=${MODEL_CONFIGS[$size]}
    local name="solr_${size}_300ep"
    local target=${REMDET_TARGETS[$size]}
    
    print_header "Training YOLO12-RGBD-${size^^} with SOLR"
    
    print_info "Configuration:"
    print_info "  Model size:    ${size} (batch=${batch})"
    print_info "  Target:        ${target}"
    print_info "  SOLR weights:  small=${SMALL_WEIGHT}x, medium=${MEDIUM_WEIGHT}x, large=${LARGE_WEIGHT}x"
    print_info "  Epochs:        ${EPOCHS}"
    print_info "  Device:        ${DEVICE}"
    print_info "  Output:        ${PROJECT}/${name}"
    echo ""
    
    # å¼€å§‹è®­ç»ƒ
    print_info "Starting training at $(date '+%Y-%m-%d %H:%M:%S')..."
    
    python train_depth_solr.py \
        --data "${DATA_YAML}" \
        --cfg "${size}" \
        --epochs ${EPOCHS} \
        --batch ${batch} \
        --device "${DEVICE}" \
        --small_weight ${SMALL_WEIGHT} \
        --medium_weight ${MEDIUM_WEIGHT} \
        --large_weight ${LARGE_WEIGHT} \
        --optimizer SGD \
        --lr0 0.01 \
        --momentum 0.937 \
        --weight_decay 0.0005 \
        --mosaic 1.0 \
        --mixup 0.15 \
        --close_mosaic 10 \
        --amp \
        --project "${PROJECT}" \
        --name "${name}" \
        --exist_ok
    
    # æ£€æŸ¥è®­ç»ƒç»“æœ
    if [ $? -eq 0 ]; then
        print_success "Training completed successfully!"
        print_info "Results saved to: ${PROJECT}/${name}"
        print_info "Finished at $(date '+%Y-%m-%d %H:%M:%S')"
        
        # æ˜¾ç¤ºæœ€ä½³mAP (å¦‚æœresults.txtå­˜åœ¨)
        local results_file="${PROJECT}/${name}/results.txt"
        if [ -f "${results_file}" ]; then
            local best_map=$(tail -1 "${results_file}" | awk '{print $7}')  # mAP@0.5
            local best_map50_95=$(tail -1 "${results_file}" | awk '{print $8}')  # mAP@0.5:0.95
            print_success "Best mAP@0.5:     ${best_map}"
            print_success "Best mAP@0.5:0.95: ${best_map50_95}"
        fi
    else
        print_error "Training failed for size ${size}!"
        exit 1
    fi
    
    echo ""
}

# ================================================================================================
# ä¸»ç¨‹åº
# ================================================================================================
main() {
    print_header "ğŸš€ YOLO12-RGBD Multi-Size Training with SOLR"
    
    # æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
    if [ ! -f "${DATA_YAML}" ]; then
        print_error "Dataset config not found: ${DATA_YAML}"
        print_info "Please check the path and try again."
        exit 1
    fi
    print_success "Dataset config found: ${DATA_YAML}"
    
    # ç¡®å®šè¦è®­ç»ƒçš„æ¨¡å‹å°ºå¯¸
    if [ $# -eq 0 ]; then
        # æœªæŒ‡å®šå‚æ•°,è®­ç»ƒæ‰€æœ‰å°ºå¯¸
        SIZES_TO_TRAIN=("n" "s" "m" "l" "x")
        print_info "No size specified, will train all sizes: n, s, m, l, x"
        print_info "Estimated total time: ~14-16 hours (on RTX 4090)"
        echo ""
        read -p "Continue? [y/N] " -n 1 -r
        echo ""
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            print_info "Training cancelled."
            exit 0
        fi
    else
        # åªè®­ç»ƒæŒ‡å®šçš„å°ºå¯¸
        SIZES_TO_TRAIN=("$@")
        print_info "Will train sizes: ${SIZES_TO_TRAIN[@]}"
    fi
    
    # å¼€å§‹æ‰¹é‡è®­ç»ƒ
    START_TIME=$(date +%s)
    
    for size in "${SIZES_TO_TRAIN[@]}"; do
        # éªŒè¯å°ºå¯¸å‚æ•°
        if [[ ! " n s m l x " =~ " ${size} " ]]; then
            print_error "Invalid model size: ${size} (must be n/s/m/l/x)"
            continue
        fi
        
        # è®­ç»ƒå½“å‰å°ºå¯¸
        train_model "${size}"
        
        # è®­ç»ƒé—´éš” (é¿å…GPUè¿‡çƒ­)
        if [ "${size}" != "${SIZES_TO_TRAIN[-1]}" ]; then
            print_info "Cooling down for 60 seconds before next training..."
            sleep 60
        fi
    done
    
    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    END_TIME=$(date +%s)
    TOTAL_TIME=$((END_TIME - START_TIME))
    HOURS=$((TOTAL_TIME / 3600))
    MINUTES=$(((TOTAL_TIME % 3600) / 60))
    
    print_header "ğŸ‰ All Training Completed!"
    print_success "Total time: ${HOURS}h ${MINUTES}m"
    print_info "Results directory: ${PROJECT}/"
    
    # ç”Ÿæˆç»“æœå¯¹æ¯”è¡¨
    print_header "ğŸ“Š Results Summary"
    echo ""
    printf "%-8s %-12s %-12s %-12s %-40s\n" "Model" "mAP@0.5" "mAP@0.5:0.95" "Best Epoch" "Target (RemDet)"
    echo "--------------------------------------------------------------------------------------------"
    
    for size in "${SIZES_TO_TRAIN[@]}"; do
        local name="solr_${size}_300ep"
        local results_file="${PROJECT}/${name}/results.txt"
        
        if [ -f "${results_file}" ]; then
            local best_map=$(tail -1 "${results_file}" | awk '{print $7}')
            local best_map50_95=$(tail -1 "${results_file}" | awk '{print $8}')
            local best_epoch=$(tail -1 "${results_file}" | awk '{print $1}')
            local target=${REMDET_TARGETS[$size]}
            
            printf "%-8s %-12s %-12s %-12s %-40s\n" \
                "${size^^}" "${best_map}" "${best_map50_95}" "${best_epoch}" "${target}"
        else
            printf "%-8s %-12s %-12s %-12s %-40s\n" \
                "${size^^}" "N/A" "N/A" "N/A" "${REMDET_TARGETS[$size]}"
        fi
    done
    
    echo ""
    print_info "Next steps:"
    print_info "  1. Run COCO evaluation: python val_coco_eval.py --weights ${PROJECT}/solr_s_300ep/weights/best.pt"
    print_info "  2. Compare with RemDet benchmarks"
    print_info "  3. Analyze which size achieves best performance/efficiency trade-off"
    echo ""
}

# è¿è¡Œä¸»ç¨‹åº
main "$@"
