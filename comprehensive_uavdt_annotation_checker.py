"""
UAVDTæ ‡æ³¨è´¨é‡ç»¼åˆæ£€æŸ¥å·¥å…·
===========================

åŠŸèƒ½:
1. åŸºç¡€ç»Ÿè®¡åˆ†æ (bboxå°ºå¯¸ã€ç±»åˆ«åˆ†å¸ƒã€é•¿å®½æ¯”ç­‰)
2. å¼‚å¸¸æ£€æµ‹ (è¶…ç•Œæ¡†ã€ç•¸å½¢æ¡†ã€æç«¯å°ºå¯¸ã€é‡å åº¦)
3. å¯è§†åŒ–æŠ½æ · (éšæœºç»˜åˆ¶bboxéªŒè¯æ ‡æ³¨æ­£ç¡®æ€§)
4. ä¸VisDroneå¯¹æ¯” (æ‰¾å‡ºæ•°æ®é›†é—´çš„å·®å¼‚)

ä½¿ç”¨æ–¹æ³•:
python comprehensive_uavdt_annotation_checker.py \
    --uavdt_root /data2/user/2024/lzy/Datasets/UAVDT_YOLO \
    --visdrone_root /data2/user/2024/lzy/Datasets/VisDrone \
    --output_dir ./uavdt_annotation_analysis \
    --num_visualize 100
"""

import os
import cv2
import numpy as np
from pathlib import Path
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import argparse
import json


class AnnotationChecker:
    """UAVDTæ ‡æ³¨è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, dataset_root, dataset_name="UAVDT"):
        self.dataset_root = Path(dataset_root)
        self.dataset_name = dataset_name
        
        # ç±»åˆ«æ˜ å°„ (VisDrone 10ç±»)
        self.class_names = {
            0: 'ignored',
            1: 'pedestrian',
            2: 'people',
            3: 'car',
            4: 'van',
            5: 'truck',
            6: 'tricycle',
            7: 'awning-tricycle',
            8: 'bus',
            9: 'motor'
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_images': 0,
            'total_objects': 0,
            'category_count': Counter(),
            'bbox_areas': [],
            'bbox_widths': [],
            'bbox_heights': [],
            'aspect_ratios': [],
            'abnormal_boxes': [],  # å¼‚å¸¸æ¡†
            'empty_images': [],    # æ— æ ‡æ³¨å›¾åƒ
            'errors': [],
        }
    
    def check_split(self, split='train'):
        """æ£€æŸ¥æŸä¸ªsplitçš„æ ‡æ³¨è´¨é‡"""
        print(f"\n{'='*80}")
        print(f"æ£€æŸ¥ {self.dataset_name} - {split} split")
        print(f"{'='*80}\n")
        
        # è·¯å¾„
        image_dir = self.dataset_root / split / 'images' / 'rgb'
        label_dir = self.dataset_root / split / 'labels' / 'rgb'
        
        if not image_dir.exists():
            print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
            return None
        
        if not label_dir.exists():
            print(f"âŒ æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {label_dir}")
            return None
        
        # è·å–æ‰€æœ‰å›¾åƒ
        image_files = sorted(list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png")))
        print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
        
        # ç»Ÿè®¡ä¿¡æ¯
        split_stats = {
            'total_images': len(image_files),
            'total_objects': 0,
            'category_count': Counter(),
            'bbox_areas': [],
            'bbox_widths': [],
            'bbox_heights': [],
            'aspect_ratios': [],
            'abnormal_boxes': [],
            'empty_images': [],
            'errors': [],
        }
        
        # éå†æ¯å¼ å›¾åƒ
        for img_file in tqdm(image_files, desc=f"åˆ†æ{split}é›†"):
            # å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
            label_file = label_dir / (img_file.stem + '.txt')
            
            # è¯»å–å›¾åƒå°ºå¯¸
            img = cv2.imread(str(img_file))
            if img is None:
                split_stats['errors'].append(f"æ— æ³•è¯»å–å›¾åƒ: {img_file}")
                continue
            
            img_h, img_w = img.shape[:2]
            
            # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶
            if not label_file.exists():
                split_stats['empty_images'].append(str(img_file.name))
                continue
            
            # è¯»å–æ ‡æ³¨
            try:
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                
                if not lines:
                    split_stats['empty_images'].append(str(img_file.name))
                    continue
                
                # è§£ææ¯ä¸ªbbox
                for line_idx, line in enumerate(lines):
                    line = line.strip()
                    if not line:
                        continue
                    
                    parts = line.split()
                    if len(parts) < 5:
                        split_stats['errors'].append(
                            f"{img_file.name} ç¬¬{line_idx+1}è¡Œ: æ ¼å¼é”™è¯¯"
                        )
                        continue
                    
                    # è§£æYOLOæ ¼å¼ (class x_center y_center width height)
                    try:
                        class_id = int(parts[0])
                        x_center = float(parts[1])
                        y_center = float(parts[2])
                        width = float(parts[3])
                        height = float(parts[4])
                        
                        # ç»Ÿè®¡ç±»åˆ«
                        split_stats['category_count'][class_id] += 1
                        split_stats['total_objects'] += 1
                        
                        # è®¡ç®—å®é™…åƒç´ å°ºå¯¸
                        bbox_w_px = width * img_w
                        bbox_h_px = height * img_h
                        bbox_area = bbox_w_px * bbox_h_px
                        
                        # è®°å½•å°ºå¯¸ä¿¡æ¯
                        split_stats['bbox_widths'].append(bbox_w_px)
                        split_stats['bbox_heights'].append(bbox_h_px)
                        split_stats['bbox_areas'].append(bbox_area)
                        
                        # é•¿å®½æ¯”
                        if bbox_h_px > 0:
                            aspect_ratio = bbox_w_px / bbox_h_px
                            split_stats['aspect_ratios'].append(aspect_ratio)
                        
                        # å¼‚å¸¸æ£€æµ‹
                        abnormal = self.detect_abnormal_bbox(
                            img_file.name, class_id, 
                            x_center, y_center, width, height,
                            img_w, img_h
                        )
                        if abnormal:
                            split_stats['abnormal_boxes'].append(abnormal)
                    
                    except ValueError as e:
                        split_stats['errors'].append(
                            f"{img_file.name} ç¬¬{line_idx+1}è¡Œ: è§£æé”™è¯¯ - {e}"
                        )
            
            except Exception as e:
                split_stats['errors'].append(f"{img_file.name}: {e}")
        
        return split_stats
    
    def detect_abnormal_bbox(self, img_name, class_id, 
                            x_center, y_center, width, height,
                            img_w, img_h):
        """æ£€æµ‹å¼‚å¸¸bbox"""
        issues = []
        
        # 1. è¶…å‡ºå›¾åƒè¾¹ç•Œ
        x_min = x_center - width / 2
        y_min = y_center - height / 2
        x_max = x_center + width / 2
        y_max = y_center + height / 2
        
        if x_min < 0 or y_min < 0 or x_max > 1 or y_max > 1:
            issues.append("è¶…å‡ºè¾¹ç•Œ")
        
        # 2. å°ºå¯¸å¼‚å¸¸ (è¿‡å°æˆ–è¿‡å¤§)
        bbox_w_px = width * img_w
        bbox_h_px = height * img_h
        
        if bbox_w_px < 3 or bbox_h_px < 3:
            issues.append(f"è¿‡å° ({bbox_w_px:.1f}x{bbox_h_px:.1f}px)")
        
        if width > 0.8 or height > 0.8:
            issues.append(f"è¿‡å¤§ ({width:.2f}x{height:.2f})")
        
        # 3. é•¿å®½æ¯”å¼‚å¸¸
        if bbox_h_px > 0:
            aspect_ratio = bbox_w_px / bbox_h_px
            if aspect_ratio > 10 or aspect_ratio < 0.1:
                issues.append(f"é•¿å®½æ¯”å¼‚å¸¸ ({aspect_ratio:.2f})")
        
        # 4. ä¸­å¿ƒç‚¹å¼‚å¸¸
        if x_center < 0 or x_center > 1 or y_center < 0 or y_center > 1:
            issues.append("ä¸­å¿ƒç‚¹è¶…ç•Œ")
        
        if issues:
            return {
                'image': img_name,
                'class': class_id,
                'bbox': [x_center, y_center, width, height],
                'issues': issues
            }
        
        return None
    
    def visualize_annotations(self, split='train', num_samples=50, output_dir='./vis'):
        """å¯è§†åŒ–æ ‡æ³¨ç»“æœ"""
        print(f"\n{'='*80}")
        print(f"å¯è§†åŒ– {self.dataset_name} - {split} split çš„æ ‡æ³¨")
        print(f"{'='*80}\n")
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·¯å¾„
        image_dir = self.dataset_root / split / 'images' / 'rgb'
        label_dir = self.dataset_root / split / 'labels' / 'rgb'
        
        # éšæœºé€‰æ‹©å›¾åƒ
        image_files = sorted(list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png")))
        if len(image_files) > num_samples:
            np.random.seed(42)
            image_files = np.random.choice(image_files, num_samples, replace=False)
        
        print(f"éšæœºæŠ½å– {len(image_files)} å¼ å›¾åƒè¿›è¡Œå¯è§†åŒ–...")
        
        # é¢œè‰²æ˜ å°„
        colors = {
            0: (128, 128, 128),  # ignored - ç°è‰²
            1: (255, 0, 0),      # pedestrian - çº¢è‰²
            2: (255, 165, 0),    # people - æ©™è‰²
            3: (0, 255, 0),      # car - ç»¿è‰²
            4: (0, 255, 255),    # van - é’è‰²
            5: (255, 255, 0),    # truck - é»„è‰²
            6: (255, 0, 255),    # tricycle - å“çº¢
            7: (128, 0, 255),    # awning-tricycle - ç´«è‰²
            8: (0, 0, 255),      # bus - è“è‰²
            9: (255, 128, 0),    # motor - æ©™çº¢
        }
        
        for img_file in tqdm(image_files, desc="ç»˜åˆ¶æ ‡æ³¨"):
            # è¯»å–å›¾åƒ
            img = cv2.imread(str(img_file))
            if img is None:
                continue
            
            img_h, img_w = img.shape[:2]
            
            # è¯»å–æ ‡ç­¾
            label_file = label_dir / (img_file.stem + '.txt')
            if not label_file.exists():
                continue
            
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            # ç»˜åˆ¶æ¯ä¸ªbbox
            for line in lines:
                parts = line.strip().split()
                if len(parts) < 5:
                    continue
                
                try:
                    class_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    
                    # è½¬æ¢ä¸ºåƒç´ åæ ‡
                    x_min = int((x_center - width / 2) * img_w)
                    y_min = int((y_center - height / 2) * img_h)
                    x_max = int((x_center + width / 2) * img_w)
                    y_max = int((y_center + height / 2) * img_h)
                    
                    # ç»˜åˆ¶bbox
                    color = colors.get(class_id, (255, 255, 255))
                    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 2)
                    
                    # ç»˜åˆ¶ç±»åˆ«æ ‡ç­¾
                    label_text = self.class_names.get(class_id, f"class_{class_id}")
                    cv2.putText(img, label_text, (x_min, y_min - 5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                except:
                    continue
            
            # ä¿å­˜
            output_file = output_dir / f"{self.dataset_name}_{split}_{img_file.name}"
            cv2.imwrite(str(output_file), img)
        
        print(f"âœ… å¯è§†åŒ–å®Œæˆ! ä¿å­˜åˆ°: {output_dir}")
        return output_dir
    
    def print_statistics(self, stats):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print(f"\n{'='*80}")
        print("ğŸ“Š ç»Ÿè®¡ç»“æœ")
        print(f"{'='*80}\n")
        
        print(f"æ€»å›¾åƒæ•°:     {stats['total_images']}")
        print(f"æ€»å¯¹è±¡æ•°:     {stats['total_objects']}")
        print(f"ç©ºå›¾åƒæ•°:     {len(stats['empty_images'])}")
        print(f"å¼‚å¸¸æ¡†æ•°:     {len(stats['abnormal_boxes'])}")
        print(f"é”™è¯¯æ•°:       {len(stats['errors'])}")
        print()
        
        # ç±»åˆ«åˆ†å¸ƒ
        print("ç±»åˆ«åˆ†å¸ƒ:")
        total_objs = sum(stats['category_count'].values())
        for class_id in sorted(stats['category_count'].keys()):
            count = stats['category_count'][class_id]
            percentage = count / total_objs * 100 if total_objs > 0 else 0
            class_name = self.class_names.get(class_id, f"class_{class_id}")
            print(f"  {class_id} ({class_name:>20}): {count:>8} ({percentage:>5.2f}%)")
        print()
        
        # Bboxå°ºå¯¸ç»Ÿè®¡
        if stats['bbox_widths']:
            print("Bboxå°ºå¯¸ç»Ÿè®¡ (åƒç´ ):")
            print(f"  å®½åº¦: min={np.min(stats['bbox_widths']):.1f}, "
                  f"mean={np.mean(stats['bbox_widths']):.1f}, "
                  f"median={np.median(stats['bbox_widths']):.1f}, "
                  f"max={np.max(stats['bbox_widths']):.1f}")
            print(f"  é«˜åº¦: min={np.min(stats['bbox_heights']):.1f}, "
                  f"mean={np.mean(stats['bbox_heights']):.1f}, "
                  f"median={np.median(stats['bbox_heights']):.1f}, "
                  f"max={np.max(stats['bbox_heights']):.1f}")
            print(f"  é¢ç§¯: min={np.min(stats['bbox_areas']):.1f}, "
                  f"mean={np.mean(stats['bbox_areas']):.1f}, "
                  f"median={np.median(stats['bbox_areas']):.1f}, "
                  f"max={np.max(stats['bbox_areas']):.1f}")
            print()
        
        # é•¿å®½æ¯”
        if stats['aspect_ratios']:
            print("é•¿å®½æ¯”ç»Ÿè®¡:")
            print(f"  min={np.min(stats['aspect_ratios']):.2f}, "
                  f"mean={np.mean(stats['aspect_ratios']):.2f}, "
                  f"median={np.median(stats['aspect_ratios']):.2f}, "
                  f"max={np.max(stats['aspect_ratios']):.2f}")
            print()
        
        # å¼‚å¸¸æ¡†ç¤ºä¾‹
        if stats['abnormal_boxes']:
            print(f"âš ï¸  å‘ç° {len(stats['abnormal_boxes'])} ä¸ªå¼‚å¸¸æ¡† (æ˜¾ç¤ºå‰10ä¸ª):")
            for abnormal in stats['abnormal_boxes'][:10]:
                print(f"  - {abnormal['image']} | "
                      f"ç±»åˆ«{abnormal['class']} | "
                      f"é—®é¢˜: {', '.join(abnormal['issues'])}")
            if len(stats['abnormal_boxes']) > 10:
                print(f"  ... è¿˜æœ‰ {len(stats['abnormal_boxes']) - 10} ä¸ªå¼‚å¸¸æ¡†")
            print()
        
        # é”™è¯¯ç¤ºä¾‹
        if stats['errors']:
            print(f"âŒ å‘ç° {len(stats['errors'])} ä¸ªé”™è¯¯ (æ˜¾ç¤ºå‰10ä¸ª):")
            for error in stats['errors'][:10]:
                print(f"  - {error}")
            if len(stats['errors']) > 10:
                print(f"  ... è¿˜æœ‰ {len(stats['errors']) - 10} ä¸ªé”™è¯¯")
            print()
    
    def plot_statistics(self, stats, output_file='stats.png'):
        """ç»˜åˆ¶ç»Ÿè®¡å›¾è¡¨"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle(f'{self.dataset_name} æ ‡æ³¨è´¨é‡åˆ†æ', fontsize=16)
        
        # 1. ç±»åˆ«åˆ†å¸ƒ
        if stats['category_count']:
            ax = axes[0, 0]
            class_ids = sorted(stats['category_count'].keys())
            counts = [stats['category_count'][cid] for cid in class_ids]
            labels = [self.class_names.get(cid, f"c{cid}") for cid in class_ids]
            ax.bar(range(len(class_ids)), counts)
            ax.set_xticks(range(len(class_ids)))
            ax.set_xticklabels(labels, rotation=45, ha='right')
            ax.set_title('ç±»åˆ«åˆ†å¸ƒ')
            ax.set_ylabel('æ•°é‡')
            ax.grid(axis='y', alpha=0.3)
        
        # 2. Bboxå®½åº¦åˆ†å¸ƒ
        if stats['bbox_widths']:
            ax = axes[0, 1]
            ax.hist(stats['bbox_widths'], bins=50, edgecolor='black', alpha=0.7)
            ax.set_title('Bboxå®½åº¦åˆ†å¸ƒ (åƒç´ )')
            ax.set_xlabel('å®½åº¦')
            ax.set_ylabel('é¢‘æ¬¡')
            ax.axvline(np.median(stats['bbox_widths']), color='r', 
                      linestyle='--', label=f'ä¸­ä½æ•°={np.median(stats["bbox_widths"]):.1f}')
            ax.legend()
            ax.grid(axis='y', alpha=0.3)
        
        # 3. Bboxé«˜åº¦åˆ†å¸ƒ
        if stats['bbox_heights']:
            ax = axes[0, 2]
            ax.hist(stats['bbox_heights'], bins=50, edgecolor='black', alpha=0.7)
            ax.set_title('Bboxé«˜åº¦åˆ†å¸ƒ (åƒç´ )')
            ax.set_xlabel('é«˜åº¦')
            ax.set_ylabel('é¢‘æ¬¡')
            ax.axvline(np.median(stats['bbox_heights']), color='r', 
                      linestyle='--', label=f'ä¸­ä½æ•°={np.median(stats["bbox_heights"]):.1f}')
            ax.legend()
            ax.grid(axis='y', alpha=0.3)
        
        # 4. Bboxé¢ç§¯åˆ†å¸ƒ (å¯¹æ•°åæ ‡)
        if stats['bbox_areas']:
            ax = axes[1, 0]
            ax.hist(np.log10(stats['bbox_areas']), bins=50, edgecolor='black', alpha=0.7)
            ax.set_title('Bboxé¢ç§¯åˆ†å¸ƒ (log10)')
            ax.set_xlabel('log10(é¢ç§¯)')
            ax.set_ylabel('é¢‘æ¬¡')
            ax.grid(axis='y', alpha=0.3)
        
        # 5. é•¿å®½æ¯”åˆ†å¸ƒ
        if stats['aspect_ratios']:
            ax = axes[1, 1]
            # è¿‡æ»¤æç«¯å€¼
            ar_filtered = [ar for ar in stats['aspect_ratios'] if 0.1 <= ar <= 10]
            ax.hist(ar_filtered, bins=50, edgecolor='black', alpha=0.7)
            ax.set_title('é•¿å®½æ¯”åˆ†å¸ƒ (0.1-10)')
            ax.set_xlabel('é•¿å®½æ¯”')
            ax.set_ylabel('é¢‘æ¬¡')
            ax.axvline(np.median(ar_filtered), color='r', 
                      linestyle='--', label=f'ä¸­ä½æ•°={np.median(ar_filtered):.2f}')
            ax.legend()
            ax.grid(axis='y', alpha=0.3)
        
        # 6. å°ç›®æ ‡åˆ†æ (é¢ç§¯ < 32x32)
        if stats['bbox_areas']:
            ax = axes[1, 2]
            small_threshold = 32 * 32
            small_objs = [area for area in stats['bbox_areas'] if area < small_threshold]
            medium_objs = [area for area in stats['bbox_areas'] 
                          if small_threshold <= area < 96*96]
            large_objs = [area for area in stats['bbox_areas'] if area >= 96*96]
            
            sizes = ['Small\n(<32Â²)', 'Medium\n(32Â²-96Â²)', 'Large\n(â‰¥96Â²)']
            counts = [len(small_objs), len(medium_objs), len(large_objs)]
            ax.bar(sizes, counts, color=['red', 'orange', 'green'], alpha=0.7)
            ax.set_title('ç›®æ ‡å°ºå¯¸åˆ†å¸ƒ')
            ax.set_ylabel('æ•°é‡')
            for i, count in enumerate(counts):
                percentage = count / len(stats['bbox_areas']) * 100
                ax.text(i, count, f'{count}\n({percentage:.1f}%)', 
                       ha='center', va='bottom')
            ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"âœ… ç»Ÿè®¡å›¾è¡¨ä¿å­˜åˆ°: {output_file}")
        plt.close()


def compare_datasets(uavdt_stats, visdrone_stats, output_dir):
    """å¯¹æ¯”UAVDTå’ŒVisDroneæ•°æ®é›†"""
    print(f"\n{'='*80}")
    print("ğŸ“Š æ•°æ®é›†å¯¹æ¯”: UAVDT vs VisDrone")
    print(f"{'='*80}\n")
    
    # å¯¹æ¯”ç±»åˆ«åˆ†å¸ƒ
    print("ç±»åˆ«åˆ†å¸ƒå¯¹æ¯” (è®­ç»ƒé›†):")
    print(f"{'ç±»åˆ«':<20} | {'UAVDT':>12} | {'VisDrone':>12} | {'æ¯”ä¾‹':>10}")
    print("-" * 60)
    
    all_classes = set(uavdt_stats['category_count'].keys()) | \
                  set(visdrone_stats['category_count'].keys())
    
    class_names = {
        0: 'ignored',
        1: 'pedestrian',
        2: 'people',
        3: 'car',
        4: 'van',
        5: 'truck',
        6: 'tricycle',
        7: 'awning-tricycle',
        8: 'bus',
        9: 'motor'
    }
    
    for class_id in sorted(all_classes):
        uavdt_count = uavdt_stats['category_count'].get(class_id, 0)
        visdrone_count = visdrone_stats['category_count'].get(class_id, 0)
        
        ratio = uavdt_count / visdrone_count if visdrone_count > 0 else float('inf')
        class_name = class_names.get(class_id, f"class_{class_id}")
        
        print(f"{class_name:<20} | {uavdt_count:>12,} | {visdrone_count:>12,} | {ratio:>10.2f}")
    
    print()
    
    # å¯¹æ¯”bboxå°ºå¯¸
    print("Bboxå°ºå¯¸å¯¹æ¯”:")
    print(f"{'æŒ‡æ ‡':<20} | {'UAVDT':>12} | {'VisDrone':>12}")
    print("-" * 50)
    
    metrics = [
        ('å¹³å‡å®½åº¦', np.mean(uavdt_stats['bbox_widths']), np.mean(visdrone_stats['bbox_widths'])),
        ('å¹³å‡é«˜åº¦', np.mean(uavdt_stats['bbox_heights']), np.mean(visdrone_stats['bbox_heights'])),
        ('å¹³å‡é¢ç§¯', np.mean(uavdt_stats['bbox_areas']), np.mean(visdrone_stats['bbox_areas'])),
        ('ä¸­ä½æ•°å®½åº¦', np.median(uavdt_stats['bbox_widths']), np.median(visdrone_stats['bbox_widths'])),
        ('ä¸­ä½æ•°é«˜åº¦', np.median(uavdt_stats['bbox_heights']), np.median(visdrone_stats['bbox_heights'])),
    ]
    
    for metric_name, uavdt_val, visdrone_val in metrics:
        print(f"{metric_name:<20} | {uavdt_val:>12.1f} | {visdrone_val:>12.1f}")
    
    print()
    
    # å°ç›®æ ‡æ¯”ä¾‹å¯¹æ¯”
    uavdt_small = sum(1 for area in uavdt_stats['bbox_areas'] if area < 32*32)
    visdrone_small = sum(1 for area in visdrone_stats['bbox_areas'] if area < 32*32)
    uavdt_small_ratio = uavdt_small / len(uavdt_stats['bbox_areas']) * 100
    visdrone_small_ratio = visdrone_small / len(visdrone_stats['bbox_areas']) * 100
    
    print("å°ç›®æ ‡(<32x32)æ¯”ä¾‹:")
    print(f"  UAVDT:    {uavdt_small:>8,} / {len(uavdt_stats['bbox_areas']):>8,} ({uavdt_small_ratio:.2f}%)")
    print(f"  VisDrone: {visdrone_small:>8,} / {len(visdrone_stats['bbox_areas']):>8,} ({visdrone_small_ratio:.2f}%)")
    print()


def main():
    parser = argparse.ArgumentParser(description="UAVDTæ ‡æ³¨è´¨é‡ç»¼åˆæ£€æŸ¥å·¥å…·")
    parser.add_argument('--uavdt_root', type=str, required=True,
                       help='UAVDTæ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--visdrone_root', type=str, default=None,
                       help='VisDroneæ•°æ®é›†æ ¹ç›®å½• (ç”¨äºå¯¹æ¯”)')
    parser.add_argument('--splits', nargs='+', default=['train', 'val'],
                       help='è¦æ£€æŸ¥çš„splits (é»˜è®¤: train val)')
    parser.add_argument('--output_dir', type=str, default='./uavdt_annotation_analysis',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--num_visualize', type=int, default=100,
                       help='å¯è§†åŒ–çš„å›¾åƒæ•°é‡')
    parser.add_argument('--skip_vis', action='store_true',
                       help='è·³è¿‡å¯è§†åŒ– (ä»…åšç»Ÿè®¡åˆ†æ)')
    
    args = parser.parse_args()
    
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("="*80)
    print("ğŸ” UAVDTæ ‡æ³¨è´¨é‡ç»¼åˆæ£€æŸ¥å·¥å…·")
    print("="*80)
    print(f"UAVDTæ ¹ç›®å½•: {args.uavdt_root}")
    print(f"è¾“å‡ºç›®å½•:     {args.output_dir}")
    print(f"æ£€æŸ¥splits:   {args.splits}")
    print("="*80)
    
    # æ£€æŸ¥UAVDT
    uavdt_checker = AnnotationChecker(args.uavdt_root, "UAVDT")
    uavdt_results = {}
    
    for split in args.splits:
        stats = uavdt_checker.check_split(split)
        if stats:
            uavdt_results[split] = stats
            uavdt_checker.print_statistics(stats)
            
            # ç»˜åˆ¶ç»Ÿè®¡å›¾
            plot_file = output_dir / f"uavdt_{split}_stats.png"
            uavdt_checker.plot_statistics(stats, plot_file)
            
            # å¯è§†åŒ–
            if not args.skip_vis:
                vis_dir = output_dir / f"visualizations_{split}"
                uavdt_checker.visualize_annotations(split, args.num_visualize, vis_dir)
    
    # å¦‚æœæä¾›äº†VisDroneè·¯å¾„,è¿›è¡Œå¯¹æ¯”
    if args.visdrone_root and 'train' in uavdt_results:
        visdrone_checker = AnnotationChecker(args.visdrone_root, "VisDrone")
        visdrone_stats = visdrone_checker.check_split('train')
        
        if visdrone_stats:
            visdrone_checker.print_statistics(visdrone_stats)
            compare_datasets(uavdt_results['train'], visdrone_stats, output_dir)
    
    # ä¿å­˜å®Œæ•´æŠ¥å‘Š
    report_file = output_dir / "annotation_quality_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        serializable_results = {}
        for split, stats in uavdt_results.items():
            serializable_results[split] = {
                'total_images': stats['total_images'],
                'total_objects': stats['total_objects'],
                'category_count': dict(stats['category_count']),
                'num_abnormal_boxes': len(stats['abnormal_boxes']),
                'num_empty_images': len(stats['empty_images']),
                'num_errors': len(stats['errors']),
                'bbox_stats': {
                    'width_mean': float(np.mean(stats['bbox_widths'])) if stats['bbox_widths'] else 0,
                    'height_mean': float(np.mean(stats['bbox_heights'])) if stats['bbox_heights'] else 0,
                    'area_mean': float(np.mean(stats['bbox_areas'])) if stats['bbox_areas'] else 0,
                },
                'abnormal_boxes_sample': stats['abnormal_boxes'][:100],
            }
        json.dump(serializable_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"\nğŸ‰ æ£€æŸ¥å®Œæˆ! æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_dir}")


if __name__ == "__main__":
    main()
