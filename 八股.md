# ğŸ“š å…«è‚¡çŸ¥è¯†ç‚¹ - Depth å›¾åƒæ ¼å¼ä¸ä¿¡æ¯ç†µ

## [çŸ¥è¯†ç‚¹ 001] ä¸ºä»€ä¹ˆ Depth å›¾åƒå¿…é¡»ç”¨ 16-bit ä¿å­˜?

### æ ‡å‡†ä¾‹å­

**ç»å…¸åœºæ™¯**: è‡ªåŠ¨é©¾é©¶ä¸­çš„ LiDAR æ·±åº¦å›¾

```python
# åœºæ™¯å‚æ•°
scene_range = 100  # ç±³
target_precision = 0.05  # 5å˜ç±³ç²¾åº¦è¦æ±‚ (å°è½¦æ£€æµ‹)

# 8-bit depth
levels_8bit = 256
precision_8bit = scene_range / levels_8bit
# = 100m / 256 = 0.39m = 39cm âŒ æ— æ³•æ»¡è¶³5cmè¦æ±‚

# 16-bit depth
levels_16bit = 65536
precision_16bit = scene_range / levels_16bit
# = 100m / 65536 = 0.0015m = 1.5mm âœ… è¿œè¶…5cmè¦æ±‚
```

**ç»“è®º**: 8-bit depth æ— æ³•æä¾›è¶³å¤Ÿç²¾åº¦ç”¨äºå°ç›®æ ‡æ£€æµ‹

---

### æœ¬é¡¹ç›®åº”ç”¨

**UAV ç›®æ ‡æ£€æµ‹åœºæ™¯**:

- é£è¡Œé«˜åº¦: 20-100 ç±³
- ç›®æ ‡å°ºå¯¸: è½¦è¾†(1-5 ç±³), è¡Œäºº(0.5 ç±³)
- å…³é”®éœ€æ±‚: åŒºåˆ†è¿œè¿‘ç›®æ ‡ä»¥å­¦ä¹ è·ç¦»-å°ºå¯¸å…ˆéªŒ

**å®é™…å¯¹æ¯”**:

```python
# åœºæ™¯: æ£€æµ‹50ç±³å¤–çš„è½¦è¾† vs 20ç±³å¤–çš„è½¦è¾†

# 16-bit depth (æ­£å¸¸)
car_50m: depth_value = 50000  # 50ç±³ = 50000æ¯«ç±³
car_20m: depth_value = 20000  # 20ç±³ = 20000æ¯«ç±³
å·®å¼‚: 30000çº§ â†’ æ¨¡å‹èƒ½æ¸…æ¥šåŒºåˆ†

# 8-bit depth (é™è´¨)
car_50m: depth_value = 128  # (50000/65535)*255 â‰ˆ 128
car_20m: depth_value = 51   # (20000/65535)*255 â‰ˆ 51
å·®å¼‚: 77çº§ â†’ ä¿¡æ¯é‡å¤ªä½,æ¨¡å‹å‡ ä¹å­¦ä¸åˆ°æœ‰æ•ˆç‰¹å¾
```

**è®­ç»ƒæ•ˆæœè¯æ˜**:

```
16-bit depthè®­ç»ƒ: mAP 40-42% (RGB+DåŒæ¨¡æ€æœ‰æ•ˆ)
8-bit depthè®­ç»ƒ:  mAP 21% (æ¥è¿‘çº¯RGBçš„22%,depthå‡ ä¹æ— è´¡çŒ®)
```

---

### æ·±å…¥è®²è§£

#### 1. ä¿¡æ¯ç†µç†è®º

**ä¿¡æ¯ç†µå®šä¹‰**:

```
H = logâ‚‚(N)
N: å¯èƒ½çŠ¶æ€æ•°é‡
H: ä¿¡æ¯é‡(bits)

8-bit depth:  H = logâ‚‚(256)   = 8 bits
16-bit depth: H = logâ‚‚(65536) = 16 bits

ä¿¡æ¯é‡å·®å¼‚: 16 - 8 = 8 bits = 2â¸å€ = 256å€!
```

**æ·±åº¦ç¥ç»ç½‘ç»œçš„è§’åº¦**:

```python
# å·ç§¯å±‚å­¦ä¹ depthç‰¹å¾

# 8-bitè¾“å…¥: 256ä¸ªç¦»æ•£å€¼
conv_input_8bit = [0, 1, 2, ..., 255]
# â†’ ç‰¹å¾ç©ºé—´ç¨€ç–,æ¢¯åº¦ä¿¡å·å¼±

# 16-bitè¾“å…¥: 65536ä¸ªç¦»æ•£å€¼
conv_input_16bit = [0, 1, 2, ..., 65535]
# â†’ ç‰¹å¾ç©ºé—´è¿ç»­,æ¢¯åº¦ä¿¡å·å¼º
```

#### 2. é‡åŒ–è¯¯å·®åˆ†æ

**é‡åŒ–è¯¯å·®å…¬å¼**:

```
E_quantization = (max_value - min_value) / (2^bits - 1)

åœºæ™¯èŒƒå›´: 0.5m - 100m

8-bit:  E = 99.5m / 255 = 0.39m = 39cm
16-bit: E = 99.5m / 65535 = 0.0015m = 1.5mm

è¯¯å·®æ¯”: 39cm / 1.5mm = 260å€
```

**å¯¹å°ç›®æ ‡çš„å½±å“**:

```
å°ç›®æ ‡è¾¹ç•Œæ¡†: 32x32 pixels
æ·±åº¦å˜åŒ–: 20m â†’ 20.5m (ç‰©ä½“è¾¹ç¼˜åˆ°ä¸­å¿ƒ)

8-bit depth:
  20.0m â†’ depth=51
  20.5m â†’ depth=51 (same!)
  â†’ è¾¹ç•Œæ¡†å†…éƒ¨depthå®Œå…¨å‡åŒ€,æ— çº¹ç†ç‰¹å¾

16-bit depth:
  20.0m â†’ depth=20000
  20.5m â†’ depth=20500
  â†’ è¾¹ç•Œæ¡†å†…æœ‰500çº§å˜åŒ–,ç½‘ç»œèƒ½å­¦åˆ°å½¢çŠ¶ä¿¡æ¯
```

#### 3. PIL Image Mode é™·é˜±

**PIL Image çš„æ¨¡å¼ç³»ç»Ÿ**:

```python
from PIL import Image

# I mode: 32-bit signed integer
img_I = Image.fromarray(depth_int32, mode='I')
print(img_I.mode)  # 'I'
print(depth_int32.min(), depth_int32.max())  # 0, 50000

# é”™è¯¯æ“ä½œ: convert('L')
img_L = img_I.convert('L')  # âŒ ä¸å¯é€†çš„é™è´¨!
print(img_L.mode)  # 'L' (8-bit)

# ä¿å­˜æ—¶çš„éšè—é™·é˜±
img_I.save('depth.png')  # é»˜è®¤ä¼šè½¬ä¸º8-bit! âŒ

# æ­£ç¡®ä¿å­˜16-bitçš„æ–¹æ³•
depth_uint16 = depth.astype(np.uint16)
cv2.imwrite('depth.png', depth_uint16)  # âœ…
```

**æ¨¡å¼è½¬æ¢çŸ©é˜µ**:

| æºæ¨¡å¼      | convert('L')  | convert('I')                  | astype(uint16)                |
| ----------- | ------------- | ----------------------------- | ----------------------------- |
| I (32-bit)  | âŒ é™ä¸º 8-bit | âœ… ä¿æŒ                       | âœ… è½¬ä¸º 16-bit                |
| L (8-bit)   | âœ… ä¿æŒ       | âš ï¸ å‡ä¸º 32-bit ä½†æ— æ³•æ¢å¤ç²¾åº¦ | âš ï¸ å‡ä¸º 16-bit ä½†æ— æ³•æ¢å¤ç²¾åº¦ |
| F (float32) | âŒ é™ä¸º 8-bit | âœ… è½¬ä¸º 32-bit                | âœ… è½¬ä¸º 16-bit                |

**æ˜“é”™ç‚¹**: convert('L')æ˜¯**å•å‘é—¨**,ä¸€æ—¦æ‰§è¡Œæ— æ³•æ¢å¤åŸå§‹ç²¾åº¦!

---

### å¸¸è§è¿½é—®ä¸ç­”æ¡ˆ

**Q1: "8-bit depth åœ¨ä»€ä¹ˆæƒ…å†µä¸‹å¯ä»¥æ¥å—?"**

**A**: å‡ ä¹æ²¡æœ‰,é™¤é:

1. **åœºæ™¯æ·±åº¦æå°** (<5 ç±³,å¦‚å®¤å†…æ¡Œé¢ç‰©ä½“)
   - ç²¾åº¦: 5m/256 = 2cm âœ… å‹‰å¼ºå¯æ¥å—
2. **åªåšç²—ç²’åº¦åˆ†ç±»** (è¿‘æ™¯ 0-10m, ä¸­æ™¯ 10-30m, è¿œæ™¯ 30m+)
   - ä¸éœ€è¦ç²¾ç¡®è·ç¦»,åªéœ€åŒºé—´
3. **Depth ä»…ä½œè¾…åŠ©æç¤º** (ä¸»è¦é  RGB,depth æƒé‡æå°)
   - å¦‚ attention mask: åªåˆ¤æ–­"æœ‰ç‰©ä½“"vs"æ— ç‰©ä½“"

**å…¸å‹åä¾‹ (8-bit ç»å¯¹ä¸å¯ç”¨)**:

- UAV ç›®æ ‡æ£€æµ‹ (æœ¬é¡¹ç›®) âŒ
- è‡ªåŠ¨é©¾é©¶ âŒ
- æœºå™¨äººæŠ“å– âŒ
- ä¸‰ç»´é‡å»º âŒ

---

**Q2: "ä¸ºä»€ä¹ˆä¸ç”¨ 32-bit float depth?"**

**A**:

ä¼˜ç‚¹:

- ç²¾åº¦æ— é™é«˜ (æµ®ç‚¹è¡¨ç¤º)
- é€‚åˆä¸­é—´è®¡ç®—

ç¼ºç‚¹:

- å­˜å‚¨ç©ºé—´ 2 å€äº 16-bit
- ä¼ æ„Ÿå™¨åŸå§‹æ•°æ®é€šå¸¸æ˜¯ uint16,è½¬ float32 æ²¡æœ‰å®é™…ç²¾åº¦æå‡
- æ·±åº¦å­¦ä¹ æ¡†æ¶åŠ è½½å›¾åƒé»˜è®¤è½¬ uint8,éœ€è¦ç‰¹æ®Šå¤„ç†

**æ¨èæ–¹æ¡ˆ**:

```python
# ä¼ æ„Ÿå™¨è¾“å‡º â†’ ä¿å­˜
depth_sensor = lidar.get_depth()  # float32, å•ä½:ç±³
depth_mm = (depth_sensor * 1000).astype(np.uint16)  # è½¬ä¸ºæ¯«ç±³çº§uint16
cv2.imwrite('depth.png', depth_mm)  # ä¿å­˜ä¸º16-bit PNG

# æ¨¡å‹è®­ç»ƒ â†’ åŠ è½½
depth_uint16 = cv2.imread('depth.png', cv2.IMREAD_UNCHANGED)  # uint16
depth_float = depth_uint16.astype(np.float32) / 1000.0  # è½¬å›ç±³
# â†’ è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨float32è®¡ç®—
```

---

**Q3: "å¦‚ä½•åˆ¤æ–­ depth å›¾åƒæ˜¯ 8-bit è¿˜æ˜¯ 16-bit?"**

**A**: ä¸‰ç§æ–¹æ³•

**æ–¹æ³• 1: OpenCV**

```python
import cv2
depth = cv2.imread('depth.png', cv2.IMREAD_UNCHANGED)
print(f"dtype: {depth.dtype}")
# uint8 â†’ 8-bit âŒ
# uint16 â†’ 16-bit âœ…
```

**æ–¹æ³• 2: PIL**

```python
from PIL import Image
img = Image.open('depth.png')
print(f"mode: {img.mode}")
# 'L' â†’ 8-bit âŒ
# 'I;16' â†’ 16-bit âœ…
```

**æ–¹æ³• 3: æ–‡ä»¶å±æ€§**

```python
from pathlib import Path
import struct

def check_png_bit_depth(path):
    with open(path, 'rb') as f:
        f.read(8)  # PNG signature
        while True:
            length = struct.unpack('>I', f.read(4))[0]
            chunk_type = f.read(4)
            if chunk_type == b'IHDR':
                f.read(8)  # width, height
                bit_depth = struct.unpack('>B', f.read(1))[0]
                return bit_depth
            f.read(length + 4)  # skip data + CRC

print(check_png_bit_depth('depth.png'))
# 8 â†’ 8-bit âŒ
# 16 â†’ 16-bit âœ…
```

---

**Q4: "è®­ç»ƒæ—¶æ˜¯å¦éœ€è¦å¯¹ depth åšå½’ä¸€åŒ–?"**

**A**: éœ€è¦,ä½†æ–¹æ³•å¾ˆé‡è¦

**é”™è¯¯åšæ³•**:

```python
# âŒ ç›´æ¥é™¤ä»¥65535 (ä¸¢å¤±è·ç¦»åˆ†å¸ƒä¿¡æ¯)
depth_norm = depth_uint16 / 65535.0  # å…¨éƒ¨æ˜ å°„åˆ°[0, 1]
```

**æ¨èåšæ³•**:

```python
# âœ… åŸºäºåœºæ™¯ç»Ÿè®¡çš„Percentileå½’ä¸€åŒ–
p_low = np.percentile(depth[depth > 0], 5)   # ç¬¬5ç™¾åˆ†ä½
p_high = np.percentile(depth[depth > 0], 95) # ç¬¬95ç™¾åˆ†ä½

depth_clipped = np.clip(depth, p_low, p_high)
depth_norm = (depth_clipped - p_low) / (p_high - p_low)
# â†’ ä¿ç•™ä¸»è¦è·ç¦»åˆ†å¸ƒ,æŠ‘åˆ¶ç¦»ç¾¤å€¼
```

**æœ¬é¡¹ç›®å®ç°** (dataset.py):

```python
@staticmethod
def _process_depth_channel(depth: np.ndarray, target_hw: tuple[int, int]) -> np.ndarray:
    # 1. ä¸­å€¼æ»¤æ³¢ (å»å™ª)
    depth = cv2.medianBlur(depth, 3)

    # 2. é«˜æ–¯æ»¤æ³¢ (å¹³æ»‘)
    depth = cv2.GaussianBlur(depth, (5, 5), 0)

    # 3. Percentileå½’ä¸€åŒ– (ä¿ç•™åˆ†å¸ƒ)
    valid_depth = depth[depth > 0]
    if len(valid_depth) > 0:
        p_low = np.percentile(valid_depth, 5)
        p_high = np.percentile(valid_depth, 95)
        depth = np.clip(depth, p_low, p_high)
        depth = (depth - p_low) / (p_high - p_low + 1e-6)

    # 4. ç½®ä¿¡åº¦åŠ æƒ (æŠ‘åˆ¶æ— æ•ˆåŒºåŸŸ)
    confidence = (depth > 0).astype(np.float32)
    depth = depth * confidence

    return depth
```

---

### æ˜“é”™ç‚¹æç¤º

#### æ˜“é”™ç‚¹ 1: PIL ä¿å­˜ PNG æ—¶çš„éšå¼è½¬æ¢

```python
from PIL import Image
import numpy as np

depth_uint16 = np.random.randint(0, 65535, (100, 100), dtype=np.uint16)
img = Image.fromarray(depth_uint16)

# âŒ é”™è¯¯: é»˜è®¤ä¿å­˜ä¸º8-bit
img.save('depth_wrong.png')
# å†…éƒ¨è°ƒç”¨: img.convert('L').save(...)

# âœ… æ­£ç¡®: æ˜ç¡®æŒ‡å®š16-bit
img.save('depth_correct.png', 'PNG', bits=16)

# æˆ–è€…ç”¨OpenCV (æ¨è)
cv2.imwrite('depth_opencv.png', depth_uint16)
```

#### æ˜“é”™ç‚¹ 2: NumPy æ•°ç»„è½¬ Image æ—¶çš„ mode æ¨æ–­

```python
# uint16æ•°ç»„ â†’ PIL Image
depth_uint16 = np.array([[1000, 2000], [3000, 4000]], dtype=np.uint16)

# âŒ é”™è¯¯: PILè‡ªåŠ¨æ¨æ–­ä¸º'I' (32-bit)
img_wrong = Image.fromarray(depth_uint16)
print(img_wrong.mode)  # 'I' (ä¸æ˜¯'I;16'!)

# âœ… æ­£ç¡®: æ˜ç¡®æŒ‡å®šmode
img_correct = Image.fromarray(depth_uint16, mode='I;16')
print(img_correct.mode)  # 'I;16'
```

#### æ˜“é”™ç‚¹ 3: OpenCV imread çš„ flags å‚æ•°

```python
# âŒ é”™è¯¯: ä½¿ç”¨é»˜è®¤flags (ä¼šè½¬ä¸ºBGR 3é€šé“)
depth_wrong = cv2.imread('depth.png')  # é»˜è®¤flags=cv2.IMREAD_COLOR
print(depth_wrong.shape)  # (H, W, 3) âŒ æ·±åº¦å›¾è¢«è½¬ä¸º3é€šé“!

# âœ… æ­£ç¡®: ä½¿ç”¨IMREAD_UNCHANGED
depth_correct = cv2.imread('depth.png', cv2.IMREAD_UNCHANGED)
print(depth_correct.shape)  # (H, W) âœ… ä¿æŒå•é€šé“
print(depth_correct.dtype)  # uint16 âœ… ä¿æŒ16-bit
```

---

### æ‹“å±•é˜…è¯»

1. **PNG è§„èŒƒ - Bit Depth**:

   - [PNG Specification - IHDR Chunk](https://www.w3.org/TR/PNG/#11IHDR)
   - æ”¯æŒçš„ bit depth: 1, 2, 4, 8, 16

2. **æ·±åº¦å›¾è¡¨ç¤ºæ–¹æ³•å¯¹æ¯”**:

   - [A Survey on Deep Learning for Monocular Depth Estimation](https://arxiv.org/abs/2003.06620)
   - å¯¹æ¯” uint16, float32, log-depth ç­‰è¡¨ç¤º

3. **ä¿¡æ¯ç†µä¸é‡åŒ–è¯¯å·®**:

   - [Rate-Distortion Theory](https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory)
   - é‡åŒ–ä½æ•°ä¸ä¿¡æ¯æŸå¤±çš„æ•°å­¦å…³ç³»

4. **PIL vs OpenCV å›¾åƒå¤„ç†å¯¹æ¯”**:
   - [OpenCV Python Tutorial - Image I/O](https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html)
   - [Pillow Documentation - Image Modes](https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes)

---

### æ€è€ƒé¢˜

**ç»ƒä¹  1: è®¡ç®—ç²¾åº¦éœ€æ±‚**

åœºæ™¯: æ— äººæœºåœ¨ 50 ç±³é«˜åº¦æ£€æµ‹è½¦è¾† (é•¿åº¦ 4 ç±³)

é—®é¢˜:

1. è‹¥è¦æ±‚ depth ç²¾åº¦è¾¾åˆ°è½¦è¾†é•¿åº¦çš„ 1%,éœ€è¦å¤šå°‘ bit?
2. 8-bit depth åœ¨è¯¥åœºæ™¯ä¸‹çš„æœ€å¤§å¯æ£€æµ‹è·ç¦»æ˜¯å¤šå°‘?

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**ç­”æ¡ˆ 1**:

```
ç²¾åº¦è¦æ±‚: 4m * 1% = 0.04m = 4cm
åœºæ™¯èŒƒå›´: å‡è®¾0-100m

æ‰€éœ€çº§æ•°: 100m / 0.04m = 2500çº§
æ‰€éœ€bitæ•°: logâ‚‚(2500) â‰ˆ 11.3 bits â†’ è‡³å°‘12-bit

ç»“è®º: 8-bit (256çº§) è¿œè¿œä¸å¤Ÿ, 16-bit (65536çº§) è¶³å¤Ÿ
```

**ç­”æ¡ˆ 2**:

```
8-bitç²¾åº¦: 100m / 256 = 39cm

å¯æ£€æµ‹è·ç¦»: å½“ç‰©ä½“æ·±åº¦å˜åŒ– < 39cmæ—¶,depthå€¼ç›¸åŒ
è½¦è¾†é•¿åº¦4mæ—¶: 4m / 39cm = 10.2ä¸ªdepthçº§åˆ«

æœ€è¿œå¯æ£€æµ‹è·ç¦»: çº¦50-100m (ä½†ç²¾åº¦æä½)
è¶…è¿‡100m: depthå€¼é¥±å’Œ,æ— æ³•åŒºåˆ†
```

</details>

---

**ç»ƒä¹  2: è¯Šæ–­ depth åŠ è½½é—®é¢˜**

ç»™å®šä»£ç ç‰‡æ®µ,åˆ¤æ–­æ˜¯å¦ä¼šä¸¢å¤±ç²¾åº¦:

```python
from PIL import Image
import cv2

# ä»£ç ç‰‡æ®µA
depth = cv2.imread('depth.png', cv2.IMREAD_GRAYSCALE)

# ä»£ç ç‰‡æ®µB
depth = Image.open('depth.png').convert('L')
depth = np.array(depth)

# ä»£ç ç‰‡æ®µC
depth = cv2.imread('depth.png', cv2.IMREAD_UNCHANGED)
```

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**ä»£ç ç‰‡æ®µ A**: âŒ ä¼šä¸¢å¤±ç²¾åº¦

- `IMREAD_GRAYSCALE` = `IMREAD_COLOR` with grayscale conversion
- å¼ºåˆ¶è½¬ä¸º 8-bit,å³ä½¿åŸå›¾æ˜¯ 16-bit

**ä»£ç ç‰‡æ®µ B**: âŒ ä¼šä¸¢å¤±ç²¾åº¦

- `convert('L')` å¼ºåˆ¶è½¬ä¸º 8-bit
- PIL çš„ convert æ˜¯ä¸å¯é€†æ“ä½œ

**ä»£ç ç‰‡æ®µ C**: âœ… ä¸ä¼šä¸¢å¤±ç²¾åº¦

- `IMREAD_UNCHANGED` ä¿ç•™åŸå§‹ bit depth
- å¦‚æœåŸå›¾æ˜¯ 16-bit uint16,åŠ è½½åä»æ˜¯ uint16

</details>

---

**ç»ƒä¹  3: æ‰‹æ’•ä»£ç  - å®ç° Percentile å½’ä¸€åŒ–**

è¦æ±‚:

1. è¾“å…¥: uint16 depth å›¾ (shape: HÃ—W)
2. è¾“å‡º: float32 å½’ä¸€åŒ– depth (range: [0, 1])
3. è¦æ±‚: ä½¿ç”¨ 5th-95th percentile è£å‰ª,å¿½ç•¥é›¶å€¼

```python
def percentile_normalize_depth(depth: np.ndarray) -> np.ndarray:
    """
    Args:
        depth: uint16, shape (H, W)
    Returns:
        depth_norm: float32, shape (H, W), range [0, 1]
    """
    # TODO: ä½ çš„å®ç°
    pass
```

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

```python
def percentile_normalize_depth(depth: np.ndarray) -> np.ndarray:
    """
    Args:
        depth: uint16, shape (H, W)
    Returns:
        depth_norm: float32, shape (H, W), range [0, 1]
    """
    # 1. æå–æœ‰æ•ˆdepthå€¼ (æ’é™¤é›¶å€¼/æ— æ•ˆå€¼)
    valid_mask = depth > 0
    valid_depth = depth[valid_mask]

    # 2. å¤„ç†è¾¹ç•Œæƒ…å†µ
    if len(valid_depth) == 0:
        return np.zeros_like(depth, dtype=np.float32)

    # 3. è®¡ç®—5thå’Œ95thç™¾åˆ†ä½æ•°
    p_low = np.percentile(valid_depth, 5)
    p_high = np.percentile(valid_depth, 95)

    # 4. Clipping
    depth_clipped = np.clip(depth.astype(np.float32), p_low, p_high)

    # 5. å½’ä¸€åŒ–åˆ°[0, 1]
    depth_range = p_high - p_low
    if depth_range < 1e-6:  # é˜²æ­¢é™¤é›¶
        return np.zeros_like(depth, dtype=np.float32)

    depth_norm = (depth_clipped - p_low) / depth_range

    # 6. ä¿ç•™æ— æ•ˆåŒºåŸŸä¸º0
    depth_norm[~valid_mask] = 0.0

    return depth_norm

# æµ‹è¯•
depth_uint16 = np.random.randint(0, 65535, (100, 100), dtype=np.uint16)
depth_uint16[50:, :] = 0  # æ¨¡æ‹Ÿæ— æ•ˆåŒºåŸŸ
depth_norm = percentile_normalize_depth(depth_uint16)
print(f"Output dtype: {depth_norm.dtype}")  # float32
print(f"Output range: [{depth_norm.min()}, {depth_norm.max()}]")  # [0.0, 1.0]
print(f"Zero preserved: {(depth_norm[50:, :] == 0).all()}")  # True
```

**å…³é”®ç‚¹**:

- ç”¨`valid_mask`åˆ†ç¦»æœ‰æ•ˆ/æ— æ•ˆåŒºåŸŸ
- `np.percentile`å‰å¿…é¡»è¿‡æ»¤é›¶å€¼
- Clipping é˜²æ­¢ç¦»ç¾¤å€¼
- é™¤æ³•å‰æ£€æŸ¥`depth_range`é¿å…é™¤é›¶
- æœ€åæ¢å¤æ— æ•ˆåŒºåŸŸä¸º 0

</details>

---

## [çŸ¥è¯†ç‚¹ 002] RGB-D èåˆä¸­çš„æ¨¡æ€å¯¹é½

(å¾…è¡¥å…… - å°†åœ¨åç»­èåˆæ¨¡å—æ”¹è¿›æ—¶æ·»åŠ )

---

## [çŸ¥è¯†ç‚¹ 003] å°ç›®æ ‡æ£€æµ‹çš„æŸå¤±å‡½æ•°è®¾è®¡

(å¾…è¡¥å…… - å°†åœ¨æŸå¤±å‡½æ•°ä¼˜åŒ–æ—¶æ·»åŠ )

---

## [çŸ¥è¯†ç‚¹ 039] Ultralytics å¤šæ•°æ®é›†è”åˆè®­ç»ƒæœºåˆ¶

**è¯¦ç»†æ–‡æ¡£**: è§ `å…«è‚¡_çŸ¥è¯†ç‚¹39_å¤šæ•°æ®é›†è”åˆè®­ç»ƒæœºåˆ¶.md`

### å¿«é€Ÿæ€»ç»“

**æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•åœ¨ä¸€æ¬¡è®­ç»ƒä¸­åŒæ—¶ä½¿ç”¨ VisDrone å’Œ UAVDT ä¸¤ä¸ªæ•°æ®é›†ï¼Ÿ

**Ultralytics æ–¹æ¡ˆ**:

1. **YAML é…ç½®**: ç”¨åˆ—è¡¨æŒ‡å®šå¤šä¸ªæ•°æ®é›†è·¯å¾„

   ```yaml
   train:
     - VisDroneè·¯å¾„ # 6,471å¼ 
     - UAVDTè·¯å¾„ # 23,258å¼ 
   ```

2. **è‡ªåŠ¨æ‹¼æ¥**: `YOLOConcatDataset` æ— ç¼æ‹¼æ¥ä¸ºå•ä¸ªå¤§æ•°æ®é›† (29,729 å¼ )

3. **é€æ˜è®­ç»ƒ**: æ¨¡å‹æ— æ„ŸçŸ¥æ•°æ®æ¥è‡ªå¤šä¸ªæº,æŒ‰ç»Ÿä¸€ç´¢å¼•éšæœºé‡‡æ ·

**é‡‡æ ·ç­–ç•¥**:

- **é»˜è®¤**: ç­‰æ¦‚ç‡é‡‡æ · (VisDrone 21.8%, UAVDT 78.2%)
- **å¯é€‰**: åŠ æƒé‡‡æ · (éœ€è‡ªå®šä¹‰ Sampler,å¹³è¡¡æ•°æ®é›†æ¯”ä¾‹)

**å…³é”®ç±»**:

- `check_det_dataset()`: è§£æ YAML,æ”¯æŒå­—ç¬¦ä¸²æˆ–åˆ—è¡¨è·¯å¾„
- `build_yolo_dataset()`: æ£€æµ‹åˆ—è¡¨ç±»å‹,åˆ›å»ºå¤šæ•°æ®é›†
- `YOLOConcatDataset`: ç»§æ‰¿ PyTorch `ConcatDataset`,å¤„ç†ç´¢å¼•æ˜ å°„

**å¸¸è§é—®é¢˜**:

- âœ… ç±»åˆ«ä¸ä¸€è‡´? â†’ YAML é…ç½® `uavdt_class_mapping` æ˜ å°„ç±»åˆ«
- âœ… æ·±åº¦å›¾è´¨é‡? â†’ ä½¿ç”¨ç›¸åŒæ¨¡å‹å’Œå‚æ•°ç”Ÿæˆ
- âœ… ç›‘æ§åˆ†å¸ƒ? â†’ åœ¨ callback ä¸­è®°å½•æ¯ä¸ª batch çš„æ•°æ®é›†æ¥æº
- âœ… éªŒè¯é›†? â†’ RemDet åè®®åªåœ¨ VisDrone val ä¸ŠéªŒè¯

---

## æ›´æ–°æ—¥å¿—

- 2025-11-16: åˆ›å»ºçŸ¥è¯†ç‚¹ 039 - å¤šæ•°æ®é›†è”åˆè®­ç»ƒæœºåˆ¶
- 2024-01-XX: åˆ›å»ºçŸ¥è¯†ç‚¹ 001 - Depth å›¾åƒæ ¼å¼ä¸ä¿¡æ¯ç†µ
- å¾…è¡¥å……: çŸ¥è¯†ç‚¹ 002-003 å°†åœ¨åç»­ç ”ç©¶è¿›å±•ä¸­æ·»åŠ 
