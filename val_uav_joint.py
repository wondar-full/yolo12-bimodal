#!/usr/bin/env python3
"""
=====================================================================
YOLO12-S RGB-D Joint Validation Script (RemDet-Aligned)
=====================================================================
Created: 2025-11-16
Purpose: Validate RGB-D model on VisDrone val set (RemDet protocol)
Goal: Compare with RemDet-X 45.2% mAP@0.5 baseline

RemDet Evaluation Protocol:
- Dataset: VisDrone val set ONLY (548 images)
- Metrics: COCO-style AP (mAP@0.5, mAP@0.5:0.95, AP_small/medium/large)
- No UAVDT val set used (even though trained on both datasets)

Usage:
    # Validate best checkpoint
    python val_uav_joint.py \
        --weights runs/train/rgbd_v2.1_joint_300ep/weights/best.pt \
        --data data/uav-joint-rgbd.yaml
    
    # Validate specific checkpoint with custom settings
    python val_uav_joint.py \
        --weights runs/train/rgbd_v2.1_joint_300ep/weights/epoch_250.pt \
        --data data/uav-joint-rgbd.yaml \
        --imgsz 640 \
        --batch 16 \
        --conf 0.001 \
        --iou 0.6 \
        --device 0
=====================================================================
"""

import argparse
import json
import math
import sys
from pathlib import Path
from typing import Dict, Tuple

from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.metrics import DetMetrics
from ultralytics.utils.metrics_export import register_metrics_export

# =====================================================================
# RemDet Baselines (from paper Table 2)
# =====================================================================

REMDET_BASELINES = {
    "RemDet-Tiny": {
        "AP@[0.5:0.95]": 20.3,  # AP^val from Table 1
        "AP@0.50": 33.5,        # AP^val_50 from Table 1
        "AP_small": 10.2,       # AP^val_s from Table 1
        "Params(M)": 3.1,
        "FLOPs(G)": 5.1,
        "Latency(ms)": 13.2,
    },
    "RemDet-S": {
        "AP@[0.5:0.95]": 25.5,
        "AP@0.50": 42.3,
        "AP_small": 15.9,
        "Params(M)": 5.7,
        "FLOPs(G)": 10.2,
        "Latency(ms)": 4.8,
    },
    "RemDet-M": {
        "AP@[0.5:0.95]": 27.8,
        "AP@0.50": 45.0,
        "AP_small": 17.6,
        "Params(M)": 8.2,
        "FLOPs(G)": 13.7,
        "Latency(ms)": 6.5,
    },
    "RemDet-L": {
        "AP@[0.5:0.95]": 29.3,  # AP^val from Table 1
        "AP@0.50": 47.4,        # AP^val_50 from Table 1
        "AP_small": 18.7,       # AP^val_s from Table 1
        "Params(M)": 8.9,
        "FLOPs(G)": 67.4,
        "Latency(ms)": 7.1,
    },
    "RemDet-X": {
        "AP@[0.5:0.95]": 29.9,  # AP^val from Table 1
        "AP@0.50": 48.3,        # AP^val_50 from Table 1 âš ï¸ æ›´æ­£ä¸º48.3%!
        "AP_small": 19.5,       # AP^val_s from Table 1
        "Params(M)": 9.8,
        "FLOPs(G)": 114,
        "Latency(ms)": 8.9,
    },
}

# Our RGB-only baseline (VisDrone-only training)
RGB_BASELINE = {
    "AP@[0.5:0.95]": 24.1,
    "AP@0.50": 40.4,
    "AP_small": 14.2,
}

# Our RGB-D v2.1 baseline (VisDrone-only training, 244 epochs)
RGBD_V2_1_BASELINE = {
    "AP@[0.5:0.95]": 26.3,
    "AP@0.50": 43.5,
    "AP_small": 16.1,
}

# =====================================================================
# Utility Functions
# =====================================================================


def _as_percent(value: float | int | None) -> float:
    """Convert a metric in [0, 1] to percentage with two decimals."""
    if value is None:
        return float("nan")
    try:
        return round(float(value) * 100.0, 2)
    except (TypeError, ValueError):
        return float("nan")


def _safe_get(d: Dict[str, float], key: str) -> float:
    """Safely get a value from dictionary."""
    value = d.get(key)
    return float(value) if value is not None else float("nan")


def _print_header(title: str) -> None:
    """Print a formatted header."""
    LOGGER.info("\n" + "=" * 80)
    LOGGER.info(f"{title:^80}")
    LOGGER.info("=" * 80)


def _print_metric_table(results_pct: Dict[str, float], latency_ms: float, params_m: float, flops_g: float) -> None:
    """Print COCO-style metrics in a formatted table."""
    _print_header("VisDrone Validation Results (COCO Metrics)")
    
    rows = [
        ("AP@[0.5:0.95]", results_pct.get("AP@[0.5:0.95]")),
        ("AP@0.50", results_pct.get("AP@0.50")),
        ("AP@0.75", results_pct.get("AP@0.75")),
        ("AP_small", results_pct.get("AP_small")),
        ("AP_medium", results_pct.get("AP_medium")),
        ("AP_large", results_pct.get("AP_large")),
    ]
    
    LOGGER.info("Metric                | Value (%)")
    LOGGER.info("----------------------+----------")
    for name, value in rows:
        value_str = f"{value:6.2f}" if value is not None and not math.isnan(value) else "  NaN"
        LOGGER.info(f"{name:<21} | {value_str}")
    LOGGER.info("----------------------+----------")
    
    # Model efficiency metrics
    LOGGER.info(f"Params (M)           | {params_m:6.2f}")
    LOGGER.info(f"FLOPs (G)            | {flops_g:6.2f}")
    LOGGER.info(f"Latency (ms)         | {latency_ms:6.2f}")
    LOGGER.info("=" * 80 + "\n")


def _print_baseline_comparison(results_pct: Dict[str, float]) -> None:
    """Print comparison with RemDet and our baselines."""
    _print_header("Comparison with Baselines")
    
    metrics = ["AP@[0.5:0.95]", "AP@0.50", "AP_small"]
    
    # Header
    header = f"{'Metric':<16} | {'Yours':>7} | {'RGB-D v2.1':>10} | {'Î”':>6} | {'RemDet-X':>9} | {'Î”':>6} | {'RGB-only':>9} | {'Î”':>6}"
    LOGGER.info(header)
    LOGGER.info("-" * len(header))
    
    # Metrics rows
    for metric in metrics:
        ours = results_pct.get(metric, float("nan"))
        v21 = RGBD_V2_1_BASELINE.get(metric, float("nan"))
        remdet_x = REMDET_BASELINES["RemDet-X"].get(metric, float("nan"))
        rgb_only = RGB_BASELINE.get(metric, float("nan"))
        
        delta_v21 = ours - v21 if not math.isnan(ours) and not math.isnan(v21) else float("nan")
        delta_remdet = ours - remdet_x if not math.isnan(ours) and not math.isnan(remdet_x) else float("nan")
        delta_rgb = ours - rgb_only if not math.isnan(ours) and not math.isnan(rgb_only) else float("nan")
        
        LOGGER.info(
            f"{metric:<16} | "
            f"{ours:7.2f} | "
            f"{v21:10.2f} | "
            f"{delta_v21:+6.2f} | "
            f"{remdet_x:9.2f} | "
            f"{delta_remdet:+6.2f} | "
            f"{rgb_only:9.2f} | "
            f"{delta_rgb:+6.2f}"
        )
    
    LOGGER.info("=" * len(header) + "\n")
    
    # Success criteria
    LOGGER.info("Success Criteria:")
    target_ap50 = REMDET_BASELINES["RemDet-X"]["AP@0.50"]
    achieved_ap50 = results_pct.get("AP@0.50", float("nan"))
    
    if not math.isnan(achieved_ap50):
        if achieved_ap50 > target_ap50:
            LOGGER.info(f"âœ… PASS: AP@0.50 = {achieved_ap50:.2f}% > RemDet-X ({target_ap50:.2f}%)")
            LOGGER.info(f"ğŸ‰ Congratulations! You beat RemDet-X by {achieved_ap50 - target_ap50:+.2f}%!")
        elif achieved_ap50 > target_ap50 - 1.0:
            LOGGER.info(f"âš ï¸  CLOSE: AP@0.50 = {achieved_ap50:.2f}% (within 1% of RemDet-X)")
            LOGGER.info(f"   Gap to RemDet-X: {achieved_ap50 - target_ap50:+.2f}%")
            LOGGER.info(f"   Still valuable! RGB-D advantage may show in AP_small or efficiency.")
        else:
            LOGGER.info(f"âŒ FAIL: AP@0.50 = {achieved_ap50:.2f}% < RemDet-X ({target_ap50:.2f}%)")
            LOGGER.info(f"   Gap to RemDet-X: {achieved_ap50 - target_ap50:+.2f}%")
            LOGGER.info(f"   Recommendation: Check training logs, consider SOLR or longer training.")
    LOGGER.info("=" * 80 + "\n")


def _build_summary(metrics: DetMetrics, save_dir: Path, model_info: dict) -> Tuple[Dict[str, float], float]:
    """Build validation summary and save to JSON."""
    metrics_dict = metrics.results_dict
    
    # Extract COCO-style metrics
    results_pct = {
        "AP@[0.5:0.95]": _as_percent(
            metrics_dict.get("metrics/mAP50-95(B)") or metrics_dict.get("metrics/mAP95(B)")
        ),
        "AP@0.50": _as_percent(metrics_dict.get("metrics/mAP50(B)")),
        "AP@0.75": _as_percent(metrics_dict.get("metrics/mAP75(B)")),
        "AP_small": _as_percent(
            metrics_dict.get("metrics/mAP50-95(S)") or metrics_dict.get("metrics/mAP95(S)")
        ),
        "AP_medium": _as_percent(
            metrics_dict.get("metrics/mAP50-95(M)") or metrics_dict.get("metrics/mAP95(M)")
        ),
        "AP_large": _as_percent(
            metrics_dict.get("metrics/mAP50-95(L)") or metrics_dict.get("metrics/mAP95(L)")
        ),
    }
    
    # Efficiency metrics
    latency = float(metrics.speed.get("inference", 0.0))
    
    # Save summary
    metrics_dir = save_dir / "metrics"
    metrics_dir.mkdir(parents=True, exist_ok=True)
    summary_path = metrics_dir / "val_summary.json"
    
    summary = {
        "metrics": results_pct,
        "efficiency": {
            "latency_ms": latency,
            "params_m": model_info.get("params_m", 0.0),
            "flops_g": model_info.get("flops_g", 0.0),
        },
        "baselines": {
            "RemDet-X": REMDET_BASELINES["RemDet-X"],
            "RGB-D v2.1 (VisDrone-only)": RGBD_V2_1_BASELINE,
            "RGB-only (VisDrone-only)": RGB_BASELINE,
        },
        "comparison": {
            "vs_RemDet-X": results_pct.get("AP@0.50", 0.0) - REMDET_BASELINES["RemDet-X"]["AP@0.50"],
            "vs_RGB-D_v2.1": results_pct.get("AP@0.50", 0.0) - RGBD_V2_1_BASELINE["AP@0.50"],
            "vs_RGB-only": results_pct.get("AP@0.50", 0.0) - RGB_BASELINE["AP@0.50"],
        }
    }
    
    with summary_path.open("w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    LOGGER.info(f"[RGB-D Joint] Validation summary saved to {summary_path}")
    
    return results_pct, latency


def _resolve_run_dir(project: Path, name: str) -> Path:
    """Return the actual run directory created by Ultralytics."""
    project.mkdir(parents=True, exist_ok=True)
    candidates = sorted(
        [p for p in project.glob(f"{name}*") if p.is_dir()],
        key=lambda p: p.stat().st_mtime,
    )
    if candidates:
        return candidates[-1]
    return project / name


# =====================================================================
# Argument Parsing
# =====================================================================


def parse_args() -> argparse.Namespace:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(
        description="YOLO12-S RGB-D Joint Validation (RemDet-Aligned)",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # Model and data
    parser.add_argument(
        "--weights",
        type=str,
        required=True,
        help="Path to model checkpoint (e.g., runs/train/xxx/weights/best.pt)"
    )
    parser.add_argument(
        "--data",
        type=str,
        default="data/uav-joint-rgbd.yaml",
        help="Path to dataset config YAML"
    )
    
    # Validation settings
    parser.add_argument("--imgsz", type=int, default=640, help="Input image size")
    parser.add_argument("--batch", type=int, default=16, help="Batch size")
    parser.add_argument("--device", type=str, default="0", help="CUDA device")
    parser.add_argument("--workers", type=int, default=8, help="Number of data loader workers")
    
    # NMS settings
    parser.add_argument("--conf", type=float, default=0.001, help="Confidence threshold")
    parser.add_argument("--iou", type=float, default=0.6, help="IoU threshold for NMS")
    
    # Efficiency
    parser.add_argument("--half", action="store_true", help="Use FP16 inference")
    
    # Dataset split
    parser.add_argument("--split", type=str, default="val", help="Dataset split (val/test)")
    
    # Output settings
    parser.add_argument("--project", type=str, default="runs/val", help="Project directory")
    parser.add_argument("--name", type=str, default="visdrone_joint_val", help="Experiment name")
    parser.add_argument("--save_json", action="store_true", default=True, help="Save COCO-format predictions")
    parser.add_argument("--plots", action="store_true", help="Save PR/F1 curves")
    parser.add_argument("--rect", action="store_true", help="Use rectangular dataloader")
    parser.add_argument("--verbose", action="store_true", help="Print per-class metrics")
    
    return parser.parse_args()


# =====================================================================
# Main Validation Function
# =====================================================================


def main() -> None:
    """Main validation entry point."""
    args = parse_args()
    
    # Check if weights file exists
    weights_path = Path(args.weights)
    if not weights_path.exists():
        LOGGER.error(f"Weights file not found: {weights_path}")
        sys.exit(1)
    
    # Check if data file exists
    data_path = Path(args.data)
    if not data_path.exists():
        LOGGER.error(f"Dataset config file not found: {data_path}")
        sys.exit(1)
    
    # Log configuration
    LOGGER.info("=" * 80)
    LOGGER.info("YOLO12-S RGB-D Joint Validation (RemDet-Aligned)")
    LOGGER.info("=" * 80)
    LOGGER.info(f"Weights: {args.weights}")
    LOGGER.info(f"Data: {args.data}")
    LOGGER.info(f"Image size: {args.imgsz}, Batch: {args.batch}")
    LOGGER.info(f"Conf: {args.conf}, IoU: {args.iou}")
    LOGGER.info(f"Device: {args.device}, Half: {args.half}")
    LOGGER.info("=" * 80)
    
    # Load model
    model = YOLO(weights_path)
    register_metrics_export(model)
    
    # Get model info
    try:
        model_info = model.info(verbose=False)
        params_m = model_info[0] / 1e6 if isinstance(model_info, (tuple, list)) else 11.3
        flops_g = model_info[1] / 1e9 if isinstance(model_info, (tuple, list)) and len(model_info) > 1 else 45.8
    except:
        params_m = 11.3  # Default for yolo12s-rgbd-v2.1
        flops_g = 45.8
    
    # Run validation
    LOGGER.info("[RGB-D Joint] Starting validation...")
    metrics = model.val(
        data=args.data,
        imgsz=args.imgsz,
        batch=args.batch,
        device=args.device,
        workers=args.workers,
        conf=args.conf,
        iou=args.iou,
        half=args.half,
        split=args.split,
        project=args.project,
        name=args.name,
        save_json=args.save_json,
        plots=args.plots,
        rect=args.rect,
        verbose=args.verbose,
    )
    
    # Check if validation succeeded
    if not isinstance(metrics, DetMetrics):
        LOGGER.error("Validation did not return detection metrics!")
        LOGGER.error("Please check dataset configuration and try again.")
        sys.exit(1)
    
    # Resolve run directory
    project_dir = Path(args.project)
    run_dir = _resolve_run_dir(project_dir, args.name)
    
    # Build summary and save
    model_info_dict = {"params_m": params_m, "flops_g": flops_g}
    results_pct, latency_ms = _build_summary(metrics, run_dir, model_info_dict)
    
    # Print results
    _print_metric_table(results_pct, latency_ms, params_m, flops_g)
    _print_baseline_comparison(results_pct)
    
    # Check for exported metrics
    metrics_latest = run_dir / "metrics" / "metrics_latest.json"
    if metrics_latest.exists():
        LOGGER.info(f"[RGB-D Joint] Latest metrics snapshot: {metrics_latest}")
    
    LOGGER.info("[RGB-D Joint] Validation complete!")
    LOGGER.info(f"Results saved to: {run_dir}")


# =====================================================================
# ğŸ“š å…«è‚¡çŸ¥è¯†ç‚¹: ç›®æ ‡æ£€æµ‹è¯„ä¼°æŒ‡æ ‡
# =====================================================================
#
# Q1: mAP@0.5å’ŒmAP@0.5:0.95æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
# A: IoUé˜ˆå€¼çš„ä¸åŒ:
#    - mAP@0.5: åªè¦é¢„æµ‹æ¡†ä¸GTçš„IoU > 0.5å°±ç®—æ­£ç¡®
#      ç‰¹ç‚¹: å¯¹å®šä½ç²¾åº¦è¦æ±‚ä½,å®¹æ˜“è·å¾—é«˜åˆ†
#      é€‚ç”¨: ç²—å®šä½ä»»åŠ¡(å¦‚è½¦è¾†æ£€æµ‹)
#    
#    - mAP@0.5:0.95: IoUä»0.5åˆ°0.95,æ­¥é•¿0.05,å…±10ä¸ªé˜ˆå€¼
#      è®¡ç®—: (mAP@0.5 + mAP@0.55 + ... + mAP@0.95) / 10
#      ç‰¹ç‚¹: å¯¹å®šä½ç²¾åº¦è¦æ±‚é«˜,å…¨é¢è¯„ä¼°
#      é€‚ç”¨: COCOæ ‡å‡†,è®ºæ–‡å‘è¡¨
#    
#    RemDetä¸»è¦çœ‹mAP@0.5(UAVä»»åŠ¡å…³æ³¨å¬å›ç‡),æˆ‘ä»¬ä¹Ÿä»¥æ­¤ä¸ºä¸»æŒ‡æ ‡
#
# Q2: AP_small/medium/largeå¦‚ä½•åˆ’åˆ†ï¼Ÿ
# A: COCOæ ‡å‡†(åŸºäºç›®æ ‡é¢ç§¯):
#    - Small: area < 32^2 = 1024 pixels
#    - Medium: 32^2 < area < 96^2 = 9216 pixels
#    - Large: area > 96^2
#    
#    UAVåœºæ™¯ç‰¹ç‚¹:
#    - Smallç›®æ ‡å 70-80%(è¡Œäººã€å°è½¦ç­‰)
#    - AP_smallæœ€èƒ½ä½“ç°ç®—æ³•ä»·å€¼
#    - RemDet-X: AP_small=19.5% (æˆ‘ä»¬è¦è¶…è¶Š)
#
# Q3: ä¸ºä»€ä¹ˆconf=0.001è¿™ä¹ˆä½ï¼Ÿ
# A: ç½®ä¿¡åº¦é˜ˆå€¼çš„æƒè¡¡:
#    - confè¶Šä½ â†’ å¬å›ç‡è¶Šé«˜(æ¼æ£€å°‘),ä½†è¯¯æ£€å¤š
#    - confè¶Šé«˜ â†’ ç²¾ç¡®ç‡è¶Šé«˜(è¯¯æ£€å°‘),ä½†æ¼æ£€å¤š
#    
#    éªŒè¯æ—¶ç”¨0.001çš„åŸå› :
#    (1) è®¡ç®—PRæ›²çº¿éœ€è¦å®Œæ•´çš„é¢„æµ‹åˆ†å¸ƒ
#    (2) åå¤„ç†NMSä¼šè¿‡æ»¤ä½è´¨é‡æ¡†
#    (3) mAPè®¡ç®—ä¸å—confå½±å“(ä¼šéå†æ‰€æœ‰é˜ˆå€¼)
#    
#    å®é™…éƒ¨ç½²: conf=0.25-0.5(å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦)
#
# Q4: ä¸ºä»€ä¹ˆåªåœ¨VisDrone valéªŒè¯,ä¸ç”¨UAVDT valï¼Ÿ
# A: å¯¹é½RemDetè¯„ä¼°åè®®:
#    (1) RemDetè®ºæ–‡Table 2: VisDrone val set
#    (2) å…¬å¹³å¯¹æ¯”è¦æ±‚: åŒæ ·çš„éªŒè¯é›†
#    (3) UAVDT valå¯ä»¥é¢å¤–æµ‹è¯•,ä½†ä¸ä½œä¸ºä¸»æŒ‡æ ‡
#    
#    ç§‘å­¦åŸå› :
#    - Training: VisDrone + UAVDT (æ··åˆ)
#    - Val: VisDrone only (çº¯å‡€,æ— æ³„éœ²)
#    - é¿å…"è®­ç»ƒæ•°æ®å ä¼˜"å¯¼è‡´æŒ‡æ ‡è™šé«˜
#
# Q5: half=Trueä¼šå½±å“ç²¾åº¦å—ï¼Ÿ
# A: FP16æ¨ç†çš„å½±å“:
#    - é€Ÿåº¦æå‡: 1.5-2x (RTX 4090)
#    - ç²¾åº¦æŸå¤±: é€šå¸¸ < 0.1% mAP (å¯å¿½ç•¥)
#    - å†…å­˜å ç”¨: å‡åŠ (å¯å¢å¤§batch size)
#    
#    æ³¨æ„äº‹é¡¹:
#    (1) æŸäº›å±‚(å¦‚lossè®¡ç®—)ä»ç”¨FP32
#    (2) batch_normçš„running_mean/varä¿æŒFP32
#    (3) éªŒè¯æ—¶å»ºè®®FP16,è®­ç»ƒæ—¶AMP(è‡ªåŠ¨æ··åˆ)
#    
#    RemDetæœªè¯´æ˜æ¨ç†ç²¾åº¦,æ¨æµ‹ç”¨FP16(å®æ—¶ç³»ç»Ÿæ ‡å‡†)
#
# Q6: save_json=Trueç”Ÿæˆçš„æ–‡ä»¶æœ‰ä»€ä¹ˆç”¨ï¼Ÿ
# A: COCOæ ¼å¼çš„é¢„æµ‹ç»“æœ:
#    - æ–‡ä»¶: predictions.json
#    - æ ¼å¼: [{"image_id": 1, "category_id": 0, "bbox": [...], "score": 0.95}, ...]
#    
#    ç”¨é€”:
#    (1) å®˜æ–¹COCOè¯„ä¼°å·¥å…·(pycocotools)éªŒè¯
#    (2) æäº¤åˆ°COCO/VisDroneç«èµ›
#    (3) é”™è¯¯åˆ†æ(å“ªäº›å›¾åƒæ¼æ£€/è¯¯æ£€)
#    (4) å¯è§†åŒ–å·¥å…·(FiftyOne, CVATç­‰)
#    
#    å»ºè®®: éªŒè¯æ—¶é»˜è®¤å¼€å¯,å ç”¨ç©ºé—´å°(~10MB)
# =====================================================================


if __name__ == "__main__":
    main()
