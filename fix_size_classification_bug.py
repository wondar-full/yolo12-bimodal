#!/usr/bin/env python3
"""
ä¿®å¤å°ºåº¦åˆ†ç±»Bug - å½’ä¸€åŒ–åæ ‡ vs åƒç´ åæ ‡å•ä½ä¸åŒ¹é…

ğŸ› é—®é¢˜æè¿°:
ultralytics12/ultralytics/models/yolo/detect/val.py ä¸­çš„ _process_batch() å‡½æ•°
ä½¿ç”¨å½’ä¸€åŒ–bboxåæ ‡è®¡ç®—é¢ç§¯,ä½†ä¸åƒç´ é¢ç§¯é˜ˆå€¼æ¯”è¾ƒ,å¯¼è‡´æ‰€æœ‰ç›®æ ‡éƒ½è¢«é”™è¯¯åˆ†ç±»ã€‚

æ ¹æœ¬åŸå› :
    å½’ä¸€åŒ–é¢ç§¯èŒƒå›´: 0 ~ 1
    åƒç´ é¢ç§¯é˜ˆå€¼: 32Â² = 1024, 96Â² = 9216
    æ¯”è¾ƒ: 0.0025 < 1024 â†’ å‡ ä¹æ‰€æœ‰ç›®æ ‡éƒ½æ˜¯small!

ğŸ¯ ä¿®å¤æ–¹æ¡ˆ:
å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡åå†è®¡ç®—é¢ç§¯

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-01-29
ç‰ˆæœ¬: v1.0
"""

import torch

def analyze_bug():
    """åˆ†æBugçš„ä¸¥é‡æ€§"""
    print("=" * 80)
    print("ğŸ› Bugåˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # æ¨¡æ‹Ÿæ•°æ®
    img_size = 640
    
    # æµ‹è¯•ç”¨ä¾‹1: å°ç›®æ ‡ (32Ã—32åƒç´ )
    bbox_small = torch.tensor([0.1, 0.1, 0.15, 0.15])  # å½’ä¸€åŒ–
    width_norm = bbox_small[2] - bbox_small[0]  # 0.05
    height_norm = bbox_small[3] - bbox_small[1]  # 0.05
    area_norm = width_norm * height_norm  # 0.0025
    
    width_pixel = width_norm * img_size  # 32
    height_pixel = height_norm * img_size  # 32
    area_pixel = width_pixel * height_pixel  # 1024
    
    print(f"\næµ‹è¯•ç”¨ä¾‹1: å°ç›®æ ‡ (32Ã—32åƒç´ )")
    print(f"  å½’ä¸€åŒ–bbox: {bbox_small.tolist()}")
    print(f"  å½’ä¸€åŒ–é¢ç§¯: {area_norm:.6f}")
    print(f"  åƒç´ é¢ç§¯: {area_pixel:.0f} pixelsÂ²")
    print(f"  âŒ é”™è¯¯åˆ¤æ–­: area_norm ({area_norm:.6f}) < 1024? â†’ {area_norm < 1024} (small)")
    print(f"  âœ… æ­£ç¡®åˆ¤æ–­: area_pixel ({area_pixel:.0f}) < 1024? â†’ {area_pixel < 1024} (small)")
    
    # æµ‹è¯•ç”¨ä¾‹2: ä¸­ç­‰ç›®æ ‡ (64Ã—64åƒç´ )
    bbox_medium = torch.tensor([0.2, 0.2, 0.3, 0.3])
    width_norm = bbox_medium[2] - bbox_medium[0]  # 0.1
    height_norm = bbox_medium[3] - bbox_medium[1]  # 0.1
    area_norm = width_norm * height_norm  # 0.01
    
    width_pixel = width_norm * img_size  # 64
    height_pixel = height_norm * img_size  # 64
    area_pixel = width_pixel * height_pixel  # 4096
    
    print(f"\næµ‹è¯•ç”¨ä¾‹2: ä¸­ç­‰ç›®æ ‡ (64Ã—64åƒç´ )")
    print(f"  å½’ä¸€åŒ–bbox: {bbox_medium.tolist()}")
    print(f"  å½’ä¸€åŒ–é¢ç§¯: {area_norm:.6f}")
    print(f"  åƒç´ é¢ç§¯: {area_pixel:.0f} pixelsÂ²")
    print(f"  âŒ é”™è¯¯åˆ¤æ–­: area_norm ({area_norm:.6f}) < 1024? â†’ {area_norm < 1024} (é”™è¯¯åˆ†ä¸ºsmall)")
    print(f"  âœ… æ­£ç¡®åˆ¤æ–­: area_pixel ({area_pixel:.0f}) âˆˆ [1024, 9216)? â†’ {1024 <= area_pixel < 9216} (medium)")
    
    # æµ‹è¯•ç”¨ä¾‹3: å¤§ç›®æ ‡ (128Ã—128åƒç´ )
    bbox_large = torch.tensor([0.1, 0.1, 0.3, 0.3])
    width_norm = bbox_large[2] - bbox_large[0]  # 0.2
    height_norm = bbox_large[3] - bbox_large[1]  # 0.2
    area_norm = width_norm * height_norm  # 0.04
    
    width_pixel = width_norm * img_size  # 128
    height_pixel = height_norm * img_size  # 128
    area_pixel = width_pixel * height_pixel  # 16384
    
    print(f"\næµ‹è¯•ç”¨ä¾‹3: å¤§ç›®æ ‡ (128Ã—128åƒç´ )")
    print(f"  å½’ä¸€åŒ–bbox: {bbox_large.tolist()}")
    print(f"  å½’ä¸€åŒ–é¢ç§¯: {area_norm:.6f}")
    print(f"  åƒç´ é¢ç§¯: {area_pixel:.0f} pixelsÂ²")
    print(f"  âŒ é”™è¯¯åˆ¤æ–­: area_norm ({area_norm:.6f}) < 1024? â†’ {area_norm < 1024} (é”™è¯¯åˆ†ä¸ºsmall)")
    print(f"  âœ… æ­£ç¡®åˆ¤æ–­: area_pixel ({area_pixel:.0f}) >= 9216? â†’ {area_pixel >= 9216} (large)")
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»Ÿè®¡å½±å“")
    print("=" * 80)
    print("ç”±äºå‡ ä¹æ‰€æœ‰å½’ä¸€åŒ–é¢ç§¯éƒ½ < 1024:")
    print("  - Smallç±»åˆ«: åŒ…å«æ‰€æœ‰ç›®æ ‡ (é”™è¯¯)")
    print("  - Mediumç±»åˆ«: å‡ ä¹ä¸ºç©º")
    print("  - Largeç±»åˆ«: å‡ ä¹ä¸ºç©º")
    print("ç»“æœ: Small mAP > Medium mAP > Large mAP (å®Œå…¨é”™è¯¯çš„åˆ†å¸ƒ)")
    print("=" * 80)

def generate_fix():
    """ç”Ÿæˆä¿®å¤ä»£ç """
    print("\n" + "=" * 80)
    print("ğŸ”§ ä¿®å¤ä»£ç ")
    print("=" * 80)
    
    fix_code = """
# ä¿®å¤ä½ç½®: ultralytics12/ultralytics/models/yolo/detect/val.py
# å‡½æ•°: _process_batch()
# è¡Œå·: ~298-303

# âŒ åŸå§‹ä»£ç  (Bugç‰ˆæœ¬)
widths = (batch["bboxes"][..., 2] - batch["bboxes"][..., 0]).cpu()
heights = (batch["bboxes"][..., 3] - batch["bboxes"][..., 1]).cpu()
areas = widths * heights  # å½’ä¸€åŒ–é¢ç§¯!
small_mask = areas < 32.0**2  # é”™è¯¯æ¯”è¾ƒ!
medium_mask = (areas >= 32.0**2) & (areas < 96.0**2)
large_mask = areas >= 96.0**2

# âœ… ä¿®å¤ä»£ç  (æ­£ç¡®ç‰ˆæœ¬)
# è·å–å›¾åƒå°ºå¯¸
img_shape = batch["img"].shape  # [B, C, H, W]
img_h, img_w = img_shape[2], img_shape[3]  # é€šå¸¸æ˜¯640Ã—640

# è®¡ç®—åƒç´ çº§å®½é«˜å’Œé¢ç§¯
widths = (batch["bboxes"][..., 2] - batch["bboxes"][..., 0]) * img_w  # è½¬æ¢ä¸ºåƒç´ 
heights = (batch["bboxes"][..., 3] - batch["bboxes"][..., 1]) * img_h  # è½¬æ¢ä¸ºåƒç´ 
areas = (widths * heights).cpu()  # åƒç´ é¢ç§¯

# æ­£ç¡®çš„å°ºåº¦åˆ¤æ–­
small_mask = areas < 32.0**2  # 32Ã—32 = 1024 pixelsÂ²
medium_mask = (areas >= 32.0**2) & (areas < 96.0**2)  # 1024 ~ 9216 pixelsÂ²
large_mask = areas >= 96.0**2  # >= 9216 pixelsÂ²

# é¢„æµ‹æ¡†ä¹Ÿéœ€è¦ç›¸åŒä¿®å¤
pred_widths = (preds["bboxes"][..., 2] - preds["bboxes"][..., 0]) * img_w
pred_heights = (preds["bboxes"][..., 3] - preds["bboxes"][..., 1]) * img_h
pred_areas = pred_widths * pred_heights
area_small = pred_areas.new_tensor(32.0**2)
area_medium = pred_areas.new_tensor(96.0**2)
pred_small_mask = pred_areas < area_small
pred_medium_mask = (pred_areas >= area_small) & (pred_areas < area_medium)
pred_large_mask = pred_areas >= area_medium
"""
    
    print(fix_code)
    print("=" * 80)

def verify_fix():
    """éªŒè¯ä¿®å¤åçš„æ•ˆæœ"""
    print("\n" + "=" * 80)
    print("âœ… ä¿®å¤éªŒè¯")
    print("=" * 80)
    
    img_size = 640
    
    # æ¨¡æ‹Ÿbatchæ•°æ®
    batch_bboxes = torch.tensor([
        [0.1, 0.1, 0.15, 0.15],  # 32Ã—32 (small)
        [0.2, 0.2, 0.3, 0.3],    # 64Ã—64 (medium)
        [0.4, 0.4, 0.6, 0.6],    # 128Ã—128 (large)
    ])
    
    # âŒ é”™è¯¯çš„å½’ä¸€åŒ–é¢ç§¯è®¡ç®—
    widths_norm = batch_bboxes[:, 2] - batch_bboxes[:, 0]
    heights_norm = batch_bboxes[:, 3] - batch_bboxes[:, 1]
    areas_norm = widths_norm * heights_norm
    
    small_mask_wrong = areas_norm < 1024
    medium_mask_wrong = (areas_norm >= 1024) & (areas_norm < 9216)
    large_mask_wrong = areas_norm >= 9216
    
    print("âŒ é”™è¯¯åˆ†ç±» (å½’ä¸€åŒ–é¢ç§¯):")
    print(f"  å½’ä¸€åŒ–é¢ç§¯: {areas_norm.tolist()}")
    print(f"  Small mask: {small_mask_wrong.tolist()}  â†’ {small_mask_wrong.sum().item()} targets")
    print(f"  Medium mask: {medium_mask_wrong.tolist()} â†’ {medium_mask_wrong.sum().item()} targets")
    print(f"  Large mask: {large_mask_wrong.tolist()} â†’ {large_mask_wrong.sum().item()} targets")
    
    # âœ… æ­£ç¡®çš„åƒç´ é¢ç§¯è®¡ç®—
    widths_pixel = (batch_bboxes[:, 2] - batch_bboxes[:, 0]) * img_size
    heights_pixel = (batch_bboxes[:, 3] - batch_bboxes[:, 1]) * img_size
    areas_pixel = widths_pixel * heights_pixel
    
    small_mask_correct = areas_pixel < 1024
    medium_mask_correct = (areas_pixel >= 1024) & (areas_pixel < 9216)
    large_mask_correct = areas_pixel >= 9216
    
    print("\nâœ… æ­£ç¡®åˆ†ç±» (åƒç´ é¢ç§¯):")
    print(f"  åƒç´ é¢ç§¯: {areas_pixel.tolist()}")
    print(f"  Small mask: {small_mask_correct.tolist()}  â†’ {small_mask_correct.sum().item()} target")
    print(f"  Medium mask: {medium_mask_correct.tolist()} â†’ {medium_mask_correct.sum().item()} target")
    print(f"  Large mask: {large_mask_correct.tolist()} â†’ {large_mask_correct.sum().item()} target")
    
    print("\nğŸ’¡ é¢„æœŸæ•ˆæœ:")
    print("  ä¿®å¤å,mAPåˆ†å¸ƒåº”è¯¥å˜ä¸º: Small < Medium < Large (æ­£å¸¸è¶‹åŠ¿)")
    print("  å®é™…YOLO12n mAPå¯èƒ½ä»:")
    print("    Small: 13.30% â†’ å®é™…small mAP (ä¼šé™ä½,å› ä¸ºç°åœ¨æ˜¯çœŸçš„small)")
    print("    Medium: 10.98% â†’ å®é™…medium mAP (ä¼šæå‡,å› ä¸ºä¸å†æ··å…¥å…¶ä»–å°ºåº¦)")
    print("    Large: 14.48% â†’ å®é™…large mAP (ä¼šæå‡,åŸå› åŒä¸Š)")
    print("=" * 80)

if __name__ == "__main__":
    analyze_bug()
    generate_fix()
    verify_fix()
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. ä¿®æ”¹ ultralytics12/ultralytics/models/yolo/detect/val.py")
    print("2. é‡æ–°éªŒè¯ YOLO12n å’Œ YOLO12x")
    print("3. å¯¹æ¯”ä¿®å¤å‰åçš„mAPåˆ†å¸ƒ")
    print("4. ç¡®è®¤ Small < Medium < Large çš„æ­£å¸¸è¶‹åŠ¿")
