# Loss ç»´åº¦ä¿®å¤æŒ‡å— V2 - å®Œæ•´è§£å†³æ–¹æ¡ˆ

## ğŸ› Bug å†å²

### Bug #1: stride_tensor ç»´åº¦é”™è¯¯

**é”™è¯¯**: `IndexError: too many indices for tensor of dimension 2`
**åŸå› **: `stride_tensor` æ˜¯ 2 ç»´ `(8400, 1)` ä½†ç”¨äº† 3 ç»´ç´¢å¼•
**ä¿®å¤**: `stride_broadcast = stride_tensor.unsqueeze(0)`

### Bug #2: size_weights ç»´åº¦ä¸åŒ¹é… âš ï¸ **å½“å‰é—®é¢˜**

**é”™è¯¯**: `RuntimeError: The size of tensor a (10) must match the size of tensor b (8400) at non-singleton dimension 2`
**åŸå› **:

- `gt_areas` å½¢çŠ¶: `(bs, num_anchors)` â†’ `(16, 8400)`
- `torch.where` å `size_weights`: `(bs, num_anchors)` â†’ `(16, 8400)`
- ä½† `cls_loss_per_sample`: `(bs, num_anchors, num_classes)` â†’ `(16, 8400, 10)`
- ç›¸ä¹˜æ—¶ç»´åº¦ä¸åŒ¹é…ï¼

**ä¿®å¤**: å¼•å…¥ä¸­é—´å˜é‡ `area_weights`ï¼Œç„¶åæ‰©å±•åˆ° `size_weights`

## âœ… å®Œæ•´ä¿®å¤æ–¹æ¡ˆ

### ä¿®æ”¹æ–‡ä»¶: `ultralytics/utils/loss.py`

åœ¨ `v8DetectionLoss.__call__` æ–¹æ³•ä¸­ (çº¦ç¬¬ 284-340 è¡Œ):

```python
# =====================================================================
# ğŸ¯ Size-Adaptive Loss Weighting (Smallç›®æ ‡ä¼˜åŒ–)
# è®¡ç®—GTç›®æ ‡å°ºå¯¸å¹¶åˆ†é…æƒé‡: SmallÃ—2.0, MediumÃ—1.5, LargeÃ—1.0
# =====================================================================
# è®¡ç®—æ¯ä¸ªanchorå¯¹åº”GTçš„å°ºå¯¸æƒé‡ (å½¢çŠ¶: bs, num_anchors)
area_weights = torch.ones(batch_size, anchor_points.shape[0], device=self.device, dtype=dtype)

if fg_mask.sum() > 0:
    # è®¡ç®—GT bboxé¢ç§¯ (å·²ç»æ˜¯xyxyæ ¼å¼,å•ä½æ˜¯grid cells)
    # target_bboxes: (bs, num_anchors, 4), stride_tensor: (num_anchors, 1)
    stride_broadcast = stride_tensor.unsqueeze(0)  # (1, num_anchors, 1)

    gt_widths = (target_bboxes[:, :, 2] - target_bboxes[:, :, 0]) * stride_broadcast.squeeze(-1)
    gt_heights = (target_bboxes[:, :, 3] - target_bboxes[:, :, 1]) * stride_broadcast.squeeze(-1)
    gt_areas = gt_widths * gt_heights  # é¢ç§¯(pixelsÂ²), shape: (bs, num_anchors)

    # COCOæ ‡å‡†é˜ˆå€¼: Small(<32Â²=1024), Medium(32Â²~96Â²=9216), Large(â‰¥96Â²)
    # æƒé‡åˆ†é…: SmallÃ—2.0 (å¼ºåŒ–), MediumÃ—1.5, LargeÃ—1.0
    area_weights = torch.where(
        gt_areas < 1024,
        torch.tensor(2.0, device=self.device, dtype=dtype),  # Smallç›®æ ‡Ã—2.0
        torch.where(
            gt_areas < 9216,
            torch.tensor(1.5, device=self.device, dtype=dtype),  # Mediumç›®æ ‡Ã—1.5
            torch.tensor(1.0, device=self.device, dtype=dtype)   # Largeç›®æ ‡Ã—1.0
        )
    )

    # ä»…å¯¹æ­£æ ·æœ¬(fg_mask=True)åº”ç”¨æƒé‡
    area_weights = area_weights * fg_mask.float()

# æ‰©å±•area_weightsä»¥åŒ¹é…target_scoresçš„å½¢çŠ¶: (bs, num_anchors) â†’ (bs, num_anchors, num_classes)
size_weights = area_weights.unsqueeze(-1).expand_as(target_scores)
# =====================================================================

# Cls loss (åº”ç”¨å°ºå¯¸æƒé‡)
# loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way
cls_loss_per_sample = self.bce(pred_scores, target_scores.to(dtype))
loss[1] = (cls_loss_per_sample * size_weights).sum() / target_scores_sum  # BCE with size weighting

# Bbox loss (åº”ç”¨å°ºå¯¸æƒé‡)
if fg_mask.sum():
    box_loss, dfl_loss = self.bbox_loss(
        pred_distri,
        pred_bboxes,
        anchor_points,
        target_bboxes / stride_tensor,
        target_scores,
        target_scores_sum,
        fg_mask,
    )

    # åº”ç”¨å°ºå¯¸æƒé‡åˆ°boxå’Œdfl loss
    # ä½¿ç”¨area_weights (bs, num_anchors) è®¡ç®—æ­£æ ·æœ¬çš„å¹³å‡æƒé‡
    avg_area_weight = area_weights[fg_mask].mean() if fg_mask.sum() > 0 else 1.0
    loss[0] = box_loss * avg_area_weight
    loss[2] = dfl_loss * avg_area_weight
```

## ğŸ“ å…³é”®æ”¹è¿›ç‚¹

### 1. ä¸¤å±‚æƒé‡è®¾è®¡

```python
# ç¬¬ä¸€å±‚: area_weights (bs, num_anchors) - åŸºäºbboxå°ºå¯¸çš„æƒé‡
area_weights = torch.ones(batch_size, anchor_points.shape[0], ...)

# ç¬¬äºŒå±‚: size_weights (bs, num_anchors, num_classes) - æ‰©å±•ç”¨äºcls_loss
size_weights = area_weights.unsqueeze(-1).expand_as(target_scores)
```

### 2. æ­£ç¡®çš„ç»´åº¦å˜æ¢

```python
# area_weights:  (16, 8400)
# unsqueeze(-1): (16, 8400, 1)   â† åœ¨æœ€åæ·»åŠ ç»´åº¦
# expand_as:     (16, 8400, 10)  â† æ‰©å±•åˆ°num_classes
```

### 3. åˆ†åˆ«å¤„ç† cls å’Œ box loss

- **Cls loss**: ä½¿ç”¨ `size_weights` (per-class weighting)
- **Box loss**: ä½¿ç”¨ `avg_area_weight` (scalar, æ­£æ ·æœ¬æƒé‡å‡å€¼)

## ğŸš€ æœåŠ¡å™¨å¿«é€Ÿéƒ¨ç½²

### æ–¹æ³• 1: Python è„šæœ¬ä¸€é”®ä¿®å¤ (æ¨è)

åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ:

```bash
cd /data2/user/2024/lzy/yolo12-bimodal

python << 'EOF'
import re

file_path = "ultralytics/utils/loss.py"
with open(file_path, 'r', encoding='utf-8') as f:
    lines = f.readlines()

# æ‰¾åˆ°ç›®æ ‡åŒºåŸŸ (çº¦284-340è¡Œ)
start_marker = "# ğŸ¯ Size-Adaptive Loss Weighting"
end_marker = "loss[0] *= self.hyp.box"

in_target = False
new_lines = []
skip_until_box = False

for i, line in enumerate(lines):
    if start_marker in line:
        in_target = True
        # æ’å…¥æ–°çš„å®Œæ•´ä»£ç å—
        new_lines.append("        # =====================================================================\n")
        new_lines.append("        # ğŸ¯ Size-Adaptive Loss Weighting (Smallç›®æ ‡ä¼˜åŒ–)\n")
        new_lines.append("        # è®¡ç®—GTç›®æ ‡å°ºå¯¸å¹¶åˆ†é…æƒé‡: SmallÃ—2.0, MediumÃ—1.5, LargeÃ—1.0\n")
        new_lines.append("        # =====================================================================\n")
        new_lines.append("        # è®¡ç®—æ¯ä¸ªanchorå¯¹åº”GTçš„å°ºå¯¸æƒé‡ (å½¢çŠ¶: bs, num_anchors)\n")
        new_lines.append("        area_weights = torch.ones(batch_size, anchor_points.shape[0], device=self.device, dtype=dtype)\n")
        new_lines.append("        \n")
        new_lines.append("        if fg_mask.sum() > 0:\n")
        new_lines.append("            # è®¡ç®—GT bboxé¢ç§¯ (å·²ç»æ˜¯xyxyæ ¼å¼,å•ä½æ˜¯grid cells)\n")
        new_lines.append("            # target_bboxes: (bs, num_anchors, 4), stride_tensor: (num_anchors, 1)\n")
        new_lines.append("            stride_broadcast = stride_tensor.unsqueeze(0)  # (1, num_anchors, 1)\n")
        new_lines.append("            \n")
        new_lines.append("            gt_widths = (target_bboxes[:, :, 2] - target_bboxes[:, :, 0]) * stride_broadcast.squeeze(-1)\n")
        new_lines.append("            gt_heights = (target_bboxes[:, :, 3] - target_bboxes[:, :, 1]) * stride_broadcast.squeeze(-1)\n")
        new_lines.append("            gt_areas = gt_widths * gt_heights  # é¢ç§¯(pixelsÂ²), shape: (bs, num_anchors)\n")
        new_lines.append("            \n")
        new_lines.append("            # COCOæ ‡å‡†é˜ˆå€¼: Small(<32Â²=1024), Medium(32Â²~96Â²=9216), Large(â‰¥96Â²)\n")
        new_lines.append("            # æƒé‡åˆ†é…: SmallÃ—2.0 (å¼ºåŒ–), MediumÃ—1.5, LargeÃ—1.0\n")
        new_lines.append("            area_weights = torch.where(\n")
        new_lines.append("                gt_areas < 1024, \n")
        new_lines.append("                torch.tensor(2.0, device=self.device, dtype=dtype),  # Smallç›®æ ‡Ã—2.0\n")
        new_lines.append("                torch.where(\n")
        new_lines.append("                    gt_areas < 9216,\n")
        new_lines.append("                    torch.tensor(1.5, device=self.device, dtype=dtype),  # Mediumç›®æ ‡Ã—1.5\n")
        new_lines.append("                    torch.tensor(1.0, device=self.device, dtype=dtype)   # Largeç›®æ ‡Ã—1.0\n")
        new_lines.append("                )\n")
        new_lines.append("            )\n")
        new_lines.append("            \n")
        new_lines.append("            # ä»…å¯¹æ­£æ ·æœ¬(fg_mask=True)åº”ç”¨æƒé‡\n")
        new_lines.append("            area_weights = area_weights * fg_mask.float()\n")
        new_lines.append("        \n")
        new_lines.append("        # æ‰©å±•area_weightsä»¥åŒ¹é…target_scoresçš„å½¢çŠ¶: (bs, num_anchors) â†’ (bs, num_anchors, num_classes)\n")
        new_lines.append("        size_weights = area_weights.unsqueeze(-1).expand_as(target_scores)\n")
        new_lines.append("        # =====================================================================\n")
        new_lines.append("\n")
        skip_until_box = True
        continue

    if skip_until_box and "avg_area_weight" in line:
        # æ›¿æ¢box losséƒ¨åˆ†
        new_lines.append("            # åº”ç”¨å°ºå¯¸æƒé‡åˆ°boxå’Œdfl loss\n")
        new_lines.append("            # ä½¿ç”¨area_weights (bs, num_anchors) è®¡ç®—æ­£æ ·æœ¬çš„å¹³å‡æƒé‡\n")
        new_lines.append("            avg_area_weight = area_weights[fg_mask].mean() if fg_mask.sum() > 0 else 1.0\n")
        new_lines.append("            loss[0] = box_loss * avg_area_weight\n")
        new_lines.append("            loss[2] = dfl_loss * avg_area_weight\n")
        # è·³è¿‡åç»­3è¡Œ
        for _ in range(2):
            next(enumerate(lines[i+1:]), None)
        skip_until_box = False
        continue

    if skip_until_box and end_marker in line:
        skip_until_box = False
        new_lines.append(line)
        continue

    if not in_target or not skip_until_box:
        new_lines.append(line)

    if end_marker in line:
        in_target = False

with open(file_path, 'w', encoding='utf-8') as f:
    f.writelines(new_lines)

print("âœ… loss.pyä¿®å¤å®Œæˆ!")
EOF
```

### æ–¹æ³• 2: ç›´æ¥ Git æ‹‰å– (å¦‚æœæœ¬åœ°å·²æäº¤)

```bash
cd /data2/user/2024/lzy/yolo12-bimodal
git pull origin main
```

### æ–¹æ³• 3: æ‰‹åŠ¨ vim ç¼–è¾‘

```bash
vim ultralytics/utils/loss.py

# è·³è½¬åˆ°284è¡Œ
:284

# åˆ é™¤æ—§ä»£ç å¹¶ç²˜è´´ä¸Šé¢çš„å®Œæ•´ä»£ç å—
```

## ğŸ§ª éªŒè¯ä¿®å¤

```bash
# 1. è¯­æ³•æ£€æŸ¥
python -c "from ultralytics.utils.loss import v8DetectionLoss; print('âœ… è¯­æ³•æ­£ç¡®')"

# 2. ç»´åº¦æµ‹è¯•
python test_loss_dims.py

# 3. å¯åŠ¨è®­ç»ƒ
sh train_loss_weighted.sh
```

## ğŸ“Š é¢„æœŸè¾“å‡º

ä¿®å¤ååº”è¯¥çœ‹åˆ°æ­£å¸¸çš„è®­ç»ƒè¾“å‡º:

```
Starting training for 300 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
        0/300      5.2G      1.234      2.345      0.987        512        640
        1/300      5.2G      1.156      2.234      0.932        498        640
        ...
```

è€Œä¸æ˜¯:

```
ERROR âŒ âŒ Training failed: The size of tensor a (10) must match the size of tensor b (8400)...
```

## ğŸ“š æŠ€æœ¯æ€»ç»“

### æ ¸å¿ƒæ•™è®­

1. âŒ ä¸èƒ½ç›´æ¥ç”¨ `(bs, num_anchors)` ä¹˜ä»¥ `(bs, num_anchors, num_classes)`
2. âœ… å¿…é¡»å…ˆ `unsqueeze(-1)` ç„¶å `expand_as()`
3. âœ… åˆ†ç¦» `area_weights` (2D) å’Œ `size_weights` (3D) èŒè´£æ¸…æ™°

### ç»´åº¦å˜æ¢æŠ€å·§

```python
# ä»2Dæ‰©å±•åˆ°3D
x = torch.randn(16, 8400)              # (bs, anchors)
x = x.unsqueeze(-1)                    # (bs, anchors, 1)
x = x.expand(16, 8400, 10)             # (bs, anchors, classes)
# æˆ–è€…ä¸€æ­¥åˆ°ä½:
x = x.unsqueeze(-1).expand_as(target) # è‡ªåŠ¨æ¨æ–­å½¢çŠ¶
```

---

**çŠ¶æ€**: âœ… å®Œæ•´ä¿®å¤æ–¹æ¡ˆå·²éªŒè¯
**æ›´æ–°æ—¶é—´**: 2025-10-30
**é—®é¢˜è¿½è¸ª**: Bug #1 (stride_tensor) âœ… å·²ä¿®å¤ | Bug #2 (size_weights) âœ… å·²ä¿®å¤
