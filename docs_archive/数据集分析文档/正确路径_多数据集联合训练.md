# Loss æƒé‡å®éªŒå¤±è´¥é‡æ–°åˆ†æ - æ­£ç¡®è§†è§’

**æ—¥æœŸ**: 2025-10-31  
**å®éªŒ**: exp_loss_weighted_v110  
**ç»“æœ**: å¤±è´¥ (mAP 26% vs baseline 41%)

---

## ğŸ¯ æ ¸å¿ƒé—®é¢˜é‡æ–°è®¤è¯†

### ä½ çš„è§‚ç‚¹å®Œå…¨æ­£ç¡®!

**é—®é¢˜ä¸åœ¨äº"Large ç›®æ ‡éœ€è¦æå‡æƒé‡"**ï¼Œè€Œæ˜¯ï¼š

1. âœ… **é¡¹ç›®ç›®æ ‡æ˜¯ UAV å°ç›®æ ‡æ£€æµ‹** - å¯¹æ ‡ RemDet çš„æ ¸å¿ƒå°±æ˜¯ Small mAP
2. âœ… **Large æ€§èƒ½ä½æ˜¯æ•°æ®é—®é¢˜** - VisDrone åªæœ‰ 443 ä¸ª Large æ ·æœ¬(0.1%)
3. âœ… **RemDet ç”¨äº† 3 ä¸ªæ•°æ®é›†** - VisDrone + UAVDT + COCO (30K+å›¾åƒ)
4. âœ… **åº”è¯¥ç«‹å³å¼€å§‹å¤šæ•°æ®é›†è®­ç»ƒ** - è€Œéçº ç»“å•æ•°æ®é›†çš„ Loss æƒé‡

---

## ğŸ“Š å®éªŒå¤±è´¥çš„çœŸæ­£åŸå› 

### å½“å‰å®éªŒçš„é”™è¯¯å‡è®¾

```
é”™è¯¯å‡è®¾: "é€šè¿‡Lossæƒé‡è°ƒæ•´,åœ¨VisDroneå•æ•°æ®é›†ä¸Šæå‡Small mAP"
      â†“
SmallÃ—2.0, MediumÃ—1.5, LargeÃ—1.0
      â†“
ç»“æœ: æ•´ä½“æ€§èƒ½å´©æºƒ (26% vs 41%)
```

### ä¸ºä»€ä¹ˆå´©æºƒ?

ä»è®­ç»ƒæ›²çº¿çœ‹ (`results.csv`):

| Epoch   | mAP@0.5         | é—®é¢˜åˆ†æ                |
| ------- | --------------- | ----------------------- |
| 1-10    | 0.014% â†’ 15.86% | èµ·æ­¥ææ…¢,å‡ ä¹ä»é›¶å¼€å§‹   |
| 10-100  | 15.86% â†’ 23.55% | å¢é•¿ç¼“æ…¢,ä¸å¦‚ baseline  |
| 100-300 | 23.55% â†’ 26.05% | å‡ ä¹ä¸å¢é•¿,é™·å…¥å±€éƒ¨æœ€ä¼˜ |
| Epoch 2 | NaN             | å‡ºç°æ•°å€¼ä¸ç¨³å®š          |

**æ ¹æœ¬é—®é¢˜**:

- æƒé‡ Ã—2.0 å¤ªæ¿€è¿›,å¯¼è‡´æ¢¯åº¦ä¸ç¨³å®š
- Small ç›®æ ‡å  92.4%,å† Ã—2.0 = è®­ç»ƒè¢« Small å®Œå…¨ä¸»å¯¼
- Medium/Large ä¿¡å·è¢«æ·¹æ²¡,æ¨¡å‹å­¦ä¸åˆ°å¤šæ ·æ€§ç‰¹å¾
- æ•´ä½“è¡¨å¾èƒ½åŠ›ä¸‹é™ â†’ è¿ Small æœ¬èº«ä¹Ÿæ£€æµ‹ä¸å¥½

---

## ğŸ”„ æ­£ç¡®çš„æ”¹è¿›è·¯å¾„

### âŒ é”™è¯¯è·¯å¾„ (æˆ‘ä¹‹å‰å»ºè®®çš„)

```
Phase 1: VisDroneå•æ•°æ®é›†ä¼˜åŒ– (Lossæƒé‡/FPN/æ•°æ®å¢å¼º)
    â†“ é¢„æœŸSmall mAP 35%
Phase 2: åŠ å…¥UAVDT (å¤šæ•°æ®é›†è”åˆè®­ç»ƒ)
    â†“ é¢„æœŸSmall 38%, Large 44%
```

**é—®é¢˜**:

- åœ¨ä¸å®Œæ•´æ•°æ®ä¸Šè¿‡åº¦ä¼˜åŒ– â†’ è¿‡æ‹Ÿåˆ VisDrone ç‰¹æ€§
- RemDet ä»ä¸€å¼€å§‹å°±ç”¨å…¨éƒ¨æ•°æ®,æˆ‘ä»¬å´åªç”¨ 1/5 æ•°æ®
- æµªè´¹æ—¶é—´åœ¨å•æ•°æ®é›†è°ƒå‚ä¸Š

### âœ… æ­£ç¡®è·¯å¾„ (ä½ æå‡ºçš„)

```
ç«‹å³Phase 2: å¤šæ•°æ®é›†è”åˆè®­ç»ƒ (VisDrone + UAVDT)
    â†“
ä»ImageNeté¢„è®­ç»ƒå¼€å§‹,è”åˆè®­ç»ƒ30Kå›¾åƒ
    â†“
é¢„æœŸ: Small 35-38%, Medium 45%+, Large 42-44%, Overall 45%+
    â†“
å¦‚æœä¸å¤Ÿ,å†è€ƒè™‘Loss/FPN/æ•°æ®å¢å¼ºç­‰ç»†èŠ‚ä¼˜åŒ–
```

**ä¼˜åŠ¿**:

- ä¸€æ­¥åˆ°ä½,å¤ç° RemDet çš„è®­ç»ƒè®¾ç½®
- Large æ ·æœ¬ä» 443 ä¸ª â†’10K+ (UAVDT è½¦è¾†å æ¯”æ›´é«˜)
- æ›´å…¨é¢çš„ç‰¹å¾å­¦ä¹ ,é¿å…è¿‡æ‹Ÿåˆ
- çœå»å•æ•°æ®é›†åå¤è°ƒå‚çš„æ—¶é—´

---

## ğŸš€ ç«‹å³è¡ŒåŠ¨æ–¹æ¡ˆ: å¤šæ•°æ®é›†è”åˆè®­ç»ƒ

### Step 1: å‡†å¤‡ UAVDT æ•°æ®é›† (ä¼˜å…ˆçº§æœ€é«˜!)

#### 1.1 ä¸‹è½½ UAVDT æ•°æ®é›†

```bash
# UAVDTå®˜æ–¹é“¾æ¥
# https://sites.google.com/view/grli-uavdt/

# æˆ–ä½¿ç”¨é•œåƒæº
# Benchmark: M0401, M0403, M0601, M0602, ...ç­‰50ä¸ªåºåˆ—
# è®­ç»ƒé›†: ~23,258å¼ å›¾åƒ
# éªŒè¯é›†: ~2,934å¼ å›¾åƒ
```

#### 1.2 è½¬æ¢æ ‡æ³¨æ ¼å¼ (XML â†’ YOLO)

UAVDT æ ‡æ³¨æ ¼å¼:

```xml
<annotation>
  <object>
    <name>car</name>  <!-- ç±»åˆ«: car, truck, bus -->
    <bndbox>
      <xmin>100</xmin>
      <ymin>200</ymin>
      <xmax>300</xmax>
      <ymax>400</ymax>
    </bndbox>
  </object>
</annotation>
```

è½¬æ¢è„šæœ¬ `convert_uavdt_to_yolo.py`:

```python
import xml.etree.ElementTree as ET
from pathlib import Path

# VisDroneç±»åˆ«æ˜ å°„
# VisDrone: [0:ignored, 1:ped, 2:people, 3:bicycle, 4:car, 5:van, 6:truck, 7:tricycle, 8:awning-tri, 9:bus, 10:motor]
# UAVDT â†’ VisDroneæ˜ å°„
CLASS_MAPPING = {
    'car': 4,      # UAVDT car â†’ VisDrone car (class 4)
    'truck': 6,    # UAVDT truck â†’ VisDrone truck (class 6)
    'bus': 9       # UAVDT bus â†’ VisDrone bus (class 9)
}

def convert_uavdt_xml_to_yolo(xml_path, img_width, img_height):
    tree = ET.parse(xml_path)
    root = tree.getroot()

    yolo_lines = []
    for obj in root.findall('object'):
        name = obj.find('name').text
        if name not in CLASS_MAPPING:
            continue

        class_id = CLASS_MAPPING[name]
        bbox = obj.find('bndbox')
        xmin = float(bbox.find('xmin').text)
        ymin = float(bbox.find('ymin').text)
        xmax = float(bbox.find('xmax').text)
        ymax = float(bbox.find('ymax').text)

        # Convert to YOLO format (normalized center x, y, width, height)
        x_center = ((xmin + xmax) / 2) / img_width
        y_center = ((ymin + ymax) / 2) / img_height
        width = (xmax - xmin) / img_width
        height = (ymax - ymin) / img_height

        yolo_lines.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

    return yolo_lines

# æ‰¹é‡è½¬æ¢
uavdt_root = Path("UAVDT_Benchmark")
output_root = Path("UAVDT_YOLO")

for split in ['train', 'val']:
    img_dir = uavdt_root / split / 'images'
    anno_dir = uavdt_root / split / 'annotations'

    output_img_dir = output_root / 'images' / split
    output_label_dir = output_root / 'labels' / split
    output_img_dir.mkdir(parents=True, exist_ok=True)
    output_label_dir.mkdir(parents=True, exist_ok=True)

    for xml_file in anno_dir.glob('*.xml'):
        img_name = xml_file.stem
        # ... (è¯»å–å›¾åƒå°ºå¯¸,è½¬æ¢,ä¿å­˜)
```

#### 1.3 ç”Ÿæˆæ·±åº¦å›¾ (ZoeDepth)

```python
import torch
from PIL import Image
from zoedepth.models.builder import build_model
from zoedepth.utils.config import get_config

# åŠ è½½ZoeDepthæ¨¡å‹
conf = get_config("zoedepth", "infer")
model = build_model(conf).cuda()

def generate_depth(img_path, output_path):
    img = Image.open(img_path).convert('RGB')
    depth = model.infer_pil(img)

    # å½’ä¸€åŒ–åˆ°0-255ä¿å­˜ä¸ºç°åº¦å›¾
    depth_normalized = (depth - depth.min()) / (depth.max() - depth.min()) * 255
    depth_img = Image.fromarray(depth_normalized.astype('uint8'))
    depth_img.save(output_path)

# æ‰¹é‡å¤„ç†UAVDTå›¾åƒ
for img_path in (output_root / 'images' / 'train').glob('*.jpg'):
    depth_path = output_root / 'depths' / 'train' / f"{img_path.stem}.png"
    generate_depth(img_path, depth_path)
```

#### 1.4 åˆ›å»ºè”åˆæ•°æ®é›† YAML

`visdrone_uavdt_joint.yaml`:

```yaml
path: /data/UAV_Detection # æ ¹ç›®å½•
train:
  - VisDrone/images/train # VisDroneè®­ç»ƒé›† (6,471)
  - UAVDT/images/train # UAVDTè®­ç»ƒé›† (23,258)
val: VisDrone/images/val # åªç”¨VisDroneéªŒè¯ (ä¸RemDetå¯¹é½)

train_depth:
  - VisDrone/depths/train
  - UAVDT/depths/train
val_depth: VisDrone/depths/val

# ç±»åˆ« (ä»¥VisDroneä¸ºå‡†,UAVDTå·²æ˜ å°„åˆ°4,6,9)
nc: 10
names:
  [
    "ignored",
    "pedestrian",
    "people",
    "bicycle",
    "car",
    "van",
    "truck",
    "tricycle",
    "awning-tricycle",
    "bus",
    "motor",
  ]

# é‡‡æ ·æƒé‡ (å¯é€‰,é˜²æ­¢UAVDTä¸»å¯¼)
train_weights: [1.0, 0.5] # VisDrone:UAVDT = 2:1
```

### Step 2: å®ç°å¤šæ•°æ®é›†åŠ è½½å™¨

ä¿®æ”¹ `ultralytics/data/dataset.py`:

```python
class MultiDatasetYOLO(BaseDataset):
    """
    æ”¯æŒå¤šæ•°æ®é›†è”åˆè®­ç»ƒçš„YOLOæ•°æ®é›†
    æŒ‰æŒ‡å®šæƒé‡æ··åˆé‡‡æ ·
    """
    def __init__(self, img_paths_list, weights=None, ...):
        self.datasets = []
        for paths in img_paths_list:
            self.datasets.append(YOLODataset(paths, ...))

        self.weights = weights or [1.0] * len(self.datasets)
        self.indices = self._build_weighted_indices()

    def _build_weighted_indices(self):
        """æ„å»ºåŠ æƒé‡‡æ ·ç´¢å¼•"""
        indices = []
        for i, (dataset, weight) in enumerate(zip(self.datasets, self.weights)):
            # æ¯ä¸ªæ•°æ®é›†æŒ‰æƒé‡é‡å¤
            dataset_indices = [(i, j) for j in range(len(dataset))]
            indices.extend(dataset_indices * int(weight))
        random.shuffle(indices)
        return indices

    def __getitem__(self, idx):
        dataset_idx, sample_idx = self.indices[idx]
        return self.datasets[dataset_idx][sample_idx]
```

### Step 3: å¯åŠ¨è”åˆè®­ç»ƒ

```bash
cd /data2/user/2024/lzy/yolo12-bimodal

# è”åˆè®­ç»ƒ (ä»ImageNeté¢„è®­ç»ƒå¼€å§‹,ä¸ç”¨VisDroneçš„best.pt!)
CUDA_VISIBLE_DEVICES=7 python train_depth.py \
    --data data/visdrone_uavdt_joint.yaml \
    --epochs 300 \
    --batch 16 \
    --imgsz 640 \
    --device 0 \
    --project runs/train \
    --name exp_joint_visdrone_uavdt_v1 \
    --weights yolo12n.pt \
    --save_period 50 \
    --patience 100 \
    --workers 8

# é¢„è®¡è®­ç»ƒæ—¶é—´: 30-40å°æ—¶ (æ•°æ®é‡Ã—5)
```

### Step 4: é¢„æœŸç»“æœ

| æŒ‡æ ‡        | å½“å‰ (VisDrone å•æ•°æ®é›†) | è”åˆè®­ç»ƒé¢„æœŸ | RemDet-Tiny | å¯¹æ¯”         |
| ----------- | ------------------------ | ------------ | ----------- | ------------ |
| Small mAP   | 30.94%                   | **35-38%**   | 12.7%       | âœ… +180-200% |
| Medium mAP  | 46.24%                   | **48-50%**   | 33.0%       | âœ… +45-51%   |
| Large mAP   | 36.70%                   | **42-44%**   | 44.5%       | âœ… æ¥è¿‘      |
| Overall mAP | ~41%                     | **45-47%**   | 38.9%       | âœ… +15-20%   |

**å…³é”®æ”¹è¿›**:

- âœ… Large æ ·æœ¬ä» 443â†’10K+,æ€§èƒ½æ˜¾è‘—æå‡
- âœ… Small/Medium æ›´å¤šæ ·æœ¬,æ³›åŒ–æ€§æ›´å¼º
- âœ… æ€»è®­ç»ƒæ•°æ® 30K vs RemDet çš„ 30K+,æŒå¹³

---

## ğŸ¯ ä¸ºä»€ä¹ˆè¿™æ˜¯æ­£ç¡®è·¯å¾„?

### 1. å¯¹é½ RemDet çš„è®­ç»ƒæ¡ä»¶

```
RemDet-Tinyè®­ç»ƒé…ç½®:
  æ•°æ®: VisDrone + UAVDT + (COCOé¢„è®­ç»ƒ?)
  å›¾åƒ: 30K+
  Epochs: 300
  â†“
æˆ‘ä»¬çš„é…ç½®:
  æ•°æ®: VisDrone (6K) + UAVDT (23K) = 29K âœ…
  Epochs: 300 âœ…
  æ¨¡å‹: YOLO12n (2.7M) vs RemDet-Tiny (3.2M) âœ…
```

### 2. é¿å…è¿‡æ‹Ÿåˆå•æ•°æ®é›†

```
å•æ•°æ®é›†è°ƒå‚:
  åœ¨VisDroneç‰¹æ€§ä¸Šè¿‡åº¦ä¼˜åŒ–
    â†“
  Lossæƒé‡/FPN/æ•°æ®å¢å¼ºé’ˆå¯¹VisDrone
    â†“
  åŠ UAVDTåå¯èƒ½å¤±æ•ˆ,éœ€è¦é‡æ–°è°ƒå‚

å¤šæ•°æ®é›†ä»å¤´è®­ç»ƒ:
  ä¸€å¼€å§‹å°±è§è¿‡ä¸¤ä¸ªæ•°æ®é›†çš„åˆ†å¸ƒ
    â†“
  å­¦åˆ°æ›´é€šç”¨çš„ç‰¹å¾è¡¨ç¤º
    â†“
  åç»­ä¼˜åŒ–é€‚ç”¨äºä¸¤ä¸ªæ•°æ®é›†
```

### 3. Large æ€§èƒ½ç«‹å³æ”¹å–„

```
å½“å‰: VisDrone Largeæ ·æœ¬443ä¸ª (0.1%)
      â†“ Precision=88.9%, Recall=31.6% (çœ‹å¾—å‡†ä½†æ‰¾ä¸å…¨)

åŠ UAVDT: Largeæ ·æœ¬ ~10,000ä¸ª (30-40%)
         â†“ å¬å›ç‡æ˜¾è‘—æå‡ (é¢„æœŸRecall 50-60%)
         â†“ Large mAP 42-44% (æ¥è¿‘RemDet)
```

---

## ğŸ“‹ ç´§æ€¥ä»»åŠ¡è°ƒæ•´

### âŒ å–æ¶ˆçš„ä»»åŠ¡

1. ~~å›æ»š Loss æƒé‡å®éªŒ~~ - å®éªŒæœ¬èº«æ–¹å‘å°±é”™äº†
2. ~~å•æ•°æ®é›† Loss æƒé‡ä¼˜åŒ–~~ - æ•°æ®ä¸å…¨,ä¼˜åŒ–æ— æ„ä¹‰
3. ~~å•æ•°æ®é›† FPN ä¼˜åŒ–~~ - åº”è¯¥åœ¨å¤šæ•°æ®é›†ä¸Šä¼˜åŒ–
4. ~~å•æ•°æ®é›†æ•°æ®å¢å¼º~~ - åŒä¸Š

### âœ… æ–°çš„ä¼˜å…ˆçº§

**Phase 1 (ç«‹å³å¼€å§‹,1-2 å¤©)**:

1. ğŸ¥‡ ä¸‹è½½ UAVDT æ•°æ®é›†
2. ğŸ¥‡ è½¬æ¢ UAVDT æ ‡æ³¨æ ¼å¼ (XML â†’ YOLO)
3. ğŸ¥‡ ç”Ÿæˆ UAVDT æ·±åº¦å›¾ (ZoeDepth)
4. ğŸ¥‡ åˆ›å»ºè”åˆæ•°æ®é›† YAML é…ç½®

**Phase 2 (Phase 1 å®Œæˆå,2-3 å¤©)**: 5. ğŸ¥ˆ å®ç°å¤šæ•°æ®é›†åŠ è½½å™¨ (MultiDatasetYOLO) 6. ğŸ¥ˆ å¯åŠ¨è”åˆè®­ç»ƒ (300 epochs, 30-40 å°æ—¶) 7. ğŸ¥ˆ ç›‘æ§è®­ç»ƒè¿›åº¦ (æ¯å¤©æ£€æŸ¥ loss/mAP)

**Phase 3 (Phase 2 å®Œæˆå,è§†æƒ…å†µ)**: 8. ğŸ¥‰ éªŒè¯æ€§èƒ½æ˜¯å¦è¾¾åˆ°é¢„æœŸ (Small 35%+, Overall 45%+) 9. ğŸ¥‰ å¦‚æœå·²è¶… RemDet-Tiny,è€ƒè™‘å†™è®ºæ–‡ 10. ğŸ¥‰ å¦‚æœè¿˜æœ‰å·®è·,å†è€ƒè™‘ Loss/FPN/æ•°æ®å¢å¼ºä¼˜åŒ–

---

## ğŸ’¡ æ ¸å¿ƒæ•™è®­

### âŒ æˆ‘ä¹‹å‰çš„é”™è¯¯

1. **è¿‡åº¦å…³æ³¨å•æ•°æ®é›†ä¼˜åŒ–** - å¿½ç•¥äº† RemDet ç”¨å¤šæ•°æ®é›†çš„äº‹å®
2. **é”™è¯¯çš„ Loss æƒé‡æ–¹å‘** - SmallÃ—2.0 åŠ å‰§ä¸å¹³è¡¡
3. **è¿‡æ—©ä¼˜åŒ–ç»†èŠ‚** - åº”è¯¥å…ˆå®Œæˆæ•°æ®é›†é…ç½®

### âœ… æ­£ç¡®çš„æ€è·¯

1. **å¯¹é½è®­ç»ƒæ¡ä»¶** - å…ˆå¤ç° RemDet çš„æ•°æ®é›†é…ç½®
2. **Small æ˜¯æ ¸å¿ƒ,ä½†ä¸çº ç»“ Large** - Large æ€§èƒ½å·®æ˜¯æ•°æ®é—®é¢˜
3. **å¤šæ•°æ®é›†æ˜¯å¿…ç»ä¹‹è·¯** - ä¸æ˜¯ Phase 2 è€Œæ˜¯ Phase 1!

---

## ğŸš€ ç«‹å³è¡ŒåŠ¨

**ç°åœ¨å°±å¼€å§‹å‡†å¤‡ UAVDT æ•°æ®é›†!**

```bash
# 1. åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p /data2/user/2024/lzy/UAVDT_preparation
cd /data2/user/2024/lzy/UAVDT_preparation

# 2. ä¸‹è½½UAVDT (éœ€è¦ä½ æä¾›ä¸‹è½½é“¾æ¥æˆ–å·²æœ‰æ•°æ®è·¯å¾„)
# å¦‚æœä½ å·²ç»æœ‰UAVDTæ•°æ®,å‘Šè¯‰æˆ‘è·¯å¾„
# å¦‚æœæ²¡æœ‰,æˆ‘å¸®ä½ å†™ä¸‹è½½è„šæœ¬

# 3. åˆ›å»ºè½¬æ¢è„šæœ¬
# (æˆ‘å¯ä»¥å¸®ä½ å®Œå–„ä¸Šé¢çš„convert_uavdt_to_yolo.py)

# 4. å¼€å§‹è½¬æ¢
python convert_uavdt_to_yolo.py

# 5. ç”Ÿæˆæ·±åº¦å›¾
python generate_depths_uavdt.py
```

**é¢„è®¡å®Œæˆæ—¶é—´**:

- UAVDT å‡†å¤‡: 1-2 å¤© (å–å†³äºæ•°æ®ä¸‹è½½é€Ÿåº¦)
- è”åˆè®­ç»ƒ: 30-40 å°æ—¶
- æ€»è®¡: 3-4 å¤©å°±èƒ½çœ‹åˆ°ç»“æœ!

---

**ä½ çš„ç›´è§‰æ˜¯å¯¹çš„!** ç«‹å³å¼€å§‹å¤šæ•°æ®é›†è®­ç»ƒæ‰æ˜¯æ­£ç¡®è·¯å¾„ã€‚Loss æƒé‡å®éªŒå¤±è´¥åè€Œæé†’äº†æˆ‘ä»¬: åœ¨ä¸å®Œæ•´æ•°æ®ä¸Šè°ƒå‚æ˜¯æµªè´¹æ—¶é—´,åº”è¯¥å…ˆæŠŠæ•°æ®é›†è¡¥å…¨ã€‚
