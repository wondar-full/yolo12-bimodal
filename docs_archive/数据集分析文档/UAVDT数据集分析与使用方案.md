# UAVDT æ•°æ®é›†åˆ†æä¸å¤šæ¨¡æ€è®­ç»ƒæ–¹æ¡ˆ

**æ—¥æœŸ**: 2025-10-31  
**æ•°æ®é›†ä½ç½®**: `yoloDepth\datasets\UAVDT`  
**ç›®æ ‡**: å°† UAVDT ä¸ VisDrone è”åˆè®­ç»ƒ,å¤ç° RemDet çš„å¤šæ•°æ®é›†ç­–ç•¥

---

## ğŸ“Š UAVDT æ•°æ®é›†ç»“æ„åˆ†æ

### 1. åŸºæœ¬ä¿¡æ¯

```
æ•°æ®é›†å®Œæ•´è·¯å¾„: yoloDepth/datasets/UAVDT/
â”œâ”€â”€ images/
â”‚   â””â”€â”€ UAV-benchmark-M/
â”‚       â”œâ”€â”€ M0101/  # åºåˆ—1
â”‚       â”œâ”€â”€ M0201/  # åºåˆ—2
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ M1401/  # åºåˆ—30
â””â”€â”€ annotations/
    â”œâ”€â”€ UAV-benchmark-M-Train.json  (74.5MB, COCOæ ¼å¼)
    â””â”€â”€ UAV-benchmark-M-Val.json
```

**å…³é”®æ•°æ®**:

- âœ… è®­ç»ƒå›¾åƒ: **23,829 å¼ ** (vs ä¹‹å‰ä¼°ç®—çš„ 23,258,æ›´å¤š!)
- âœ… è®­ç»ƒåºåˆ—: **30 ä¸ªè§†é¢‘åºåˆ—**
- âœ… æ€»æ ‡æ³¨æ•°: **422,911 ä¸ª** (å¹³å‡æ¯å¼ å›¾ 17.75 ä¸ªç›®æ ‡!)
- âœ… æ ‡æ³¨æ ¼å¼: **COCO JSON** (ä¸ VisDrone çš„ YOLO æ ¼å¼ä¸åŒ)

### 2. ç±»åˆ«ä¿¡æ¯

```python
Categories (3ç±»):
  - ID: 0, Name: car      â†’ 394,633ä¸ªæ ‡æ³¨ (93.3%)
  - ID: 1, Name: truck    â†’  17,491ä¸ªæ ‡æ³¨ (4.1%)
  - ID: 2, Name: bus      â†’  10,787ä¸ªæ ‡æ³¨ (2.6%)
```

**ä¸ VisDrone çš„ç±»åˆ«å¯¹åº”**:

```python
# VisDroneæœ‰10ä¸ªç±»åˆ«(ID 0-9)
UAVDT â†’ VisDrone æ˜ å°„:
  car (0)   â†’ car (4)        # VisDroneçš„caræ˜¯ID 4
  truck (1) â†’ truck (6)      # VisDroneçš„truckæ˜¯ID 6
  bus (2)   â†’ bus (9)        # VisDroneçš„busæ˜¯ID 9
```

**é‡è¦**: UAVDT åªæœ‰è½¦è¾†ç±»,æ²¡æœ‰è¡Œäºº/è‡ªè¡Œè½¦ç­‰,è¿™æ˜¯**é¢†åŸŸäº’è¡¥**çš„å…³é”®!

### 3. ç›®æ ‡å°ºå¯¸åˆ†å¸ƒ (é‡ç‚¹!)

```
Small (<32Â²=1024åƒç´ Â²):   212,423ä¸ª (50.2%)  â† æ¯”VisDroneå°‘
Medium (32Â²-96Â²):         204,588ä¸ª (48.4%)  â† å‡ ä¹ä¸€åŠ!
Large (>96Â²=9216åƒç´ Â²):     5,900ä¸ª (1.4%)   â† VisDroneçš„13å€!
```

**å…³é”®å‘ç°**:

| æ•°æ®é›†   | Small | Medium | Large  | æ€»è®¡     |
| -------- | ----- | ------ | ------ | -------- |
| VisDrone | 92.4% | 7.5%   | 0.1%   | ~400K    |
| UAVDT    | 50.2% | 48.4%  | 1.4%   | 422,911  |
| äº’è¡¥æ€§   | ä½    | **é«˜** | **é«˜** | **å®Œç¾** |

**ç»“è®º**: UAVDT ä¸æ˜¯ç”¨æ¥æå‡ Small çš„(VisDrone å·²ç»å¤Ÿäº†),è€Œæ˜¯**è¡¥å…… Medium å’Œ Large æ ·æœ¬**!

---

## ğŸ“š å…«è‚¡çŸ¥è¯†ç‚¹: COCO æ ¼å¼ vs YOLO æ ¼å¼

### é—®é¢˜: ä»€ä¹ˆæ˜¯ COCO JSON æ ¼å¼?

**æ ‡å‡†ç­”æ¡ˆ**:
COCO (Common Objects in Context) JSON æ˜¯ä¸€ç§å¸¸ç”¨çš„ç›®æ ‡æ£€æµ‹æ ‡æ³¨æ ¼å¼,åŒ…å« 4 ä¸ªä¸»è¦å­—æ®µ:

```json
{
  "images": [
    {
      "id": 0,
      "file_name": "M1306/img_mask/img000001.jpg",
      "width": 1024,
      "height": 540
    }
  ],
  "annotations": [
    {
      "id": 0,
      "image_id": 0,
      "category_id": 0,
      "bbox": [829, 179, 45, 20],  # [x_min, y_min, width, height] ç»å¯¹åƒç´ åæ ‡
      "area": 900,
      "iscrowd": 0
    }
  ],
  "categories": [
    {"id": 0, "name": "car"}
  ]
}
```

**YOLO æ ¼å¼** (VisDrone ä½¿ç”¨çš„):

```
# æ¯ä¸ªå›¾åƒä¸€ä¸ªtxtæ–‡ä»¶,æ¯è¡Œä¸€ä¸ªç›®æ ‡
class_id center_x center_y width height  # å½’ä¸€åŒ–åˆ°[0,1]
4 0.5234 0.3567 0.0456 0.0234
```

**æœ¬é¡¹ç›®åº”ç”¨**:

- VisDrone: å·²ç»æ˜¯ YOLO æ ¼å¼,å¯ä»¥ç›´æ¥ç”¨
- UAVDT: COCO æ ¼å¼,éœ€è¦è½¬æ¢ â†’ `convert_uavdt_to_yolo.py`

**è½¬æ¢æ ¸å¿ƒä»£ç **:

```python
# COCO bbox [x, y, w, h] â†’ YOLO [cx, cy, w, h] (å½’ä¸€åŒ–)
x_min, y_min, bbox_w, bbox_h = coco_bbox
img_w, img_h = image_width, image_height

center_x = (x_min + bbox_w / 2) / img_w
center_y = (y_min + bbox_h / 2) / img_h
norm_w = bbox_w / img_w
norm_h = bbox_h / img_h

yolo_format = f"{class_id} {center_x} {center_y} {norm_w} {norm_h}"
```

**å¸¸è§è¿½é—®**: ä¸ºä»€ä¹ˆ YOLO ç”¨å½’ä¸€åŒ–åæ ‡?

- **ç­”**: å½’ä¸€åŒ–ååæ ‡ä¸å›¾åƒå°ºå¯¸æ— å…³,æ¨¡å‹å¯ä»¥å¤„ç†ä»»æ„å¤§å°çš„å›¾åƒ
- è®­ç»ƒæ—¶ resize åˆ° 640x640,æ¨ç†æ—¶å¯ä»¥ç”¨å…¶ä»–å°ºå¯¸
- ç®€åŒ–æ•°æ®å¢å¼º(ç¼©æ”¾/è£å‰ª)çš„åæ ‡å˜æ¢

**æ˜“é”™ç‚¹**:

- âŒ å¿˜è®°å½’ä¸€åŒ– â†’ bbox åæ ‡>1,è®­ç»ƒå¤±è´¥
- âŒ COCO çš„ bbox æ˜¯[x,y,w,h],ä¸æ˜¯[x1,y1,x2,y2]
- âŒ ç±»åˆ« ID æ²¡æœ‰å¯¹åº” VisDrone â†’ ç±»åˆ«é”™ä¹±

---

## ğŸ” RemDet è®ºæ–‡ä¸­çš„ UAVDT ä½¿ç”¨æ–¹å¼

### RemDet çš„å¤šæ•°æ®é›†ç­–ç•¥

æ ¹æ®è®ºæ–‡å’Œæˆ‘ä»¬çš„åˆ†æ:

**RemDet ä½¿ç”¨çš„æ•°æ®é›†**:

1. **VisDrone-DET** (6,471 train) - ä¸»æ•°æ®é›†,è¯„ä¼°åŸºå‡†
2. **UAVDT** (23,829 train) - è¡¥å…… Medium/Large æ ·æœ¬
3. **COCO** (å¯èƒ½ç”¨äºé¢„è®­ç»ƒæˆ–è¾…åŠ©è®­ç»ƒ)

**è®­ç»ƒç­–ç•¥** (æ¨æµ‹,è®ºæ–‡æœªæ˜ç¡®è¯´æ˜):

```
æ–¹æ¡ˆæ¨æµ‹: è”åˆè®­ç»ƒ (Joint Training)

VisDrone : UAVDT = 1.0 : 0.5 é‡‡æ ·æƒé‡
    â†“
æ¯ä¸ªepoch:
  - 60% batchæ¥è‡ªVisDrone
  - 40% batchæ¥è‡ªUAVDT
    â†“
éªŒè¯/æµ‹è¯•åªç”¨VisDrone (å¯¹é½benchmark)
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡?**

1. **VisDrone æ˜¯ä¸»ä»»åŠ¡** - è¯„ä¼°åœ¨ VisDrone ä¸Š,éœ€è¦æ›´å¤šé‡‡æ ·
2. **UAVDT æ˜¯è¾…åŠ©** - åªè¡¥å…… Medium/Large,ä¸åº”ä¸»å¯¼è®­ç»ƒ
3. **åŸŸç›¸ä¼¼æ€§é«˜** - éƒ½æ˜¯ UAV è§†è§’,è”åˆè®­ç»ƒä¸ä¼šå†²çª
4. **ç±»åˆ«äº’è¡¥** - UAVDT åªæœ‰è½¦è¾†,ä¸å½±å“ VisDrone çš„è¡Œäºº/è‡ªè¡Œè½¦æ£€æµ‹

### RemDet çš„æ€§èƒ½æå‡åˆ†æ

| æŒ‡æ ‡        | RemDet-Tiny | æˆ‘ä»¬çš„ baseline (VisDrone only) | è”åˆè®­ç»ƒé¢„æœŸ |
| ----------- | ----------- | ------------------------------- | ------------ |
| Overall mAP | 38.9%       | ~41%                            | **45-47%**   |
| Small mAP   | 12.7%       | **30.94%** (å·²ç¢¾å‹)             | **35-38%**   |
| Medium mAP  | 33.0%       | 46.24% (å·²è¶…è¶Š)                 | **48-50%**   |
| Large mAP   | 44.5%       | 36.70% (è½å)                   | **42-45%**   |

**å…³é”®æ´å¯Ÿ**:

- æˆ‘ä»¬ Small å·²ç»é¢†å…ˆ RemDet-Tiny **143%** (+18.2 ä¸ªç‚¹)
- Large è½åæ˜¯æ•°æ®é—®é¢˜ (443 vs 5,900 æ ·æœ¬)
- åŠ å…¥ UAVDT å,Large æ€§èƒ½å°†å¤§å¹…æå‡
- æœ‰æœºä¼šåœ¨**æ‰€æœ‰æŒ‡æ ‡ä¸Š**å…¨é¢è¶…è¶Š RemDet-Tiny!

---

## ğŸ› ï¸ UAVDT æ•°æ®é¢„å¤„ç†æµç¨‹

### Phase 1: COCO JSON â†’ YOLO TXT è½¬æ¢

#### 1.1 åˆ›å»ºè½¬æ¢è„šæœ¬

```python
# convert_uavdt_to_yolo.py
import json
import os
from pathlib import Path
from tqdm import tqdm

# ç±»åˆ«æ˜ å°„: UAVDT â†’ VisDrone
CATEGORY_MAP = {
    0: 4,  # car â†’ car (VisDrone ID 4)
    1: 6,  # truck â†’ truck (VisDrone ID 6)
    2: 9   # bus â†’ bus (VisDrone ID 9)
}

def convert_coco_to_yolo(json_path, images_root, output_root):
    """
    å°†UAVDTçš„COCO JSONè½¬æ¢ä¸ºYOLOæ ¼å¼

    Args:
        json_path: COCO JSONæ–‡ä»¶è·¯å¾„
        images_root: å›¾åƒæ ¹ç›®å½• (UAV-benchmark-M/)
        output_root: è¾“å‡ºæ ¹ç›®å½•
    """
    print(f"åŠ è½½ {json_path}...")
    with open(json_path, 'r') as f:
        coco_data = json.load(f)

    images = {img['id']: img for img in coco_data['images']}
    annotations = coco_data['annotations']

    # åˆ›å»ºè¾“å‡ºç›®å½•
    labels_dir = Path(output_root) / 'labels'
    labels_dir.mkdir(parents=True, exist_ok=True)

    # æŒ‰å›¾åƒIDåˆ†ç»„æ ‡æ³¨
    img_annotations = {}
    for ann in annotations:
        img_id = ann['image_id']
        if img_id not in img_annotations:
            img_annotations[img_id] = []
        img_annotations[img_id].append(ann)

    print(f"è½¬æ¢ {len(images)} å¼ å›¾åƒçš„æ ‡æ³¨...")
    for img_id, img_info in tqdm(images.items()):
        # è·å–å›¾åƒä¿¡æ¯
        img_w = img_info['width']
        img_h = img_info['height']
        file_name = img_info['file_name']  # "M1306/img_mask/img000001.jpg"

        # æå–åºåˆ—åå’Œå›¾åƒå
        # "M1306/img_mask/img000001.jpg" â†’ "M1306_img000001"
        parts = file_name.split('/')
        seq_name = parts[0]  # "M1306"
        img_name = parts[-1].replace('.jpg', '')  # "img000001"

        # è¾“å‡ºæ ‡æ³¨æ–‡ä»¶è·¯å¾„
        label_file = labels_dir / f"{seq_name}_{img_name}.txt"

        # è½¬æ¢è¯¥å›¾åƒçš„æ‰€æœ‰æ ‡æ³¨
        yolo_lines = []
        if img_id in img_annotations:
            for ann in img_annotations[img_id]:
                # COCO bbox: [x_min, y_min, width, height]
                x_min, y_min, bbox_w, bbox_h = ann['bbox']

                # è½¬æ¢ä¸ºYOLOæ ¼å¼: [center_x, center_y, width, height] (å½’ä¸€åŒ–)
                center_x = (x_min + bbox_w / 2) / img_w
                center_y = (y_min + bbox_h / 2) / img_h
                norm_w = bbox_w / img_w
                norm_h = bbox_h / img_h

                # æ˜ å°„ç±»åˆ«ID
                coco_cat_id = ann['category_id']
                yolo_cat_id = CATEGORY_MAP[coco_cat_id]

                # YOLOæ ¼å¼: class_id cx cy w h
                yolo_line = f"{yolo_cat_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\n"
                yolo_lines.append(yolo_line)

        # å†™å…¥æ–‡ä»¶ (å³ä½¿æ²¡æœ‰æ ‡æ³¨ä¹Ÿåˆ›å»ºç©ºæ–‡ä»¶)
        with open(label_file, 'w') as f:
            f.writelines(yolo_lines)

    print(f"âœ… è½¬æ¢å®Œæˆ! æ ‡æ³¨æ–‡ä»¶ä¿å­˜åˆ°: {labels_dir}")

def organize_images(images_root, output_root):
    """
    é‡ç»„å›¾åƒç›®å½•ç»“æ„: M0101/img1/xxx.jpg â†’ images/M0101_xxx.jpg
    """
    images_dir = Path(output_root) / 'images'
    images_dir.mkdir(parents=True, exist_ok=True)

    sequences = sorted(Path(images_root).glob('M*'))
    print(f"é‡ç»„ {len(sequences)} ä¸ªåºåˆ—çš„å›¾åƒ...")

    for seq_dir in tqdm(sequences):
        seq_name = seq_dir.name  # "M0101"
        img1_dir = seq_dir / 'img1'

        if not img1_dir.exists():
            print(f"âš ï¸ åºåˆ— {seq_name} æ²¡æœ‰img1ç›®å½•,è·³è¿‡")
            continue

        # å¤åˆ¶æ‰€æœ‰å›¾åƒ
        for img_path in img1_dir.glob('*.jpg'):
            img_name = img_path.stem  # "img000001"
            new_name = f"{seq_name}_{img_name}.jpg"
            new_path = images_dir / new_name

            # åˆ›å»ºè½¯é“¾æ¥(èŠ‚çœç©ºé—´) æˆ– å¤åˆ¶æ–‡ä»¶
            if not new_path.exists():
                new_path.symlink_to(img_path.absolute())  # Windowså¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™
                # æˆ–ä½¿ç”¨: shutil.copy(img_path, new_path)

    print(f"âœ… å›¾åƒé‡ç»„å®Œæˆ! ä¿å­˜åˆ°: {images_dir}")

if __name__ == '__main__':
    # è·¯å¾„é…ç½®
    uavdt_root = r'f:\CV\Paper\yoloDepth\yoloDepth\datasets\UAVDT'
    output_root = r'f:\CV\Paper\yoloDepth\yoloDepth\datasets\UAVDT_YOLO'

    # è½¬æ¢è®­ç»ƒé›†
    print("\n" + "="*60)
    print("è½¬æ¢ UAVDT Train æ ‡æ³¨")
    print("="*60)
    convert_coco_to_yolo(
        json_path=f'{uavdt_root}/annotations/UAV-benchmark-M-Train.json',
        images_root=f'{uavdt_root}/images/UAV-benchmark-M',
        output_root=f'{output_root}/train'
    )

    # é‡ç»„è®­ç»ƒé›†å›¾åƒ
    organize_images(
        images_root=f'{uavdt_root}/images/UAV-benchmark-M',
        output_root=f'{output_root}/train'
    )

    # è½¬æ¢éªŒè¯é›†
    print("\n" + "="*60)
    print("è½¬æ¢ UAVDT Val æ ‡æ³¨")
    print("="*60)
    convert_coco_to_yolo(
        json_path=f'{uavdt_root}/annotations/UAV-benchmark-M-Val.json',
        images_root=f'{uavdt_root}/images/UAV-benchmark-M',
        output_root=f'{output_root}/val'
    )

    # é‡ç»„éªŒè¯é›†å›¾åƒ
    organize_images(
        images_root=f'{uavdt_root}/images/UAV-benchmark-M',
        output_root=f'{output_root}/val'
    )

    print("\n" + "="*60)
    print("âœ… UAVDT æ•°æ®é›†è½¬æ¢å®Œæˆ!")
    print("="*60)
    print(f"è¾“å‡ºç›®å½•: {output_root}")
    print("ç›®å½•ç»“æ„:")
    print("  train/")
    print("    images/  (23,829å¼ )")
    print("    labels/  (23,829ä¸ªtxt)")
    print("  val/")
    print("    images/")
    print("    labels/")
```

#### 1.2 è¿è¡Œè½¬æ¢

```bash
cd f:\CV\Paper\yoloDepth\yoloDepth
python convert_uavdt_to_yolo.py
```

**é¢„è®¡è€—æ—¶**: 5-10 åˆ†é’Ÿ (ä¸»è¦æ˜¯ JSON è§£æå’Œæ–‡ä»¶åˆ›å»º)

---

### Phase 2: ç”Ÿæˆ RGB-D æ·±åº¦å›¾

#### 2.1 ä½¿ç”¨ ZoeDepth æ‰¹é‡ç”Ÿæˆ

```python
# generate_depths_uavdt.py
import torch
from PIL import Image
from pathlib import Path
from tqdm import tqdm
import numpy as np

# åŠ è½½ ZoeDepth æ¨¡å‹
print("åŠ è½½ ZoeDepth æ¨¡å‹...")
model = torch.hub.load('isl-org/ZoeDepth', 'ZoeD_N', pretrained=True)
model.eval()
model.cuda()

def generate_depth(image_path, output_path):
    """ä¸ºå•å¼ å›¾åƒç”Ÿæˆæ·±åº¦å›¾"""
    # è¯»å–RGBå›¾åƒ
    rgb = Image.open(image_path).convert('RGB')

    # ç”Ÿæˆæ·±åº¦å›¾
    with torch.no_grad():
        depth = model.infer_pil(rgb)

    # å½’ä¸€åŒ–åˆ°0-255
    depth_normalized = (depth - depth.min()) / (depth.max() - depth.min()) * 255
    depth_uint8 = depth_normalized.astype(np.uint8)

    # ä¿å­˜ä¸ºç°åº¦PNG
    depth_img = Image.fromarray(depth_uint8, mode='L')
    depth_img.save(output_path)

def batch_generate_depths(images_dir, output_dir):
    """æ‰¹é‡ç”Ÿæˆæ·±åº¦å›¾"""
    images_dir = Path(images_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è·å–æ‰€æœ‰å›¾åƒ
    image_files = sorted(images_dir.glob('*.jpg'))
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")

    # æ‰¹é‡å¤„ç†
    for img_path in tqdm(image_files, desc="ç”Ÿæˆæ·±åº¦å›¾"):
        depth_path = output_dir / img_path.name.replace('.jpg', '.png')

        if depth_path.exists():
            continue  # è·³è¿‡å·²å­˜åœ¨çš„

        try:
            generate_depth(img_path, depth_path)
        except Exception as e:
            print(f"âš ï¸ {img_path.name} ç”Ÿæˆå¤±è´¥: {e}")

if __name__ == '__main__':
    uavdt_yolo = r'f:\CV\Paper\yoloDepth\yoloDepth\datasets\UAVDT_YOLO'

    # è®­ç»ƒé›†
    print("\n" + "="*60)
    print("ç”Ÿæˆ UAVDT Train æ·±åº¦å›¾")
    print("="*60)
    batch_generate_depths(
        images_dir=f'{uavdt_yolo}/train/images',
        output_dir=f'{uavdt_yolo}/train/depths'
    )

    # éªŒè¯é›†
    print("\n" + "="*60)
    print("ç”Ÿæˆ UAVDT Val æ·±åº¦å›¾")
    print("="*60)
    batch_generate_depths(
        images_dir=f'{uavdt_yolo}/val/images',
        output_dir=f'{uavdt_yolo}/val/depths'
    )

    print("\nâœ… æ·±åº¦å›¾ç”Ÿæˆå®Œæˆ!")
```

#### 2.2 è¿è¡Œæ·±åº¦ç”Ÿæˆ

```bash
cd f:\CV\Paper\yoloDepth\yoloDepth
python generate_depths_uavdt.py
```

**é¢„è®¡è€—æ—¶**: 4-6 å°æ—¶ (23,829 å¼ å›¾åƒ Ã— ~1 ç§’/å¼ )

---

## ğŸ”§ å¤šæ•°æ®é›†è”åˆè®­ç»ƒé…ç½®

### æ–¹æ¡ˆ 1: ç®€å•æ‹¼æ¥ (æ¨èå…ˆè¯•)

åˆ›å»º `data/visdrone_uavdt_joint.yaml`:

```yaml
# VisDrone + UAVDT è”åˆæ•°æ®é›†é…ç½®

path: f:/CV/Paper/yoloDepth/yoloDepth/datasets # æ•°æ®é›†æ ¹ç›®å½•

# è®­ç»ƒé›†: æ‹¼æ¥ä¸¤ä¸ªæ•°æ®é›†
train:
  - VisDrone/images/train # 6,471å¼ 
  - UAVDT_YOLO/train/images # 23,829å¼ 
  # æ€»è®¡: 30,300å¼ 

# éªŒè¯é›†: åªç”¨VisDrone (å¯¹é½RemDetè¯„ä¼°)
val: VisDrone/images/val # 548å¼ 

# æ·±åº¦å›¾è·¯å¾„
train_depth:
  - VisDrone/depths/train
  - UAVDT_YOLO/train/depths

val_depth: VisDrone/depths/val

# ç±»åˆ«æ•° (ä½¿ç”¨VisDroneçš„10ç±»)
nc: 10

# ç±»åˆ«åç§°
names:
  0: ignored
  1: pedestrian
  2: people
  3: bicycle
  4: car
  5: van
  6: truck
  7: tricycle
  8: awning-tricycle
  9: bus
  10: motor
# æ³¨æ„: UAVDTåªæœ‰car(4), truck(6), bus(9)ä¸‰ç±»
# å…¶ä»–ç±»åˆ«åªæœ‰VisDroneæä¾›
```

**ä¼˜ç‚¹**: å®ç°ç®€å•,Ultralytics åŸç”Ÿæ”¯æŒå¤šè·¯å¾„
**ç¼ºç‚¹**: æ— æ³•æ§åˆ¶é‡‡æ ·æƒé‡ (UAVDT å  80%,VisDrone ä»… 20%)

### æ–¹æ¡ˆ 2: åŠ æƒé‡‡æ · (æ›´ä¼˜,éœ€ä¿®æ”¹ä»£ç )

åˆ›å»º `data/visdrone_uavdt_weighted.yaml`:

```yaml
path: f:/CV/Paper/yoloDepth/yoloDepth/datasets

# æ•°æ®é›†åˆ—è¡¨ (å¸¦æƒé‡)
datasets:
  - name: visdrone
    train: VisDrone/images/train
    val: VisDrone/images/val
    train_depth: VisDrone/depths/train
    val_depth: VisDrone/depths/val
    weight: 1.0 # 100%é‡‡æ ·ç‡

  - name: uavdt
    train: UAVDT_YOLO/train/images
    train_depth: UAVDT_YOLO/train/depths
    weight: 0.5 # 50%é‡‡æ ·ç‡ (ç›¸å¯¹VisDrone)

# éªŒè¯åªç”¨VisDrone
val_dataset: visdrone

nc: 10
names:
  [
    ignored,
    pedestrian,
    people,
    bicycle,
    car,
    van,
    truck,
    tricycle,
    awning-tricycle,
    bus,
    motor,
  ]
```

**é‡‡æ ·ç­–ç•¥**:

```python
# æ¯ä¸ªepochçš„batchåˆ†å¸ƒ (ä¼ªä»£ç )
visdrone_samples = 6471 * 1.0 = 6471
uavdt_samples = 23829 * 0.5 = 11915
total_samples = 18386

æ¯ä¸ªbatch (16å¼ å›¾):
  - VisDrone: 6å¼  (35%)
  - UAVDT: 10å¼  (65%)
```

**å®ç°**: éœ€è¦ä¿®æ”¹ `ultralytics/data/dataset.py` æ·»åŠ  `WeightedMultiDataset` ç±»

---

## ğŸ“ TODO æ›´æ–°

åŸºäº UAVDT æ•°æ®é›†çš„å®é™…æƒ…å†µ,æ›´æ–°å¾…åŠäº‹é¡¹:

### âœ… å·²å®Œæˆ

- [x] ç¡®è®¤ UAVDT æ•°æ®é›†å­˜åœ¨ (yoloDepth/datasets/UAVDT)
- [x] åˆ†æ UAVDT ç»“æ„ (COCO æ ¼å¼, 23,829 å¼ , 3 ç±», 422K æ ‡æ³¨)
- [x] ç†è§£å°ºå¯¸åˆ†å¸ƒäº’è¡¥æ€§ (UAVDT æä¾› 48% Medium, 1.4% Large)

### â³ å¾…æ‰§è¡Œ (ä¼˜å…ˆçº§ 1)

1. **è½¬æ¢ UAVDT æ ‡æ³¨** (é¢„è®¡ 10 åˆ†é’Ÿ)
   - è¿è¡Œ `convert_uavdt_to_yolo.py`
   - è¾“å‡º: UAVDT_YOLO/train/{images,labels}/
2. **ç”Ÿæˆ UAVDT æ·±åº¦å›¾** (é¢„è®¡ 4-6 å°æ—¶)
   - è¿è¡Œ `generate_depths_uavdt.py`
   - è¾“å‡º: UAVDT_YOLO/train/depths/
3. **åˆ›å»ºè”åˆæ•°æ®é›†é…ç½®**
   - æ–¹æ¡ˆ 1: `visdrone_uavdt_joint.yaml` (ç®€å•æ‹¼æ¥)
   - æ–¹æ¡ˆ 2: `visdrone_uavdt_weighted.yaml` (åŠ æƒé‡‡æ ·)
4. **å¯åŠ¨è”åˆè®­ç»ƒ**
   ```bash
   CUDA_VISIBLE_DEVICES=7 python train_depth.py \
       --data data/visdrone_uavdt_joint.yaml \
       --epochs 300 \
       --batch 16 \
       --imgsz 640 \
       --device 0 \
       --project runs/train \
       --name exp_joint_visdrone_uavdt_v1 \
       --weights yolo12n.pt \
       --save_period 50
   ```

### ğŸ¯ é¢„æœŸç»“æœ

| æŒ‡æ ‡        | Baseline (VisDrone only) | è”åˆè®­ç»ƒç›®æ ‡ | RemDet-Tiny | èƒœç‡  |
| ----------- | ------------------------ | ------------ | ----------- | ----- |
| Overall mAP | 41%                      | **45-47%**   | 38.9%       | +15%  |
| Small mAP   | 30.94%                   | **35-38%**   | 12.7%       | +180% |
| Medium mAP  | 46.24%                   | **48-50%**   | 33.0%       | +50%  |
| Large mAP   | 36.70%                   | **42-45%**   | 44.5%       | -2%   |

**å…³é”®ç›®æ ‡**: åœ¨ Small å’Œ Medium ä¸Šå…¨é¢ç¢¾å‹ RemDet, Large è¿½å¹³å³å¯!

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

**è¯·ç¡®è®¤ä»¥ä¸‹ä¿¡æ¯,ç„¶åæˆ‘ä»¬å¼€å§‹æ‰§è¡Œ**:

1. âœ… UAVDT æ•°æ®é›†è·¯å¾„ç¡®è®¤: `yoloDepth\datasets\UAVDT`
2. â“ æœåŠ¡å™¨ä¸Šæ˜¯å¦å·²å®‰è£… ZoeDepth? (éœ€è¦ç”¨æ¥ç”Ÿæˆæ·±åº¦å›¾)
3. â“ æ˜¯å¦æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´? (æ·±åº¦å›¾éœ€è¦~20GB)
4. â“ è®­ç»ƒç¯å¢ƒçš„ GPU æ˜¾å­˜? (batch size å¯èƒ½éœ€è¦è°ƒæ•´)

**æˆ‘ç°åœ¨ç«‹å³åˆ›å»ºè½¬æ¢è„šæœ¬,ä½ ç¡®è®¤åå°±å¯ä»¥è¿è¡Œ!** ğŸ¯
