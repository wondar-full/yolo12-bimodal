# yoloDepth 项目改进规划总表

> **创建时间**: 2025 年 10 月 30 日  
> **项目目标**: 超越 AAAI2025 RemDet 论文在 UAV 目标检测任务上的性能  
> **当前状态**: Phase 1 - VisDrone 单数据集优化阶段

---

## 📊 当前性能基线 (Baseline)

### 模型配置

- **模型**: YOLO12n-RGBD (双模态: RGB + Depth)
- **参数量**: 2.70M
- **FLOPs**: 11.95G
- **数据集**: VisDrone2019-DET (6,471 训练图像)
- **训练轮次**: 300 epochs
- **图像尺寸**: 640×640

### 性能指标 (VisDrone2019-DET val)

| 指标                | 当前值 | RemDet-Tiny | 差距      | 状态            |
| ------------------- | ------ | ----------- | --------- | --------------- |
| **Overall mAP@0.5** | ~41%   | 38.9%       | +2.1%     | ✅ 已超越       |
| **Small mAP**       | 30.94% | 12.7%       | **+143%** | ⭐⭐⭐ 显著优势 |
| **Medium mAP**      | 46.24% | 33.0%       | **+40%**  | ⭐⭐ 显著优势   |
| **Large mAP**       | 36.70% | 44.5%       | -17.5%    | ⚠️ 待改进       |

### 数据集分布分析

```
VisDrone训练集 (6,471图像):
  Small  (<32×32):   92.4%  (占绝对主导)
  Medium (32~96):     7.5%  (较少)
  Large  (≥96×96):    0.1%  (极度稀缺,仅443个!)

→ Large性能不佳的根本原因: 训练样本不足,非模型问题
```

---

## 🎯 改进总体策略

### 核心思路

```
Phase 1: VisDrone单数据集优化 (当前,1-2周)
    ↓ 目标: Small mAP 35%+, Overall 42%+

Phase 2: 多数据集联合训练 (2-4周后)
    ↓ VisDrone + UAVDT (补Large样本)
    ↓ 目标: Small 38%+, Large 44%+, Overall 45%+

Phase 3: 超越RemDet-M (4-8周后)
    ↓ 架构创新 + 完整数据集
    ↓ 目标: Overall 48%+
```

### 为什么不立即做多数据集?

1. ✅ UAVDT 数据集还需准备 (下载 23K 图像 + 生成深度图 = 3-5 天)
2. ✅ 先验证 idea 有效性 (Loss 调整、FPN 优化等)
3. ✅ 建立单数据集 Baseline (方便对比改进效果)
4. ✅ 避免多数据集干扰调试 (问题定位更清晰)

---

## 📋 Phase 1: VisDrone 单数据集优化 (当前)

**总体目标**: Small mAP 30.94% → 35%+, Overall mAP → 42%+

### 改进项列表

#### 🔥 改进 1: Loss 权重按尺寸调整 (最高优先级)

**实施时间**: 立即开始 (预计 2 小时完成代码)

**理论依据**:

- Small 目标占 92.4%,但 Loss 权重与 Medium/Large 相同 → 不公平!
- 应该让 Small 目标有更高的 Loss 权重,强化学习

**实现方案**:

```python
# 文件: ultralytics/utils/loss.py
# 类: v8DetectionLoss
# 方法: __call__

# 计算GT面积
gt_areas = (bbox[:, 2] - bbox[:, 0]) * (bbox[:, 3] - bbox[:, 1]) * (imgsz ** 2)

# 尺寸自适应权重
size_weight = torch.where(
    gt_areas < 1024, 2.0,      # Small ×2.0  ← 强化小目标
    torch.where(
        gt_areas < 9216, 1.5,  # Medium ×1.5
        1.0                     # Large ×1.0
    )
)

# 应用到各Loss分量
loss_box *= size_weight.unsqueeze(1)  # Box回归Loss
loss_cls *= size_weight.unsqueeze(1)  # 分类Loss
loss_dfl *= size_weight.unsqueeze(1)  # DFL Loss
```

**预期效果**:

- Small mAP: 30.94% → 33-34% (+2-3%)
- Overall mAP: ~41% → 42-43%

**验证方式**:

```bash
# 训练300 epochs
python train_depth.py --data data/visdrone-rgbd.yaml --epochs 300

# 验证
python val_depth.py --weights runs/train/exp_loss_weighted/weights/best.pt

# 对比Baseline
对比指标: Small/Medium/Large/Overall mAP变化
```

**风险评估**:

- ❌ 低风险: Loss 权重调整是成熟技术,不会引入新 bug
- ✅ 可回退: 如果效果不好,恢复原代码即可

---

#### 🔥 改进 2: FPN 小目标注意力优化

**实施时间**: Loss 改进完成后 (预计 1 天)

**理论依据**:

- FPN 特征融合时,小目标特征容易被大目标"淹没"
- 注意力机制可以增强小目标特征的表达

**实现方案**:

```python
# 文件: ultralytics/nn/modules/block.py
# 新增模块: SmallObjectAttention

class SmallObjectAttention(nn.Module):
    """小目标注意力模块 (CBAM简化版)"""
    def __init__(self, channels, reduction=16):
        super().__init__()
        # Channel Attention
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(channels // reduction, channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Channel attention
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        channel_att = self.sigmoid(avg_out + max_out)
        x = x * channel_att
        return x

# 在FPN的P3层(小目标层)插入注意力
# 文件: ultralytics/nn/tasks.py
# DetectionModel的forward中,P3输出后添加attention
```

**修改位置**:

- P3 层输出后 (80×80 特征图,对应小目标)
- P4 层可选添加 (40×40 特征图,对应中小目标)

**预期效果**:

- Small mAP: 额外提升 1-2%
- 代价: 推理速度略微下降 (~5%)

---

#### 🔥 改进 3: 小目标数据增强

**实施时间**: FPN 优化完成后 (预计 1-2 天)

**理论依据**:

- 当前数据增强对所有目标一视同仁
- 小目标需要特殊增强策略 (Copy-Paste, 多尺度)

**实现方案 A: Copy-Paste 增强**

```python
# 文件: ultralytics/data/augment.py
# 在Mosaic或MixUp后添加

def copy_paste_small_objects(img, labels, prob=0.3):
    """将小目标复制粘贴到其他位置"""
    if random.random() > prob:
        return img, labels

    # 提取小目标 (area < 1024)
    areas = (labels[:, 3] - labels[:, 1]) * (labels[:, 4] - labels[:, 2])
    small_mask = areas < (32*32 / 640**2)  # 归一化坐标
    small_objs = labels[small_mask]

    if len(small_objs) == 0:
        return img, labels

    # 随机选择1-3个小目标复制
    n_paste = min(random.randint(1, 3), len(small_objs))
    paste_objs = small_objs[random.sample(range(len(small_objs)), n_paste)]

    # 粘贴到随机位置 (避免重叠)
    # ... 实现细节

    return img, new_labels
```

**实现方案 B: 多尺度训练**

```python
# 文件: ultralytics/engine/trainer.py
# 在训练循环中动态调整img_size

# 每10个epoch切换尺度
if epoch % 10 == 0:
    img_size = random.choice([512, 576, 640, 704, 768])
    model.img_size = img_size
```

**预期效果**:

- Small mAP: 额外提升 1-2%
- 训练时间增加: ~10%

---

### Phase 1 验收标准

**必达目标** (Milestone 1):

- ✅ Small mAP > 35% (vs Baseline 30.94%)
- ✅ Overall mAP > 42% (vs Baseline ~41%)
- ✅ 保持推理速度 > 35 FPS (RTX 4090)

**理想目标**:

- 🎯 Small mAP > 37%
- 🎯 Overall mAP > 43%
- 🎯 Medium mAP > 48%

**验证方式**:

```bash
# 完整验证
python val_depth.py --weights runs/train/exp_final/weights/best.pt

# 生成对比报告
python generate_comparison_report.py \
    --baseline runs/train/baseline/weights/best.pt \
    --improved runs/train/exp_final/weights/best.pt \
    --output phase1_report.md
```

---

## 📋 Phase 2: 多数据集联合训练 (2-4 周后)

**前置条件**:

- ✅ Phase 1 完成,Small mAP 达到 35%+
- ✅ UAVDT 数据集准备完毕
- ✅ 多数据集 DataLoader 实现完成

### 数据集准备清单

#### UAVDT 数据集

| 任务                  | 工作量 | 负责人 | 状态      |
| --------------------- | ------ | ------ | --------- |
| 下载 UAVDT (23K 图像) | 1 天   | -      | ⏳ 待开始 |
| 标注转换 (XML→YOLO)   | 0.5 天 | -      | ⏳ 待开始 |
| 生成深度图 (ZoeDepth) | 2-3 天 | -      | ⏳ 待开始 |
| 类别映射设计          | 0.5 天 | -      | ⏳ 待开始 |
| 数据集验证            | 0.5 天 | -      | ⏳ 待开始 |

#### 类别映射方案

```python
# UAVDT (3类) → VisDrone (10类)
uavdt_to_visdrone_mapping = {
    0: 3,  # car → car
    1: 5,  # truck → truck
    2: 8   # bus → bus
}

# VisDrone类别列表
visdrone_classes = [
    'pedestrian', 'people', 'bicycle', 'car', 'van',
    'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'
]
```

### 多数据集配置文件

```yaml
# data/multi-dataset-rgbd.yaml

# 主数据集: VisDrone
visdrone:
  path: /data2/user/2024/lzy/Datasets/VisDrone2019-DET-YOLO/VisDrone2YOLO
  train: VisDrone2019-DET-train/images/rgb
  val: VisDrone2019-DET-val/images/rgb
  train_depth: VisDrone2019-DET-train/images/d
  val_depth: VisDrone2019-DET-val/images/d
  nc: 10
  weight: 1.0 # 100%采样
  names:
    [
      pedestrian,
      people,
      bicycle,
      car,
      van,
      truck,
      tricycle,
      awning-tricycle,
      bus,
      motor,
    ]

# 辅助数据集: UAVDT
uavdt:
  path: /data2/user/2024/lzy/Datasets/UAVDT
  train: train/images
  val: val/images
  train_depth: train/depths
  val_depth: val/depths
  nc: 3
  weight: 0.5 # 50%采样
  names: [car, truck, bus]
  class_mapping: # 映射到VisDrone类别
    0: 3 # car
    1: 5 # truck
    2: 8 # bus

# 联合训练设置
training:
  primary_dataset: visdrone # 主要评估基准
  batch_composition: # 每个batch的组成
    visdrone_ratio: 0.67 # 67% VisDrone
    uavdt_ratio: 0.33 # 33% UAVDT
  validation:
    eval_all_datasets: true
    primary_metric: visdrone_mAP
```

### 实现多数据集 DataLoader

```python
# 文件: ultralytics/data/dataset.py
# 新增类: MultiDatasetLoader

class MultiDatasetLoader:
    """多数据集联合训练加载器"""

    def __init__(self, config_path):
        self.config = self.load_config(config_path)
        self.datasets = {}
        self.samplers = {}

        # 初始化各数据集
        for ds_name, ds_config in self.config.items():
            if ds_name == 'training':
                continue
            self.datasets[ds_name] = self.create_dataset(ds_config)
            self.samplers[ds_name] = WeightedRandomSampler(
                weights=ds_config['weight'],
                num_samples=len(self.datasets[ds_name])
            )

    def __iter__(self):
        """按权重采样,组成混合batch"""
        while True:
            batch_data = []

            # 按配置的比例从各数据集采样
            for ds_name, ratio in self.config['training']['batch_composition'].items():
                ds_name = ds_name.replace('_ratio', '')
                n_samples = int(self.batch_size * ratio)
                samples = self.sample_from_dataset(ds_name, n_samples)
                batch_data.extend(samples)

            yield self.collate_batch(batch_data)
```

### 训练策略

```bash
# 从ImageNet预训练开始 (不要用VisDrone best.pt!)
python train_depth.py \
    --data data/multi-dataset-rgbd.yaml \
    --epochs 300 \
    --batch 16 \
    --img 640 \
    --weights yolo12n.pt \  # ImageNet预训练
    --device 0 \
    --project runs/train_multi \
    --name exp_visdrone_uavdt

# 关键: 避免灾难性遗忘!
```

### Phase 2 验收标准

**必达目标** (Milestone 2):

- ✅ Small mAP > 38% (vs Phase 1 的 35%)
- ✅ Large mAP > 44% (vs Phase 1 的 37%, 补 Large 样本后)
- ✅ Overall mAP > 45% (超越 RemDet-S 41.2%)

**理想目标**:

- 🎯 Small mAP > 40%
- 🎯 Large mAP > 46%
- 🎯 Overall mAP > 47%

---

## 📋 Phase 3: 超越 RemDet-M (4-8 周后)

**目标**: Overall mAP > 48% (vs RemDet-M 43.5%)

### 架构级创新方向

1. **自适应双模态融合**

   - 当前: 固定权重融合 RGB 和 Depth
   - 改进: 学习动态权重,不同场景自适应

2. **多尺度几何先验增强**

   - 当前: 单一尺度几何先验
   - 改进: 多尺度先验金字塔

3. **轻量化 Transformer**

   - 在检测头引入 Transformer
   - 增强全局上下文建模

4. **知识蒸馏**
   - 用大模型(YOLO12x)蒸馏小模型(YOLO12n)
   - 保持轻量同时提升性能

---

## 📊 性能跟踪表

### 改进效果记录

| 日期       | 改进项        | Small mAP | Medium mAP | Large mAP | Overall mAP | 备注        |
| ---------- | ------------- | --------- | ---------- | --------- | ----------- | ----------- |
| 2025-10-25 | Baseline      | 30.94%    | 46.24%     | 36.70%    | ~41%        | 初始性能    |
| 待填写     | Loss 权重调整 | ?         | ?          | ?         | ?           | 预期+2-3%   |
| 待填写     | FPN 注意力    | ?         | ?          | ?         | ?           | 预期+1-2%   |
| 待填写     | 数据增强      | ?         | ?          | ?         | ?           | 预期+1%     |
| 待填写     | Phase 1 完成  | >35%      | >48%       | ~37%      | >42%        | Milestone 1 |
| 待填写     | 多数据集训练  | >38%      | >50%       | >44%      | >45%        | Milestone 2 |
| 待填写     | 架构创新      | >40%      | >52%       | >46%      | >48%        | Milestone 3 |

---

## 🔧 开发环境配置

### 本地环境 (Windows)

- **用途**: 代码修改、调试、版本控制
- **Python**: 3.9+
- **IDE**: VS Code + Copilot
- **Git**: 版本管理

### 训练环境 (Linux Server)

- **GPU**: NVIDIA RTX 4090 (24GB)
- **CUDA**: 11.8+
- **PyTorch**: 2.0+
- **Ultralytics**: 8.3.155 (定制版)
- **路径**: `/data2/user/2024/lzy/yolo12-bimodal`

### 代码同步流程

```bash
# 本地修改后
git add .
git commit -m "改进说明"
git push origin main

# 服务器更新
ssh server
cd /data2/user/2024/lzy/yolo12-bimodal
git pull origin main
```

---

## 📝 论文撰写准备

### 核心亮点 (Contributions)

1. **双模态融合创新** ⭐⭐⭐

   - RGB-D 中期融合策略
   - 几何先验增强小目标检测

2. **小目标检测 SOTA** ⭐⭐⭐

   - Small mAP 提升 143% (vs RemDet-Tiny)
   - 专门针对 UAV 场景的优化

3. **轻量化设计** ⭐⭐

   - 仅 2.7M 参数
   - 保持 35+ FPS 实时性

4. **多数据集训练策略** ⭐
   - 避免灾难性遗忘
   - 跨数据集泛化能力

### 实验章节规划

#### 4.1 实验设置

- 数据集: VisDrone, UAVDT
- 实现细节: PyTorch, RTX 4090
- 超参数: 学习率、batch size 等

#### 4.2 与 SOTA 对比

- Table 1: 与 RemDet 系列对比 (主表)
- Table 2: 与其他 UAV 检测方法对比

#### 4.3 消融实验

- RGB vs RGB-D
- 不同融合策略对比
- Loss 权重调整消融
- 数据集规模影响

#### 4.4 可视化分析

- Figure 1: 检测结果可视化
- Figure 2: 特征图可视化
- Figure 3: PR 曲线对比

---

## ✅ 检查清单 (Checklist)

### Phase 1 准备

- [x] 理解 RemDet 多数据集策略
- [x] 理解顺序训练 vs 联合训练
- [x] 创建改进规划文档
- [ ] 实现 Loss 权重调整
- [ ] 训练并验证 Loss 改进效果
- [ ] 实现 FPN 注意力优化
- [ ] 实现数据增强改进
- [ ] Phase 1 完整验证
- [ ] 生成对比报告

### Phase 2 准备

- [ ] 下载 UAVDT 数据集
- [ ] 转换 UAVDT 标注格式
- [ ] 生成 UAVDT 深度图
- [ ] 实现多数据集 DataLoader
- [ ] 创建 multi-dataset-rgbd.yaml
- [ ] 测试多数据集加载器
- [ ] 开始联合训练
- [ ] Phase 2 完整验证

### 论文准备

- [ ] 收集所有实验数据
- [ ] 绘制性能对比表格
- [ ] 生成可视化图表
- [ ] 撰写方法章节
- [ ] 撰写实验章节
- [ ] 准备补充材料

---

## 📞 问题记录与解决

### 已解决问题

1. **Large mAP 低的原因** ✅

   - 原因: VisDrone 训练集 Large 样本仅 0.1% (443 个)
   - 解决: Phase 2 引入 UAVDT 补充 Large 样本

2. **训练策略选择** ✅
   - 问题: 顺序训练 vs 联合训练?
   - 答案: RemDet 使用联合训练,我们分阶段实施

### 待解决问题

1. **多数据集类别映射** ⏳

   - UAVDT 只有 3 类,如何与 VisDrone 10 类对齐?
   - 方案: 映射到 VisDrone 的 car/truck/bus 子集

2. **采样权重调优** ⏳
   - VisDrone vs UAVDT 的采样比例?
   - 初始方案: 1.0 vs 0.5,后续根据效果调整

---

## 🎯 本周行动计划 (Week 1)

### 周一-周二: Loss 权重调整

- [ ] 修改`ultralytics/utils/loss.py`
- [ ] 本地测试代码正确性
- [ ] 上传到服务器
- [ ] 开始 300 epoch 训练

### 周三-周四: 等待训练 + FPN 准备

- [ ] 监控训练曲线
- [ ] 设计 FPN 注意力模块
- [ ] 实现并测试代码

### 周五: 验证 Loss 改进效果

- [ ] 训练完成后验证
- [ ] 分析 Small/Medium/Large mAP 变化
- [ ] 决定是否继续 FPN 改进

### 周末: 总结与规划

- [ ] 生成本周改进报告
- [ ] 更新性能跟踪表
- [ ] 规划下周任务

---

## 📚 参考资料

### 论文

- RemDet (AAAI2025): Rethinking Efficient Model Design for UAV Object Detection
- YOLOv12: Ultralytics 最新版本
- VisDrone: Vision Meets Drones Challenge

### 代码仓库

- Ultralytics: https://github.com/ultralytics/ultralytics
- RemDet (如果开源): 待查找

### 数据集

- VisDrone2019-DET: http://aiskyeye.com/
- UAVDT: https://sites.google.com/view/grli-uavdt/

---

**最后更新**: 2025 年 10 月 30 日  
**下次更新**: Loss 改进训练完成后  
**负责人**: 项目组  
**状态**: 🚀 进行中 (Phase 1)
