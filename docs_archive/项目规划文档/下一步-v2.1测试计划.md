# Phase 2.1: 快速 10-epoch 验证测试

## 目标

验证 v2.1 多尺度融合架构是否有效改进 v1.0 性能

## 成功标准

- mAP@0.5 > 32% (vs v1.0 的 30.86%)
- last_attn_mean 在[0.2, 0.6]范围 (自适应融合正常工作)
- 无 NaN/Inf/OOM 错误
- 训练速度与 v1.0 相当 (~2.5 min/epoch on RTX 4090)

## 测试命令

```bash
# 本地测试(如果环境ok)
python train_depth.py \
    --model ultralytics/cfg/models/12/yolo12s-rgbd-v2.1.yaml \
    --data data/visdrone-rgbd.yaml \
    --epochs 10 \
    --batch 8 \
    --imgsz 640 \
    --device 0 \
    --name rgbd_v2.1_test \
    --save_period -1

# 服务器训练
nohup python train_depth.py \
    --model ultralytics/cfg/models/12/yolo12s-rgbd-v2.1.yaml \
    --data data/visdrone-rgbd.yaml \
    --epochs 10 \
    --batch 8 \
    --imgsz 640 \
    --device 0 \
    --workers 4 \
    --name rgbd_v2.1_test \
    > train_v2.1_test.log 2>&1 &
```

## 监控指标

训练过程中重点观察:

1. **Epoch 1-3 (Warmup)**:

   - Loss 应该快速下降
   - 检查 last_attn_mean (期望 0.3-0.5)
   - 无 CUDA OOM

2. **Epoch 5**:

   - mAP@0.5应该达到 20-25%
   - Precision/Recall gap < 15%

3. **Epoch 10**:
   - **关键目标**: mAP@0.5 > 32%
   - 对比 v1.0 结果表

## 结果分析

### 场景 1: 成功 (mAP@0.5 > 32%)

✅ v2.1 架构有效!
→ 启动 300-epoch 完整训练
→ 预期最终 43-44% mAP@0.5

### 场景 2: 边缘成功 (mAP@0.5 = 31-32%)

⚠️ 有小幅提升但不明显
→ 检查 last_attn_mean 是否过低(<0.2)
→ 调整 fusion_weight 初始值(0.3→0.5)
→ 重新测试 10 epochs

### 场景 3: 失败 (mAP@0.5 < 31%)

❌ 架构有问题
→ 检查 depth_skip 是否全 0 (数据加载问题)
→ 检查 RGBDMidFusion 是否被调用 (添加 debug print)
→ 回退到 v1.0,重新分析问题

## 对比表模板

| 指标         | v1.0 @ epoch 10 | v2.1 @ epoch 10 | 变化 | 结论 |
| ------------ | --------------- | --------------- | ---- | ---- |
| mAP@0.5      | 30.86%          | ?               | ?    | ?    |
| mAP@0.5:0.95 | 17.90%          | ?               | ?    | ?    |
| Precision    | 40.9%           | ?               | ?    | ?    |
| Recall       | 32.3%           | ?               | ?    | ?    |
| box_loss     | 1.382           | ?               | ?    | ?    |
| cls_loss     | 1.016           | ?               | ?    | ?    |
| dfl_loss     | 0.943           | ?               | ?    | ?    |
| Epoch time   | ~2.5 min        | ?               | ?    | ?    |

填写完成后更新到 改进记录.md

## Troubleshooting 预案

### 问题 1: ModuleNotFoundError: No module named 'RGBDMidFusion'

解决:

```bash
# 确认导入正常
python -c "from ultralytics.nn.modules import RGBDMidFusion; print('OK')"

# 如果失败,重新安装
pip install -e .  # editable mode
```

### 问题 2: RuntimeError: depth_skip is None

解决:

- 检查 Layer 0 是否是 RGBDStem
- 添加 debug: 在 tasks.py \_predict_once 中 print(depth_skip.shape)
- 验证:
  ```python
  # 应该看到类似输出:
  # Layer 0 output: torch.Size([8, 128, 320, 320])
  # depth_skip: torch.Size([8, 64, 320, 320])
  ```

### 问题 3: Attention weights stuck at 0.0

解决:

- 深度图可能全 0 或质量极差
- 运行 check_depth_quality.py 验证
- 如果确实有问题,临时增大 fusion_weight (0.3→0.8)

### 问题 4: OOM (Out of Memory)

解决:

- 降低 batch size (8→4)
- 检查 depth_skip 是否被重复存储
- 使用 FP16 混精度: --amp True

## Timeline

- **Day 1 (今晚)**:

  - 上传 v2.1 配置到服务器
  - 启动 10-epoch 测试
  - 设置 monitor_training.py 监控

- **Day 2 (明天)**:

  - 查看结果 (约 25 分钟训练时间)
  - 填写对比表
  - 决定是否进行 300-epoch 训练

- **Day 3 (后天)**:
  - 如果成功,启动完整训练
  - 如果失败,回到 debug 模式

## 预期耗时

- 10 epochs × 2.5 min/epoch = **25 分钟**
- 服务器后台训练,无需等待

## 成功后的奖励 🎁

如果 v2.1 成功 (>32%):

- 证明多尺度融合策略有效 ✅
- 为 Phase 3 (ChannelC2f + SOLR loss) 铺平道路
- 预期最终超越 RemDet! 🚀
